[
  {
    "objectID": "examples/13b_Examples_LatentClassGrowthAnalysis.html",
    "href": "examples/13b_Examples_LatentClassGrowthAnalysis.html",
    "title": "Latent Class Growth Analysis",
    "section": "",
    "text": "Latent Class Growth Analysis (LCGA) is a specialized form of growth modeling that identifies distinct subgroups within a population based on their trajectory patterns over time. Unlike traditional growth models that assume a single underlying growth trajectory for all individuals, LCGA allows for the identification of multiple latent classes, each characterized by its own unique growth path. This method is particularly useful for uncovering heterogeneous patterns of change that might be obscured in an overall population analysis.\nThis example focuses on exploring the developmental trajectories of height across several annual assessments in a cohort from the ABCD Study. Employing LCGA provides the ability to categorize participants into distinct groups based on their growth patterns in height from baseline to subsequent follow-ups. The analysis will determine the number of latent classes that best fit the data, describe the characteristic growth trajectory of each class, and interpret the developmental implications of these findings. Visualizations such as trajectory plots for each class will be used to illustrate the distinct growth patterns."
  },
  {
    "objectID": "examples/13b_Examples_LatentClassGrowthAnalysis.html#overview",
    "href": "examples/13b_Examples_LatentClassGrowthAnalysis.html#overview",
    "title": "Latent Class Growth Analysis",
    "section": "",
    "text": "Latent Class Growth Analysis (LCGA) is a specialized form of growth modeling that identifies distinct subgroups within a population based on their trajectory patterns over time. Unlike traditional growth models that assume a single underlying growth trajectory for all individuals, LCGA allows for the identification of multiple latent classes, each characterized by its own unique growth path. This method is particularly useful for uncovering heterogeneous patterns of change that might be obscured in an overall population analysis.\nThis example focuses on exploring the developmental trajectories of height across several annual assessments in a cohort from the ABCD Study. Employing LCGA provides the ability to categorize participants into distinct groups based on their growth patterns in height from baseline to subsequent follow-ups. The analysis will determine the number of latent classes that best fit the data, describe the characteristic growth trajectory of each class, and interpret the developmental implications of these findings. Visualizations such as trajectory plots for each class will be used to illustrate the distinct growth patterns."
  },
  {
    "objectID": "examples/13b_Examples_LatentClassGrowthAnalysis.html#preliminary-setup",
    "href": "examples/13b_Examples_LatentClassGrowthAnalysis.html#preliminary-setup",
    "title": "Latent Class Growth Analysis",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nLoad Packages\n\n\nCode\nlibrary(tidyverse) # Collection of R packages for data science\nlibrary(tidySEM) # Structural equation modeling in R\nlibrary(gridExtra) # Arrange multiple grid-based plots on a page\nlibrary(easystats)\nlibrary(gtsummary) # Publication-ready tables\nlibrary(rstatix) # Statistical Tests in tidy format\n\n\n\n\nDescriptives\n\n\nCode\ndescriptives_table &lt;- df_long %&gt;%\n    select(event, height) %&gt;%\n    mutate(event = factor(event)) %&gt;%\n    tbl_summary(\n        by = event,\n        missing = \"no\",\n        label = list(height ~ \"Height\"),\n        statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n    ) %&gt;%\n    modify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n    bold_labels() %&gt;%\n    italicize_levels() %&gt;%\n    modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 28181\nYear_1\nN = 28181\nYear_2\nN = 28181\nYear_3\nN = 28181\n\n\n\n\nHeight\n55.1 (3.6) )\n57.5 (3.7) )\n60.3 (3.6) )\n62.3 (4.1) )\n\n\n\n1 Mean (SD) )"
  },
  {
    "objectID": "examples/13b_Examples_LatentClassGrowthAnalysis.html#results",
    "href": "examples/13b_Examples_LatentClassGrowthAnalysis.html#results",
    "title": "Latent Class Growth Analysis",
    "section": "Results",
    "text": "Results\n\nCompute Latent Class Growth Analysis\nLatent Class Growth Analysis (LCGA) is utilized to identify distinct subgroups within the sample based on their growth trajectories of height over four time points. This approach models latent classes that capture varying patterns of growth, potentially reflecting different developmental processes or intervention outcomes.\nThe resulting latent class growth model helps delineate classes that show distinct growth patterns. Each class’s trajectory can be characterized by its initial status (intercept), rate of growth (slope), and pattern changes over time (step and shape), providing a nuanced understanding of how height progresses differently across subgroups. This analysis is particularly valuable in understanding heterogeneity in developmental outcomes.\nSTEP 1: Compute LCGA\n\n\nCode\ndf_wide &lt;- df_long %&gt;%\n    pivot_wider(\n        names_from = event,\n        values_from = height,\n        id_cols = id\n    )\n\nset.seed(27796)\ndf_wide[[\"id\"]] &lt;- NULL\nres_step &lt;- mx_growth_mixture(\n    model = \"\n  i =~ 1*Baseline + 1*Year_1 + 1*Year_2 +1*Year_3\n  step =~ 0*Baseline + 1*Year_1 + 1*Year_2 +1*Year_3\n  s =~ 0*Baseline + 0*Year_1 + 1*Year_2 +2*Year_3\n  Baseline ~~ vBaseline*Baseline\n  Year_1 ~~ vYear_1*Year_1\n  Year_2 ~~ vYear_2*Year_2\n  Year_3 ~~ Year_3*Year_3\n  i ~~ 0*i\n  step ~~ 0*step\n  s ~~ 0*s\n  i ~~ 0*s\n  i ~~ 0*step\n  s ~~ 0*step\",\n    classes = 1:3, data = df_wide\n)\n# Include additional iterations if convergence problems encountered\n# model 1:\n# res_step[[1]] &lt;- mxTryHardWideSearch(res_step[[1]], extraTries = 50)\n\n# Get fit table fit\ntab_fit &lt;- table_fit(res_step)\n# Select columns\ntab_fit &lt;- tab_fit %&gt;%\n    select(Name, Classes, LL, n, Parameters, AIC, BIC, saBIC, Entropy, prob_min, n_min)\n\nprint(tab_fit)\n\n\n  Name Classes     LL    n Parameters   AIC   BIC saBIC Entropy prob_min n_min\n1    1       1 -30782 2818          7 61579 61620 61598   1.000    1.000 1.000\n2    2       2 -28832 2818         11 57687 57752 57717   0.801    0.939 0.468\n3    3       3 -28081 2818         15 56192 56282 56234   0.807    0.887 0.188\n\n\nCode\nres_final &lt;- mx_switch_labels(res_step[[3]],\n    param = \"M[1,7]\",\n    decreasing = FALSE\n)\ntab_res &lt;- table_results(res_final, columns = NULL)\n# Select rows and columns\ntab_res &lt;- tab_res[\n    tab_res$Category %in% c(\"Means\", \"Variances\"),\n    c(\"Category\", \"lhs\", \"est\", \"se\", \"pval\", \"confint\", \"name\")\n]\ntab_res\n\n\n\n  \n\n\n\nCode\nnames(coef(res_final))\n\n\n [1] \"mix3.weights[1,2]\" \"mix3.weights[1,3]\" \"vBaseline\"         \"vYear_1\"           \"vYear_2\"           \"Year_3\"            \"class1.M[1,5]\"     \"class1.M[1,6]\"     \"class1.M[1,7]\"     \"class2.M[1,5]\"    \n[11] \"class2.M[1,6]\"     \"class2.M[1,7]\"     \"class3.M[1,5]\"     \"class3.M[1,6]\"     \"class3.M[1,7]\"    \n\n\nCode\n# Wald test for model comparison\nwald_tests &lt;- wald_test(res_final, \"\n    class1.M[1,6] = class2.M[1,6] &\n    class1.M[1,6] = class3.M[1,6] ;\n    class1.M[1,7] = class2.M[1,7] &\n    class1.M[1,7] = class3.M[1,7]\n\")\n\n# Rename the hypothesis\nwald_tests$Hypothesis &lt;- c(\"Mean Year_1\", \"Mean Year_2\")\nknitr::kable(wald_tests, digits = 2, caption = \"Wald tests\")\n\n\n\nWald tests\n\n\nHypothesis\ndf\nchisq\np\n\n\n\n\nMean Year_1\n2\n17.35\n0.00\n\n\nMean Year_2\n2\n9.35\n0.01\n\n\n\n\n\nThe results from the latent class growth analysis indicate a substantial improvement in model fit as the number of classes increases from one to three, as evidenced by lower Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) values. Specifically, the three-class model shows a log-likelihood (LL) of -28081.19, with an entropy of 0.80, suggesting a good classification accuracy. Notably, each class exhibits distinct growth parameters: the first class shows a mean intercept (i) of 59.45 and slope (s) of 2.29, indicating steady growth; while the third class has a notably lower mean intercept of 51.76 but a comparable slope of 2.36, reflecting similar growth rates from different starting points. The variances across time points also differ significantly between classes, highlighting variability in growth patterns across the sample.\n\n\nModel Plots\n\n\nCode\n# Assuming rng_height and lambda are defined previously in your script\nbrks &lt;- seq(0, 1, length.out = 5) # Breaks in the rescaled 0-1 range\n\n# Convert breaks back to the original log scale\n# Note: This assumes that the original transformation was simply log(x) scaled to 0-1\nlabs &lt;- exp(scales::rescale(brks, from = c(0, 1)))\n\np &lt;- plot_growth(res_step[[3]], rawdata = TRUE, alpha_range = c(0, 0.05))\np &lt;- p + scale_y_continuous(\n    breaks = brks, # Use the same breaks for simplicity\n    labels = round(labs, 2) # Round the labels for readability\n) + ylab(\"Height (rescaled from log)\")\np\n\n\n\n\n\n\n\n\n\nThe provided plot visualizes the growth trajectories from the latent class growth analysis, showcasing how height develops across different classes over time. The plot uses transformed height data, rescaled from log values to a normalized 0-1 range for easier interpretation and comparison. By setting specific breaks on the y-axis, corresponding to the original height values before transformation, the plot facilitates an intuitive understanding of growth patterns across the four time points. The plot highlights distinct growth curves for each class, with the shaded areas representing confidence intervals that help gauge the variability within each class. The plot shows classes overall appear to following similar patterns of growth."
  },
  {
    "objectID": "examples/13b_Examples_LatentClassGrowthAnalysis.html#wrapping-up",
    "href": "examples/13b_Examples_LatentClassGrowthAnalysis.html#wrapping-up",
    "title": "Latent Class Growth Analysis",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThis analysis assessed how participants’ heights change across multiple time points, revealing improved model fit with an increase in the number of classes from one to three. This is supported by reductions in the Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) values, suggesting more precise class specifications enhance model accuracy. The best-fitting three-class model, which attained a log-likelihood of -28081.19 and an entropy of .80, indicates good classification accuracy. Distinct growth patterns emerged across classes and there was a notable variance in intercepts and consistent slopes across classes, emphasizing the variability of developmental patterns within the population.\nLatent Class Growth Analysis (LCGA) is particularly advantageous when exploring heterogeneous population subgroups that follow distinct developmental trajectories over time. This method can effectively identify and categorize latent classes within the data based on differing patterns of change, without the assumption of normally distributed growth within each class. By classifying individuals into discrete groups that share similar growth patterns, LCGA allows for a clearer interpretation of how subgroups differ in their developmental trajectories. This approach is especially valuable in contexts where understanding the diverse patterns of change trajectories is important. It offers robust insights that are not merely averaged across the population but reflect subgroup-specific trends, making it ideal for studies where baseline characteristics and their influence on subsequent outcomes vary significantly across individuals."
  },
  {
    "objectID": "examples/9_Examples_LatentChangeScoresModels.html",
    "href": "examples/9_Examples_LatentChangeScoresModels.html",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "Latent change score models are a statistical technique used for analyzing changes over time by integrating aspects of both structural equation modeling and traditional change score methods. This approach constructs latent variables that directly represent change between time points. First, latent variables for each time point are modeled to capture the true score of the variable of interest, adjusting for measurement error. Then, latent change scores are defined as the difference between latent variables across consecutive time points.\nThis example will explore changes in height from baseline to 3 subsequent annual follow-ups in a sample of participants from the ABCD Study. Initially, latent variables for height at each time point are defined to account for measurement error and capture the true height scores. Latent change scores are then calculated between each pair of consecutive time points to model the true change in height. The dynamics of these changes are visually depicted using trajectory plots, providing a clear visual representation of growth patterns across participants the study."
  },
  {
    "objectID": "examples/9_Examples_LatentChangeScoresModels.html#overview",
    "href": "examples/9_Examples_LatentChangeScoresModels.html#overview",
    "title": "Latent Change Score Models",
    "section": "",
    "text": "Latent change score models are a statistical technique used for analyzing changes over time by integrating aspects of both structural equation modeling and traditional change score methods. This approach constructs latent variables that directly represent change between time points. First, latent variables for each time point are modeled to capture the true score of the variable of interest, adjusting for measurement error. Then, latent change scores are defined as the difference between latent variables across consecutive time points.\nThis example will explore changes in height from baseline to 3 subsequent annual follow-ups in a sample of participants from the ABCD Study. Initially, latent variables for height at each time point are defined to account for measurement error and capture the true height scores. Latent change scores are then calculated between each pair of consecutive time points to model the true change in height. The dynamics of these changes are visually depicted using trajectory plots, providing a clear visual representation of growth patterns across participants the study."
  },
  {
    "objectID": "examples/9_Examples_LatentChangeScoresModels.html#preliminary-setup",
    "href": "examples/9_Examples_LatentChangeScoresModels.html#preliminary-setup",
    "title": "Latent Change Score Models",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nLoad Packages\n\n\nCode\nlibrary(tidyverse) # Collection of R packages for data science\nlibrary(gtsummary) # Publication-ready tables\nlibrary(rstatix) # Statistical Tests in tidy format\nlibrary(lme4) # Linear mixed-effects models\nlibrary(lcsm) # Latent Change Score Models\nlibrary(lavaan) # Structural Equation Modeling\nlibrary(kableExtra) # Table formatting\n\n\n\n\nDescriptives\n\n\nCode\ndescriptives_table &lt;- df_long %&gt;%\n    select(event, height) %&gt;%\n    mutate(event = factor(event)) %&gt;%\n    tbl_summary(\n        by = event,\n        missing = \"no\",\n        label = list(height ~ \"Height\"),\n        statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n    ) %&gt;%\n    modify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n    bold_labels() %&gt;%\n    italicize_levels() %&gt;%\n    modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 28181\nYear_1\nN = 28181\nYear_2\nN = 28181\nYear_3\nN = 28181\n\n\n\n\nHeight\n55.1 (3.6) )\n57.5 (3.7) )\n60.3 (3.6) )\n62.3 (4.1) )\n\n\n\n1 Mean (SD) )"
  },
  {
    "objectID": "examples/9_Examples_LatentChangeScoresModels.html#results",
    "href": "examples/9_Examples_LatentChangeScoresModels.html#results",
    "title": "Latent Change Score Models",
    "section": "Results",
    "text": "Results\n\nCompute Latent Change Score Model\nThe code below is used to compute a latent change score analysis to investigate changes in height across four annual assessments. This statistical approach models growth factors, including constant and proportional changes, and how they vary between individuals. It also evaluates the stability of growth patterns over time, giving a more nuanced understanding of developmental trajectories and the amount of change between each time point.\n\n\nCode\n# Reshape data from long to wide format\ndf_wide &lt;- df_long %&gt;%\n    pivot_wider(\n        id_cols = c(id),\n        names_from = event,\n        values_from = height,\n        names_prefix = \"Height_\"\n    )\n\ndf_wide &lt;- na.omit(df_wide)\n\n# Fit lcsm and save the results\nuni_lavaan_results &lt;- fit_uni_lcsm(\n    data = df_wide,\n    var = c(\n        \"Height_Baseline\", \"Height_Year_1\",\n        \"Height_Year_2\", \"Height_Year_3\"\n    ),\n    model = list(\n        alpha_constant = TRUE,\n        beta = TRUE,\n        phi = TRUE\n    )\n)\n\nuni_lavaan_results\n\n\nlavaan 0.6.16 ended normally after 63 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n  Number of equality constraints                     6\n\n  Number of observations                          2818\n  Number of missing patterns                         1\n\nModel Test User Model:\n                                              Standard      Scaled\n  Test Statistic                               369.370      11.468\n  Degrees of freedom                                 6           6\n  P-value (Chi-square)                           0.000       0.075\n  Scaling correction factor                                 32.208\n    Yuan-Bentler correction (Mplus variant)                       \n\n\nCode\n# Save the lavaan syntax that is used to create the layout matrix for semPlot\nuni_lavaan_syntax &lt;- fit_uni_lcsm(\n    data = df_wide,\n    var = c(\n        \"Height_Baseline\", \"Height_Year_1\",\n        \"Height_Year_2\", \"Height_Year_3\"\n    ),\n    model = list(\n        alpha_constant = TRUE,\n        beta = TRUE,\n        phi = TRUE\n    ),\n    return_lavaan_syntax = TRUE\n)\n\n# Now extract parameter estimates\n# Only extract first 7 columns for this example by adding [ , 1:7]\nparam_bi_lcsm_01 &lt;- extract_param(uni_lavaan_results, printp = TRUE)[, 1:6]\n\n# Print table of parameter estimates\nkable(param_bi_lcsm_01, digits = 3)\n\n\n\n\n\n\nlabel\nestimate\nstd.error\nstatistic\np.value\nstd.lv\n\n\n\n\ngamma_lx1\n55.158\n0.080\n690.80\n&lt; .001\n17.878\n\n\nsigma2_lx1\n9.519\n0.669\n14.22\n&lt; .001\n1.000\n\n\nsigma2_ux\n3.575\n0.645\n5.54\n&lt; .001\n3.575\n\n\nalpha_g2\n17.371\n3.516\n4.94\n&lt; .001\n17.337\n\n\nsigma2_g2\n1.004\n0.222\n4.53\n&lt; .001\n1.000\n\n\nsigma_g2lx1\n2.261\n0.709\n3.19\n.001\n0.731\n\n\nbeta_x\n-0.272\n0.064\n-4.24\n&lt; .001\n-1.214\n\n\nphi_x\n0.429\n0.115\n3.71\n&lt; .001\n0.371\n\n\n\n\n\n\n\n\nThe results of the latent change score model (LCSM) for height indicated increasing patterns of growth. The fitted model included a constant change factor of .52, reflecting a uniform base growth factor across all individuals consistently over time. The proportional change factor of -.27 illustrates a negative relationship, indicating that higher initial heights might result in lesser incremental growth. The phi estimate .43 shows autoregressive effects of the change scores, where the direction and magnitude of past growth significantly predict subsequent changes.\n\n\nModel Plots\n\n\nCode\n# Path diagram plot of model results\nplot_lcsm(\n    lavaan_object = uni_lavaan_results,\n    lavaan_syntax = uni_lavaan_syntax,\n    edge.label.cex = .9,\n    lcsm_colours = TRUE,\n    lcsm = \"univariate\"\n)\n\n\n\n\n\n\n\n\n\nThis path diagram represents the structural relationships specified in the LCSM by simplifying the model structure into a more intuitive graphical format. The diagram highlights connections and dependencies among the variables, as well as the model’s estimated parameters.\n\n\nCode\n# Trajectory Plots\nplot &lt;- plot_trajectories(\n    data = df_wide,\n    id_var = \"id\",\n    var_list = c(\n        \"Height_Baseline\",\n        \"Height_Year_1\",\n        \"Height_Year_2\",\n        \"Height_Year_3\"\n    ),\n    xlab = \"Time\", ylab = \"X Score\",\n    connect_missing = FALSE,\n    random_sample_frac = 0.3\n)\n\nplot\n\n\n\n\n\n\n\n\n\nThis trajectory plot depicts individual growth patterns based on a random sample of 30% of the data. The plot reveals individual variability in changes in height measurements among participants across 4 annual assessments, providing a visualization of how different individuals progress over time."
  },
  {
    "objectID": "examples/9_Examples_LatentChangeScoresModels.html#wrapping-up",
    "href": "examples/9_Examples_LatentChangeScoresModels.html#wrapping-up",
    "title": "Latent Change Score Models",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThis analysis utilized a latent change score model (LCSM) to study the progression of participants’ height across multiple time points, controlling for baseline height measurements. Model results demonstrated a consistent growth pattern, with a constant change factor (γ = .52), which suggests a uniform growth rate across all individuals over time. The proportional change factor (β = -.27) indicated a negative relationship, revealing that individuals with greater initial heights experienced smaller incremental increases. Additionally, the autoregressive parameter (φ = 0.43) highlighted that previous growth trajectories significantly influence subsequent changes, providing insights into the dynamic nature of growth.\nThe LCSM offers a robust framework for analyzing longitudinal data, as it accounts for measurement errors and individual differences in baseline scores. This approach is particularly useful in developmental studies where understanding the intricacies of growth patterns is emphasized. This approach disentangles the elements of growth over time showing the predictive utility of earlier measurements and extending our understanding of growth dynamics."
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html",
    "href": "examples/3a_Examples_LinearMixedModels.html",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "",
    "text": "The Linear mixed model (LMM) with a random intercept is similar to traditional (fixed-effect) linear regression, extending on this approach by including a subject-specific random-effect that allows each participant to have their own unique intercept value, in addition to the overall mean-level (fixed-effect) intercept value.\nThis example will examine trajectories of height obtained across 3 annual measurement occasions in a sample of youth taking part in the ABCD Study. The primary aim is to characterize stability and change in participant’s height, while accounting for observations that are clustered within youth over time. The random-intercept LMM will simultaneously estimate an overall sample mean (fixed effect) for the height trajectory’s intercept and slope values, as well as subject-specific (random) effects that vary randomly about the mean intercept value."
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#overview",
    "href": "examples/3a_Examples_LinearMixedModels.html#overview",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "",
    "text": "The Linear mixed model (LMM) with a random intercept is similar to traditional (fixed-effect) linear regression, extending on this approach by including a subject-specific random-effect that allows each participant to have their own unique intercept value, in addition to the overall mean-level (fixed-effect) intercept value.\nThis example will examine trajectories of height obtained across 3 annual measurement occasions in a sample of youth taking part in the ABCD Study. The primary aim is to characterize stability and change in participant’s height, while accounting for observations that are clustered within youth over time. The random-intercept LMM will simultaneously estimate an overall sample mean (fixed effect) for the height trajectory’s intercept and slope values, as well as subject-specific (random) effects that vary randomly about the mean intercept value."
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#preliminary-setup",
    "href": "examples/3a_Examples_LinearMixedModels.html#preliminary-setup",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nLoad Packages\n\n\nCode\nlibrary(tidyverse) # Collection of R packages for data science\nlibrary(gtsummary) # Publication-ready tables\nlibrary(rstatix) # Statistical Tests in tidy format\nlibrary(lme4) # Linear mixed-effects models\n\n\n\n\nDescriptives\n\n\nCode\ndescriptives_table &lt;- df_long %&gt;%\n    select(event, height) %&gt;%\n    mutate(event = factor(event)) %&gt;%\n    tbl_summary(\n        by = event,\n        missing = \"no\",\n        label = list(height ~ \"Height\"),\n        statistic = list(all_continuous() ~ \"{mean} ({sd})\", all_categorical() ~ \"{p}%\"),\n    ) %&gt;%\n    modify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n    bold_labels() %&gt;%\n    italicize_levels() %&gt;%\n    modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118591\nYear_1\nN = 111421\nYear_2\nN = 91901\n\n\n\n\nHeight\n55.2 (3.3)\n57.6 (3.7)\n60.2 (3.6)\n\n\n\n1 Mean (SD)"
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#results",
    "href": "examples/3a_Examples_LinearMixedModels.html#results",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Results",
    "text": "Results\n\nCompute LMM Model with Random Intercepts\nThis code fits a radom-intercept LMM to predict ‘Height’ across 3 annual visits, accounting for individual-level variability (random effects) of intercept values across participants. Model output is provided below, as well as a brief summary of results.\nThis model accounts for individual variability in height by including a random intercept for each subject (id). The output indicates that the model was fit using the REML (Restricted Maximum Likelihood) criterion.\n\n\nCode\nmodel &lt;- lmer(height ~ 1 + event + (1 | id), data = df_long, REML = T)\n\n## Output and summary statistics\nsummary(model)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: height ~ 1 + event + (1 | id)\n   Data: df_long\n\nREML criterion at convergence: 154311\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-22.541  -0.277  -0.007   0.272  25.590 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 9.20     3.03    \n Residual             3.19     1.79    \nNumber of obs: 32191, groups:  id, 11867\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  55.2411     0.0323  1709.2\neventYear_1   2.3648     0.0238    99.3\neventYear_2   5.0188     0.0256   196.3\n\nCorrelation of Fixed Effects:\n            (Intr) evnY_1\neventYear_1 -0.350       \neventYear_2 -0.326  0.456\n\n\nCode\nconfint(model, level = 0.95, method = \"Wald\")\n\n\n            2.5 % 97.5 %\n.sig01         NA     NA\n.sigma         NA     NA\n(Intercept) 55.18  55.30\neventYear_1  2.32   2.41\neventYear_2  4.97   5.07\n\n\nThese results show an increasing trajectory of height across the years, with an increase of approximately 2.36 inches in Year 1 and 5.02 inches by Year 2 compared to the baseline, as evidenced by the fixed effects estimates. The random intercepts effect suggests some between-subject variability in particpant’s height values at baseline, with a standard deviation of about 3.03 inches. The model’s residuals are mostly well-behaved, although the range suggests a few extreme values or outliers.\n\n\nModel Plots\nThe following set of plots xxxxx.\n\n\nCode\n# Extract fixed effects\nfixed_effects &lt;- fixef(model)\n\n# Prepare data frame for plotting\ndf_long$predicted_height &lt;- predict(model, re.form = NA) # Overall fixed effect predictions\n\n# Calculate individual intercept adjustments\ndf_long$individual_intercept &lt;- predict(model, re.form = ~ (1 | id)) - fixed_effects[1]\n\n# Generate the plot\nggplot(df_long, aes(x = event, y = height)) +\n    geom_line(aes(y = height, color = \"Individual Trajectories\"), alpha = 0.3) +\n    geom_line(aes(y = predicted_height + individual_intercept, group = id, color = \"Adjusted Individual Trajectories\"), alpha = 0.7) +\n    geom_line(aes(x = event, y = predicted_height, group = 1, color = \"Sample Mean Trajectory\"), size = 1.5) +\n    scale_color_manual(values = c(\"Individual Trajectories\" = \"red\", \"Adjusted Individual Trajectories\" = \"grey\", \"Sample Mean Trajectory\" = \"blue\")) +\n    labs(\n        title = \"Individual Trajectories with Fixed Slope and Random Intercepts\",\n        x = \"Event Name\",\n        y = \"Height (inches)\",\n        color = \"Trajectory Type\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nThis plot illustrates the change in participant’s height across 3 annual measurement occassions. The individual raw data points are shown as red lines, representing the original height measurements, which demonstrate the variability among participants at each time point. These are overlaid with grey lines, which adjust each individual’s trajectory to start from their unique intercept while following a common growth pattern indicated by the fixed effects from the model. The blue line represents the sample mean trajectory, calculated from the model’s fixed effects, showcasing the average growth trend across all participants.\nThe plot shows individual trajectories that vary around the model’s predicted values due to random effects, indicating substantial inter-individual variability in baseline heights. On average, participants experienced an increase in height of approximately 2.36 inches from baseline to Year 1 and an additional 2.66 inches from Year 1 to Year 2. The random effects for individual intercepts suggest differences in starting heights, with a standard deviation of 3.03 inches, reflecting the variability in growth patterns among the participants."
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#wrapping-up",
    "href": "examples/3a_Examples_LinearMixedModels.html#wrapping-up",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThe random-intercept LMM analysis revealed an increasing pattern of change in children’s height measured over 3 annual assessments. The mean intercept value showed an average initial height of 55.24 inches (sd = 3.03) with evidence of individual variability around this (random effect) estimate. An examination of the slope factor revealed year-to-year growth increments of approxmiately 2.5 inches, with the rate of change held constant across all participants.\nThe LMM framework used in this example offered the ability to account for individual differences in initial height and the consistent growth patterns over time, demonstrating its utility in handling clustered or correlated data that arise from repeated measurements on the same subjects. More generally, this approach is often particularly useful in developmental studies as it allows for the inclusion of both fixed effects, which estimate common parameters across all individuals, and random effects, which capture unique variations among individuals. This enables a more precise understanding of both the group-level trends and individual-specific trajectories in longitudinal data."
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Difference scores can be used to assess change in a variable across two timepoints. The value of the variable at the first timepoint is substracted from the value at the second timepoint. A simple regression can then be applied to determine whether a variable of interest predicts the computed difference score.\nThis example will examine height values obtained across 2 annual measurement occasions in a sample of youth taking part in the ABCD Study. The primary aim is to determine whether a variable of interest (handedness) predicts the difference in height values between the two timepoints. A difference score will be calculated between participant’s height values collected at baseline and again at the 1-year follow-up. Next, a simple regression analysis will be conducted to test whether handedness (left, right) predicts the average difference value in participants’ height from baseline to the 1-Year follow-up. Finally, a visual inspection is further conducted via a violin plot to graphically represent the relationship between the difference score and handedness."
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#overview",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#overview",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Difference scores can be used to assess change in a variable across two timepoints. The value of the variable at the first timepoint is substracted from the value at the second timepoint. A simple regression can then be applied to determine whether a variable of interest predicts the computed difference score.\nThis example will examine height values obtained across 2 annual measurement occasions in a sample of youth taking part in the ABCD Study. The primary aim is to determine whether a variable of interest (handedness) predicts the difference in height values between the two timepoints. A difference score will be calculated between participant’s height values collected at baseline and again at the 1-year follow-up. Next, a simple regression analysis will be conducted to test whether handedness (left, right) predicts the average difference value in participants’ height from baseline to the 1-Year follow-up. Finally, a visual inspection is further conducted via a violin plot to graphically represent the relationship between the difference score and handedness."
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#preliminary-setup",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#preliminary-setup",
    "title": "Difference Scores: Simple Regression",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nLoad R libraries\n\n\nCode\nlibrary(tidyverse) # Collection of R packages for data science\nlibrary(gtsummary) # Publication-ready tables\nlibrary(rstatix) # Statistical Tests in tidy format\n\n\n\n\nDescriptives\n\n\nCode\ndescriptives_table &lt;- df_long %&gt;%\n    select(event, handedness, height) %&gt;%\n    mutate(event = factor(event)) %&gt;%\n    mutate(handedness = factor(handedness)) %&gt;%\n    tbl_summary(\n        by = event,\n        missing = \"no\",\n        label = list(handedness ~ \"Handedness\", height ~ \"Height\"),\n        statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n    ) %&gt;%\n    modify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n    bold_labels() %&gt;%\n    italicize_levels() %&gt;%\n    modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 102631\nYear_1\nN = 96291\n\n\n\n\nHandedness\n\n\n\n\n    Right\n92%\n92%\n\n\n    Left\n8.3%\n8.3%\n\n\nHeight\n55.2 (3.3) )\n57.6 (3.6) )\n\n\n\n1 %; Mean (SD) )"
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#results",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#results",
    "title": "Difference Scores: Simple Regression",
    "section": "Results",
    "text": "Results\n\nCompute Difference Score\nThis code computes a difference score by subtracting participant’s height at baseline from height at the 1-year follow-up. Next, a simple regression analysis is conducted to determine whether handedness predicts the difference in height values between the two timepoints.\n\n\nCode\n# Reshape data from long to wide format\ndf_wide &lt;- df_long %&gt;%\n  pivot_wider(\n    id_cols = c(id, handedness),\n    names_from = event,\n    values_from = height,\n    names_prefix = \"Height_\"\n  )\n\n# Compute the height difference score\ndf_wide &lt;- df_wide %&gt;%\n    mutate(\n        height_diff = Height_Year_1 - Height_Baseline\n    )\n\n# Calculate summary statistics for the difference score\nsummary(df_wide$height_diff)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n    -52       2       2       2       3      67     634 \n\n\nCode\n# Compute summary statistics for Height by eventname\nsummary &lt;- df_long %&gt;%\n    group_by(event) %&gt;%\n    get_summary_stats(height, type = \"mean_sd\")\n\ndata.frame(summary)\n\n\n\n  \n\n\n\nThe summary statistics provide insights into participant’s height across two annual assessments. At baseline, the average height is 55.24 inches (sd = 3.33). Over the year, there is an increase of 2.35 inches in average height to 57.59 inches at the time of the 1-year follow-up.\n\n\nConduct regression on Difference Score\nA simple regression analyses is conducted to examine whether a grouping variable (handedness) predicts the difference score value.\n\n\nCode\n# Run the regression\nmodel &lt;- lm(height_diff ~ handedness, data = df_wide)\n\n# Get the summary of the regression model\nsummary(model)\n\n\n\nCall:\nlm(formula = height_diff ~ handedness, data = df_wide)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -54.2   -0.6   -0.1    0.6   64.6 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.3507     0.0254   92.42   &lt;2e-16 ***\nhandednessLeft   0.0347     0.0883    0.39     0.69    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.39 on 9627 degrees of freedom\n  (634 observations deleted due to missingness)\nMultiple R-squared:  1.6e-05,   Adjusted R-squared:  -8.78e-05 \nF-statistic: 0.154 on 1 and 9627 DF,  p-value: 0.694\n\n\nThe results from the simple regression analysis suggest handedness does not significantly predict change in height. The intercept, estimated at 2.35 with a standard error of .02, indicates the average height difference for right-handed individuals is approximately 2.35 units, with this effect differing by only .03 inches (p=.69) for left-handed individuals\n\n\nModel Plots\n\n\nCode\n# Visualize the difference scores across different levels of handedness\n\n# Create a violin plot to show the distribution of difference scores by sex\n# Jittered points are added to provide a more granular view of individual observations\n# Load necessary libraries\nlibrary(RColorBrewer)\n\n# Plotting using ggplot2\nggplot(df_long, aes(x = handedness, y = height, fill = handedness)) +\n    geom_violin() +\n    geom_jitter(position = position_jitter(width = 0.2), size = 1, alpha = 0.5) +\n    scale_fill_brewer(palette = \"Set2\") +\n    labs(\n        title = \"Difference Scores by Handedness\",\n        x = \"Handedness\",\n        y = \"Height Difference Score\"\n    ) +\n    theme_minimal() +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\"\n    )\n\n\n\n\n\n\n\n\n\nThe violin plot visualizes the distribution of difference scores in children’s heights by their handedness (Right, Left). Each violin shape provides insight into the density of the data at different height differences, with wider sections representing higher densities of data points. Superimposed jittered points offer a granular view of individual observations. From the plot, it appears that the distributions of height differences across the two handedness categories are markedly similar."
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#wrapping-up",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#wrapping-up",
    "title": "Difference Scores: Simple Regression",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThis analysis examined difference scores of participant’s height across a one-year period and used a simple regression analysis to explore the impact of handedness on the year-to-year change in children’s height. Findings showed an increase in height values from baseline (55.23 inches) to the year 1 follow-up (57.57 inches). The regression model’s output shows that handedness, specifically being left-handed as compared to right-handed, is not associated with any change in height (r=.03, se=.08, p=.69). Further, a violin plot visualizing the distribution of difference scores in children’s heights by their handedness showed no substantive effect.\nThis difference score approach used in this example quantifies the change in height values over time and uses a simple regression to test whether participant handedness predicts this value. More generally, this approach is often implemented when data used to evalaute change is only available at two timepoints, as more flexible approaches are typically implemented when data from additional (&gt;2) time points is available."
  },
  {
    "objectID": "manuscript/manuscript.html",
    "href": "manuscript/manuscript.html",
    "title": "Longitudinal Analysis of the ABCD® Study",
    "section": "",
    "text": "The Adolescent Brain Cognitive Development (ABCD) Study® is the largest longitudinal investigation of neurodevelopment and child health in the United States. Conceived and initiated by the National Institutes of Health (NIH), this landmark prospective longitudinal study aims to transform our understanding of the genetic and environmental factors impacting neurodevelopment and their roles in behavioral and health outcomes across ten years of adolescence Volkow et al. (2018). At its heart, the study is designed to chart the course of human development across multiple interacting domains from late childhood to early adulthood and to identify factors that lead to both positive and negative outcomes. Central to achieving these goals is the commitment of the ABCD Study and its NIH funders to an open science framework, intended to facilitate sharing of data and analytical methods by espousing practices that increase access, integrity, and reproducibility of scientific research. In this context, the ABCD Study is a collaboration with the broader research community.\nThe size and scope of the ABCD Study data allow the research community to perform a large variety of developmental analyses of both substantive and methodological interest, presenting a unique opportunity to significantly advance our understanding of how a multitude of biopsychosocial processes unfold across critical periods of development. In this paper, we describe models and methods for longitudinal analysis of ABCD Study data that can address these fundamental scientific aims, including: 1) characterization of the genetic and environmental factors associated with variation in developmental trajectories; 2) assessment of how the level and timing of exposures may impact subsequent neurodevelopment; 3) quantification of how variation in developmental domains may be associated with outcomes, including mediation models and reciprocal relationships. We instantiate these longitudinal analyses in worked examples using the ABCD Release 5.1 data with accompanying R scripts. Worked examples are available in Quarto files, accessible in the project’s GitHub repository.\n\n\nThe ABCD Study enrolled a cohort of n=11,880 participants born between 2006-2008 and aged approximately 9-10 years at baseline, each with a parent/guardian. The study sample was recruited from households in defined catchment areas for each of the 21 (originally 22) study sites across the United States. Information regarding funding agencies, recruitment sites, investigators, and project organizations can be obtained at https://abcdstudy.org. The ABCD Study design is described in more detail in Garavan et al. (2018) and Dick et al. (2021).\nThe ABCD Study is currently collecting longitudinal data on a rich variety of outcomes that will enable the construction of complex statistical models, potentially incorporating factors from many domains. Each new wave of data collection provides another building block for characterizing developmental trajectories and implementing longitudinal analyses that allow researchers to characterize normative development, to identify variables that presage deviations from normative development, and to assess a range of variables associated with biopsychosocial outcomes of interest. These data include: 1) a neurocognitive battery Luciana et al. (2018); Wesley K. Thompson et al. (2019); 2) mental and physical health assessments Barch et al. (2018); 3) measures of culture and environment Gonzalez et al. (2021); Zucker et al. (2018); 4) substance use Lisdahl et al. (2021); 5) gender identity and sexual health Potter et al. (2022); 6) biospecimens Uban et al. (2018); 7) structural and functional brain imaging Casey et al. (2018); Hagler et al. (2019); Palmer et al. (2022); 8) geolocation-based environmental exposure data Fan et al. (2021); 9) wearables and mobile technology Bagot et al. (2018); and 10) whole-genome genotyping Loughnan et al. (2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual brief telephone or online assessments.\nData are publicly released approximately annually, currently through the NIMH Data Archive (NDA). The study’s earliest data releases consisted primarily of one or two visits per participant. However, the most recent public release as of the writing of this paper (Release 5.1) contains data collected across five annual visits, including three brain imaging assessments (baseline, year 2 follow-up, and year 4 follow-up visits) for at least a subset of the cohort. Hence, starting with Release 5.0, it is feasible for researchers to begin focusing on the characterization of neurodevelopmental and other trajectories.\n\n\n\n\n\n\n\n\n\nOrganization and Aims\n\n\n\n\n\n• Part I. Introduction\n\nThe ABCD Study®\n\n• Part II. Developmental Research\n\nFundamental Concepts\n\n• Part III. Longitudinal Analysis\n\nMethods & Analysis\n\n• Part IV. Supplemental materials\n\nLinked open-source resources",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis of the ABCD&reg; Study"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#the-abcd-study-data",
    "href": "manuscript/manuscript.html#the-abcd-study-data",
    "title": "Longitudinal Analysis of the ABCD® Study",
    "section": "",
    "text": "The ABCD Study enrolled a cohort of n=11,880 participants born between 2006-2008 and aged approximately 9-10 years at baseline, each with a parent/guardian. The study sample was recruited from households in defined catchment areas for each of the 21 (originally 22) study sites across the United States. Information regarding funding agencies, recruitment sites, investigators, and project organizations can be obtained at https://abcdstudy.org. The ABCD Study design is described in more detail in Garavan et al. (2018) and Dick et al. (2021).\nThe ABCD Study is currently collecting longitudinal data on a rich variety of outcomes that will enable the construction of complex statistical models, potentially incorporating factors from many domains. Each new wave of data collection provides another building block for characterizing developmental trajectories and implementing longitudinal analyses that allow researchers to characterize normative development, to identify variables that presage deviations from normative development, and to assess a range of variables associated with biopsychosocial outcomes of interest. These data include: 1) a neurocognitive battery Luciana et al. (2018); Wesley K. Thompson et al. (2019); 2) mental and physical health assessments Barch et al. (2018); 3) measures of culture and environment Gonzalez et al. (2021); Zucker et al. (2018); 4) substance use Lisdahl et al. (2021); 5) gender identity and sexual health Potter et al. (2022); 6) biospecimens Uban et al. (2018); 7) structural and functional brain imaging Casey et al. (2018); Hagler et al. (2019); Palmer et al. (2022); 8) geolocation-based environmental exposure data Fan et al. (2021); 9) wearables and mobile technology Bagot et al. (2018); and 10) whole-genome genotyping Loughnan et al. (2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual brief telephone or online assessments.\nData are publicly released approximately annually, currently through the NIMH Data Archive (NDA). The study’s earliest data releases consisted primarily of one or two visits per participant. However, the most recent public release as of the writing of this paper (Release 5.1) contains data collected across five annual visits, including three brain imaging assessments (baseline, year 2 follow-up, and year 4 follow-up visits) for at least a subset of the cohort. Hence, starting with Release 5.0, it is feasible for researchers to begin focusing on the characterization of neurodevelopmental and other trajectories.",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis of the ABCD&reg; Study"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#section",
    "href": "manuscript/manuscript.html#section",
    "title": "Longitudinal Analysis of the ABCD® Study",
    "section": "",
    "text": "Organization and Aims\n\n\n\n\n\n• Part I. Introduction\n\nThe ABCD Study®\n\n• Part II. Developmental Research\n\nFundamental Concepts\n\n• Part III. Longitudinal Analysis\n\nMethods & Analysis\n\n• Part IV. Supplemental materials\n\nLinked open-source resources",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis of the ABCD&reg; Study"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#basic-concepts-and-considerations",
    "href": "manuscript/manuscript.html#basic-concepts-and-considerations",
    "title": "Longitudinal Analysis of the ABCD® Study",
    "section": "2.1 Basic Concepts and Considerations",
    "text": "2.1 Basic Concepts and Considerations\nThere are several important concepts to consider when conducting longitudinal analyses in a developmental context. These include different ways of thinking about the developmental course, whether certain periods of development are relatively sensitive or insensitive to various types of insults or stressors, whether some time periods or situations inhibit the expression of individual differences due to extreme environmental pressures, and whether the same behavior manifested at different times represents the same or different phenomena.\nMoreover, in the case of developmentally-focused longitudinal research, each new measurement occasion not only provides a more extended portrait of the child’s life course but also brings with it greater methodological opportunities to make use of statistical models that distinguish within- from between-person effects and that loosen constraints that need to be imposed on the furtherance of critical scientific questions.\nFor example, collecting two or more within-person observations on the same construct at different times enables estimation of individual rates of change (slopes) where more observations allow for more precise estimates of individual slopes (random slopes), as well as characterization of non-linear development. Rate of change or other trajectory characteristics may be more informative about individuals than the simple snapshots of level differences that cross-sectional data are limited to informing about. Cross-sectional age-related differences across individuals are poor substitutes for longitudinal trajectory estimates, except under highly restrictive assumptions, e.g., parallel trajectories and lack of age, cohort and experience effects Wesley K. Thompson et al. (2011). Appreciation of these and other issues can help to guide the analysis and interpretation of data and aid translation to clinical and public health applications.\n\n2.1.1 Vulnerable periods.\nAdolescent development progresses normatively from less mature to more mature levels of functioning. However, unique epochs and experiences can alter the course of this idealized form of development. Consider research that shows cannabis use during adolescence is associated with later psychosis to a greater degree than cannabis use initiated later in development Arseneault et al. (2002); Bechtold et al. (2016); Hasan et al. (2020); Semple, McIntosh, and Lawrie (2005). Similarly, rodent brains are especially sensitive to the neurotoxic effects of alcohol on brain structure and learning early in development, corresponding to early adolescence in humans Spear (2016); Crews et al. (2000); Ji et al. (2018). In another example, longitudinal data from the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) show that binge drinking is associated more strongly with decrements in gray matter volume early in adolescence compared to later Infante et al. (2022). These examples highlight the importance of considering the role of vulnerable periods – e.g., temporal windows of rapid brain development or remodeling during which the effects of environmental stimuli on the developing brain may be particularly pronounced– when trying to establish an accurate understanding of the association between exposures and outcomes.\n\n\n2.1.2 Developmental disturbances.\nWhereas vulnerable periods heighten neurobiological susceptibility to environmental influences, at other times, environmental exposures will tend to suppress stability and disrupt the orderly stochastic process of normative development (e.g., Schulenberg et al. (2019)). This situation reflects a developmental disturbance in that the normal course of development is “altered” for a time by some time-limited process. In such cases, we might find that prediction of behavior in the period of the disturbance is reduced and/or, similarly, the behavior exhibited during the disturbance might have less predictive power with respect to distal outcomes compared to the behavior exhibited before and following the disrupted period. That is, once the environmental pressures are removed (or the individual is removed from the environment), patterns of individual differences (and autoregressive effects) recover to levels similar to those prior to entering the environment.\n\n\n2.1.3 Developmental snares and cascade effects.\nNormative development can also be upended by experiences (e.g., drug use) that, through various mechanisms, disrupt the normal flow of development wherein each stage establishes a platform for the next. For instance, substance use could lead to association with deviant peers, precluding opportunities for learning various adaptive skills and prosocial behaviors, in effect creating a “snare” that delays psychosocial development, such as maturing out of adolescent antisocial behavior Moffitt (2015). Relatedly, the consequences of these types of events can cascade (e.g., school dropout, involvement in the criminal justice system) so that the effects of the snare are amplified (e.g., Masten et al. (2005); Rogosch, Oshri, and Cicchetti (2010)). Although conceptually distinct from vulnerable periods, both types of developmental considerations highlight the importance of viewing behavior in the context of development and attempting to determine how various developmental pathways unfold. Longitudinal data are crucial in this context to assess individual levels of development prior to and following onset of experiences or other environmental factors (e.g., the ABCD Study collected data starting at ages 9-10 and hence before the onset of substance use for the vast majority of participants).\n\n\n2.1.4 Mediational Processes.\nQuestions regarding the biological mechanisms whereby exposures impact outcomes can often be framed in terms of mediation analyses MacKinnon, Fairchild, and Fritz (2007); VanderWeele (2016). Mediation analyses can be implemented using the causal steps approach Baron and Kenny (1986) and structural equation models (SEM) Preacher, Zhang, and Zyphur (2011). More recently, mediation models have been adapted for longitudinal exposures, mediators, and/or outcomes Bind et al. (2016); VanderWeele and Tchetgen Tchetgen (2017). All of these modeling approaches decompose the total effects of an exposure on an outcome into direct and indirect effects, where indirect effects of an exposure flow through its impact on a mediating process. VanderWeele and Tchetgen Tchetgen (2017) details conditions under which the direct and indirect causal effects can be in a longitudinal setting. An important example of mediational analyses in the ABCD Study is the impact of exposures on behavioral outcomes (e.g., neurocognition, mental health, substance use) via their impact on the brain, as quantified by imaging-derived phenotypes (IDPs). Methods for mediational analyses using multi-dimensional IDPs have been developed and applied to functional MRI data Lindquist (2012); Zhao et al. (2018).",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis of the ABCD&reg; Study"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#considerations-and-challenges",
    "href": "manuscript/manuscript.html#considerations-and-challenges",
    "title": "Longitudinal Analysis of the ABCD® Study",
    "section": "3.1 Considerations and Challenges",
    "text": "3.1 Considerations and Challenges\nThe hallmark characteristic of longitudinal data analysis (LDA) is the administration of repeated measurements of the same constructs on assessment targets (e.g., individuals, families) across time. The primary rationale for collecting longitudinal data is to assess within-person change over time, allowing researchers to estimate individual developmental trajectories and the genetic and person-level factors that may impact these trajectories. Administering repeated measurements more frequently or over longer periods enables researchers to ask more nuanced questions and to make stronger inferences.\n\n3.1.1 Two Time Points versus Three or More.\nAlthough the clear leap from cross-sectional to the realm of longitudinal data involves going from one assessment to two or more assessments, there are also notable distinctions in designs based on two-assessment points versus three or more measurement occasions. Just as cross-sectional data can be informative in some situations, two waves of data can be beneficial in contexts such as when an exposure is involved (e.g., pre/post tests), or if the central goal is prediction (e.g., trying to predict scores on Variable A at time T as a function of prior scores on Variable A and Variable B at time T-1). At the same time, analyses of data based on two assessments are inherently limited on multiple fronts. As Rogosa, Brandt, and Zimowski (1982) noted over forty years ago, “Two waves of data are better than one, but maybe not much better” (p. 744).\nThese sentiments are reflected in more contemporary recommendations regarding best-practice guidelines for prospective data, which increasingly emphasize the benefits of additional measurement occasions for trajectory estimation, model identification and accurate parameter inferences. This is also consistent with recommendations that developmental studies include three or more assessment points, given it is impossible for data based on two-time points to determine the shape of development (given that linear change is the only estimable form for two assessment waves; (see Duncan and Duncan (2009)). Research designs that include three (but preferably more) time points allow for non-linear trajectory estimation and increasingly nuanced analyses that more adequately tease apart sources of variation and covariation among the repeated assessments King et al. (2018)– a key aspect of developmental research.\nTo illustrate, developmental theories are useful for understanding patterns of within-individual change over time (discussed in further detail, below); however, two data points provide meager information on change at the person level. This point is further underscored in a recent review of statistical models commonly touted as distinguishing within-individual vs between-individual sources of variance in which the study authors concluded “… researchers are limited when attempting to differentiate these sources of variation in psychological phenomenon when using two waves of data” and perhaps more concerning, “…the models discussed here do not offer a feasible way to overcome these inherent limitations” Andrew K. Littlefield et al. (2021). It is important to note, however, that despite the current focus on two-wave designs versus three or more assessment waves, garnering three assessment points is not a panacea for longitudinal modeling. Indeed, several contemporary longitudinal models designed to isolate within-individual variability (e.g., the Latent Curve Model with Structured Residuals [LCM: SR]; Patrick J. Curran et al. (2014)) require at least four assessments to parameterize fully and, more generally, increasingly accurate and nuanced parameter estimates are obtained as more assessment occasions are used Duncan and Duncan (2009).\n\n\n3.1.2 Types of stability and change\nIf one were to try to sum up what developmental trajectories in a living organism are exactly, one could plausibly argue they are the patterns of stability and change in its phenotypes as the organism traverses the life course. Symbolically, developmental trajectories can be expressed as fi(t), a possibly multivariate function of time t, specific to the ith individual and typically taking values in the real numbers for continuous phenotypes and the integers for discrete phenotypes. Ideally, t is a biologically meaningful temporal index (e.g., calendar age) as opposed to an exogenous progression of events (e.g., study visit number). Properties of interest might include rate of change over time, degree of smoothness (e.g., continuously differentiable), shape (e.g., polynomial or asymptotic behavior), how and how much f(t) differs across individuals, and what factors predict either within-individual variation (at different times) or between-individual variation (either overall or at specific times).\nThere are a few different ways to think about patterns of stability and change (see Figure 1). Consider measuring school disengagement at the start of middle school and the end of middle school. A common first step may be to compare sixth graders’ average disengagement values and eighth graders’ disengagement values. This comparison of the average scores for the same group of individuals at multiple time points is referred to as “mean-level”, as it provides information about change over time (or lack thereof) for an outcome of interest aggregated across members of a group. In contrast, “between-individual” stability could be assessed, e.g., by calculating the Spearman correlation between the values obtained at different time points (e.g., ‘disengagement in sixth grade’ with ’disengagement in eighth grade). This analysis focuses on the degree to which individuals retain their relative placement in a group across time. Consider someone who reported the lowest frequencies of disengagement in 6th grade and may report significantly higher disengagement over middle school (i.e., exhibit high levels of change), but report the lowest frequencies of disengagement in eighth grade. That is, the individual is manifesting rank-order stability, even in the context of high mean-level change.\nBoth types of stability and change are important. Mean-level change in certain traits might help to explain why, in general, populations of individuals tend to be particularly vulnerable to the effects of environmental factors in specific age ranges; rank-order stability might help to quantify the extent to which certain characteristics of the individual are more or less trait-like compared to others. For example, in some areas of development, considerable mean-level change occurs over time (e.g., changes in Big 5 personality traits Bleidorn et al. (2022), but exhibit relatively high rank-order stability, at least over shorter measurement intervals Bleidorn et al. (2022); Roberts and DelVecchio (2000); Roberts, Walton, and Viechtbauer (2006).\nDespite the useful information afforded by examining mean-level and rank-order stability and change, these approaches are limited in that they provide little information about the overall patterns of within-individual change and, in turn, can result in fundamental misinterpretations about substantial or meaningful changes in an outcome of interest Patrick J. Curran and Bauer (2011). For example, questions related to the impact of early-onset substance use on brain development focus on changes within a given individual (i.e., intraindividual differences). The ABCD Study will provide researchers with over ten time points for certain constructs (e.g., substance use) across a ten-year period, allowing for a detailed study of some within-person processes.\n\n\n\n\n\n\nFigure 1: Types of Stability and Change\n\n\n\n\n\n3.1.3 Use of appropriate longitudinal models\nThere is growing recognition that statistical models commonly applied to longitudinal data often fail to align with the developmental theory they are being used to assess (e.g., Patrick J. Curran and Bauer (2011); Hoffman (2015); Andrew K. Littlefield et al. (2021)). First, developmental studies typically involve the use of prospective data to inform theories that are concerned with clear within-person processes (e.g., how phenotypes change or remain stable within individuals over time, (e.g., Patrick J. Curran and Bauer (2011))). Despite this, methods generally unsuited for disaggregating between- and within-person effects (e.g., cross-lagged panel models [CLPM]) remain common within various extant literatures. Fortunately, there exists a range of models that have been proposed to tease apart between- and within-person sources of variance across time (see Andrew K. Littlefield et al. (2021); Orth et al. (2021)). Most of these contemporary alternatives incorporate time-specific latent variables to capture between-person sources of variance and model within-person deviations around an individual’s mean (or trait) level across time (e.g., random-intercept cross-lagged panel model [RI-CLPM], Hamaker, Kuiper, and Grasman (2015)); latent curve models with structured residuals [LCM-SR], Patrick J. Curran et al. (2014)). It is important to note however that these models require multiple assessments waves (e.g., four or more to fully specify the LCM-SR), additional expertise to overcome issues with model convergence, and appreciation of modeling assumptions when attempting to adjudicate among potential models in each research context (see Andrew K. Littlefield et al. (2021), for further discussion).\nSecond, many statistical models assume certain characteristics about the data to which they are being applied. Common assumptions of parametric statistical models (e.g., linear mixed-effects models) include normality and equality of variances. These assumptions should be carefully considered before finalizing analytical approaches, so that valid inferences can be made from the data, as violation of a model’s assumptions can substantively invalidate the interpretation of results. For example, longitudinal data can exhibit heterogeneous variability (i.e., the variance of the response changes over the duration of the study) that may need to be accounted for within a model. Another pertinent modeling assumption is whether trajectories are linear or non-linear. With two or three assessments per individual, usually only a linear model of within-person change is feasible.\nAs the study progresses and more time points are assessed, the potentially nonlinear aspects of trajectories can be assessed, for example using quadratic functions of time. Methods that make even fewer assumptions about trajectory shapes, such as nonparametric curve estimation at the mean (e.g., Generalized Additive Mixed Models [GAMMs]; Wood (2017)) and at the individual level (e.g., Functional Data Analysis [FDA]; Ramsay and Silverman (2002)) may also become useful. Note, baseline age in the ABCD Study ranges over two full years; for some outcomes it may be feasible to include a possibly nonlinear effect of baseline age along with a linear effect of within-person change in age even with only two or three assessment times Wesley K. Thompson et al. (2013).\n\n\n3.1.4 Continuous and Discrete Outcomes\nRepeated assessments within the ABCD Study can be based on continuous or discrete measures. Examples of discrete measures include repeated assessments of binary variables (e.g., past 12-month alcohol use disorder status measured across ten years), ordinal variables (e.g., caregiver-reported items measuring emotional and behavioral concerns via the Child Behavior Checklist including the categories of “Not True”, “Somewhat True”, and “Very True”), and count variables (e.g., number of cigarettes smoked per day). In many ways, the distributional assumptions of indicators used in longitudinal designs mirror the decision points and considerations when delineating across different types of discrete outcome variables, a topic that spans entire textbooks (e.g., see Lenz (2016)). For example, the Mplus manual L. K. Muthén (2017) includes examples of a) censored and censored-inflated models, b) linear growth models for binary or ordinal variables, c) linear growth models for a count outcome assuming a Poisson model, and d) linear growth models for a count outcome assuming a zero-inflated Poisson model. Beyond these highlighted examples, other distributions (e.g., negative binomial) can be assumed for the indicators when modeling longitudinal data Ren et al. (2022). These models account for issues that may occur when working with discrete outcomes, including overdispersion, i.e., when the variance is higher than would be expected based on a given parametric distribution (see Lenz (2016)). Given the sheer breadth of issues relevant to determining adequate models for discrete outcomes, it is not uncommon for texts on LDA to only cover models and approaches that assume continuous variables (e.g., T. D. Little (2013)). However, some textbooks on categorical data analysis provide more detailed coverage of the myriad issues and modeling choices to consider when working with discrete outcomes: Lenz (2016), Chapter 11 for matched pair/two-assessment designs; Chapter 12 for marginal and transitional models for repeated designs, such as generalized estimating equations, and Chapter 13 for random effects models for discrete outcomes.\n\n\n3.1.5 Issues in attributing longitudinal change to development\nSystematic changes over time in a variable of interest are not always attributable to development: various pitfalls with longitudinal data can complicate or even invalidate this conclusion. For example, if data missingness or participant dropout are related to the values of the outcome, changing sample composition as the study progresses can bias mean trajectory estimates (we describe this in more detail in Section 3.1.7 below). Another prerequisite for valid developmental interpretations of longitudinal data is to establish whether a construct is measured consistently over time, i.e., longitudinal measurement invariance Liu et al. (2017); Van De Schoot et al. (2015); Willoughby, Wirth, and Blair (2012). Establishing longitudinal measurement invariance ensures that change over time for a given construct is attributable to individual development rather than merely a measurement artifact. For instance, one study using data from the ABCD Study Brislin et al. (2023) found differential item functioning in two items from a brief delinquency measure, revealing significant bias in an arrest item across Black and White youth. More specifically, Black youth were more likely to report being arrested compared to White youth with similar levels of delinquency. Prevalence rates of delinquent behavior would have been severely biased if measurement invariance had not been tested. Alternatively, Vize et al. (2023) showed partially strong to strong evidence of longitudinal measurement invariance across broad externalizing dimensions in youth taking in the ABCD Study, suggesting that changes observed over time in these constructs were not due to systematic measurement error, but likely reflect true developmental change.\nObserved patterns of growth and decline often differ between cross-sectional vs. longitudinal effects Salthouse (2014) where subjects gain increasing experience with the assessment with each successive measurement occasion. Such experience effects on cognitive functioning have been demonstrated in adolescent longitudinal samples similar to ABCD Sullivan et al. (2017) and highlight the need to consider these effects and address them analytically. In the case of performance-based measures (e.g., matrix reasoning related to neurocognitive functioning; see Salthouse (2014)), this can be due to “learning” the task from previous test administrations (e.g., someone taking the test a second time performs better than they did the first time simply as a function of having taken it before). Even in the case of non-performance-based measures (e.g., levels of depression), where one cannot easily make the argument that one has acquired some task-specific skill through learning, it has been observed that respondents tend to endorse lower levels on subsequent assessments (e.g., A. T. Beck et al. (1961); French and Sutton (2010)) and this phenomenon has been well documented in research using structured diagnostic interviews Robins (1985). While it is typically assumed that individuals are rescinding or telling us less information on follow-up interviews, there is reason to suspect that in some cases the initial assessment may be artifactually elevated (see Shrout et al. (2018)).\nSome longitudinal studies, e.g., accelerated longitudinal designs (ALDs; Wesley K. Thompson et al. (2011)) are especially well suited for discovering these effects and modeling them. While ABCD is not an ALD, the variability in age (and grade in school) at the time of baseline recruitment (approximately 9-10 years old) allows some measures, collected every year, to be conceptualized as an ALD (e.g., substance use; prosocial behavior; family conflict; screen time). It is also possible that in later waves, analyses will allow for disaggregating the confounded effects of age and the number of prior assessments. However, ABCD is fundamentally a single-cohort, longitudinal design, wherein number of prior assessments and age are mostly confounded, and for, perhaps, most analyses, the possible influence of experience effects needs to be kept in mind.\n\n\n3.1.6 Modeling Covariance\nA central issue for repeated measurements on an individual is how to account for the correlated nature of the data. Lack of independence of residuals across time occurs for longitudinal data with repeated assessments on individuals and in other situations with nested data (e.g., visits nested within participants, children nested within schools; siblings nested within families). Note, the ABCD Study has multiple levels of nesting, depending on the analysis, including within-participant, within-family, within-school, within-MRI scanner, and within-site.\nStatistical models for nested data include two main components, coupling a model for the mean response and its dependence on covariates with a model for the covariance among repeated outcomes on an individual. In contrast, traditional methods, such as multiple regression and ANOVAs, assume residuals are independent and thus are generally inappropriate for designs that incorporate some type of nesting. Specifically, given that residuals are no longer independent in a repeated measures design, standard errors from these models are biased and can produce misleading inferences. Therefore, an initial question to be addressed by a researcher analyzing prospective data is how to best model their covariance structure. A range of methods can be used to model covariance structures, each with its own set of tradeoffs between model fit and parsimony and which may be more or less appropriate for each specific application (e.g., see Kincaid (2005)).\nThe most common approach is to use random effects. Essentially, random effects allow for covariance estimates around fixed effects. A classic example (from Bryk and Raudenbush (1992); Singer (1998)) involves math achievement measured among students nested within schools. In a basic, intercept-only model with no covariates (i.e., an unconditional growth model), there would be one fixed effect (the grand mean, or intercept, of math achievement), one school random effect (representing variation in the intercept between schools) and the within-school student residuals (variation left over after accounting for fixed and random effects). In this framework, each student’s score would be the sum of the fixed effect (the grand mean), the school random effect and the student’s within-school residual. Assumptions about the variance and covariance components of this model dictate the form of the variance/covariance structure. For example, if we assume the random effects are independent and identically distributed, the implied structure would be compound symmetry, where it is assumed the covariance of any two students in a single school is captured by a school random intercept and the covariance of any two students in different schools is zero. The assumptions of this relatively simple covariance structure can be relaxed depending on the nesting structure of the data, resulting in different covariance structures with additional parameters (see Singer (1998)).\nIn longitudinal studies, visits are nested within individuals. Mixed-effect models can be fitted to longitudinal data that couple a model for growth (development) at the mean level with a model for capturing within-individual covariance of assessments. For example, a linear growth model would involve two fixed effects – one for the intercept (the average score when time is coded zero) and one for the linear slope (the change in scores for each unit increase in time). Random effects could include a random effect for intercept, capturing individual variation in scores at time zero, and a random effect for the linear slope, capturing individual variation in linear change across time. Within-individual residuals account for the remaining variation in assessments after accounting for the fixed and random intercepts and slopes. Assumptions regarding the covariation among the random effects also indicate different covariance structures. For example, it is typical to assume that the random intercept and slope components covary, i.e., an individual’s score at time zero relates to the amount of change exhibited across time. Further, particularly in structural equation model forms of this model, it is sometimes assumed that the variance of the residuals varies across assessments Patrick J. Curran (2003).\nAn alternative to random effects is the autoregressive structure, which allows for correlations between repeated assessments to diminish across time. As the name suggests, the structure assumes the residual of a subsequent measurement occasion (e.g., visit 2) is regressed onto the residual of a prior measurement occasion (e.g., baseline visit). The most common type of autoregressive structure is the AR(1), where residuals at time t + 1 are regressed on residuals at time t. Identical to compound symmetry, this model assumes the variances are homogenous across time; however, it differs from compound symmetry in that the correlations between repeated assessments decline exponentially across visits rather than remaining constant. That is, we can think of the underlying process as a stochastic one that wears itself out over time. For example, per the AR(1) structure, if the correlation between visit 1 and visit 2 data is thought to be .5, then the correlation between visit 1 and visit 3 data would be assumed to be .5 × .5 = .25, and the correlation between visit 1 and visit 4 data would be assumed to be .5 × .5 × .5 = .125. As with compound symmetry, the basic AR(1) model is parsimonious in that it only requires two parameters: the variance of the residuals and the autoregressive coefficient.\nNotably, the assumption of constant autoregressive relations between assessments is often relaxed in commonly employed designs that use autoregressive modeling (e.g., CLPM). These designs still typically assume an AR(1) process. However, the magnitude of these relations is often allowed to differ across different AR(1) pairs of assessment (e.g., the relation between visit 1 and visit 2 can be different from the relation between visit 2 and visit 3). These models also often relax the assumption of equal variances of the repeated assessments.\nAlthough the AR(1) structure may involve a more realistic set of assumptions compared to compound symmetry, in that the AR(1) model allows for diminishing correlations across time, the basic AR(1) model, as well as autoregressive models more generally, can also suffer from several limitations in contexts that are common in prospective designs. In particular, recent work demonstrates that if a construct being assessed prospectively across time is trait-like in nature, then a simple AR(1) process fail to adequately account for this trait-like structure, with the downstream consequence that estimates derived from models based on AR structures (such as the CLPM) can be misleading and fail to adequately demarcate between- vs. within-person sources of variance Hamaker, Kuiper, and Grasman (2015). Note also, discrete-time autoregressive structures such as AR(1) implicitly assumes relatively constant time gaps between visits; this may not be true in many applications using the ABCD Study data.\n\n\n3.1.7 Missing Data/Attrition\nAttrition from a longitudinal study such as ABCD is inevitable and represents a potential threat to the external validity of analyses conducted at later visits, especially since attrition can only be expected to grow over time Andrew K. Littlefield et al. (2022). The ABCD Retention Workgroup employs a data-driven approach to examine, track, and intervene in these issues and while preliminary findings show participant race and parent education level to be associated with late and missing visits, although to date, formal attrition in ABCD has been minimal Ewing et al. (2022). Ideally, one tries to minimize attrition through good retention practices from the outset via strategies designed to maintain engagement in the project Cotter et al. (2005); Hill et al. (2016); Watson et al. (2018). However, even the best-executed studies need to anticipate growing attrition over the length of the study and implement analytic strategies designed to provide the most valid inferences.\nPerhaps the most key concern when dealing with data that is missing due to attrition is determining the degree of bias in retained variables that is a consequence of attrition. Such bias can attenuate generalizability, particularly if the pattern of missingness is not random (e.g., certain subsets of the population are more likely to drop out/not attend a visit). Assuming that the data are not missing completely at random, attention to the nature of the missingness and employing techniques designed to mitigate attrition-related biases need to be considered in all longitudinal analyses.\nThree types of missingness are considered in the literature R. J. Little and Rubin (1989); T. D. Little (2013), namely: a) missing completely at random (MCAR), b) missing at random (MAR), and c) missing not at random (MNAR). Data that are MCAR are a simple random sample of all data in a given dataset. MAR implies missing data are a random sample (i.e., does not hinge on some unmeasured variables) within strata of the measured covariates in a dataset (e.g., biological sex). Data that are MNAR are missing as a function of unobserved variables and may bias associations even after conditioning on the observed covariates. Graham (2009) provides an excellent and easy-to-digest overview of further details involving missing data considerations.\nModern approaches for handling missing data, such as full-information maximum likelihood, propensity weighting, auxiliary variables and multiple imputation avoid the biases of older approaches (see Enders (2010); Graham (2009)). Graham (2009) noted several “myths” regarding missing data. For example, Graham notes many assume the data must be minimally MAR to permit estimating procedures (such as maximum likelihood or multiple imputation) compared to other, more traditional approaches (e.g., using only complete case data). Violations of MAR impact both traditional and more modern data estimation procedures, though as noted by Graham, violations of MAR tend to have a greater effect on older methods. Graham thus suggests that imputing missing data is a better approach compared to listwise deletion in most circumstances, regardless of the model of missingness (i.e., MCAR, MAR, MNAR; see Graham (2009); but also see Twisk et al. (2013)). The ABCD Biostatistics Workgroup is currently implementing several missing data approaches which are being implemented and compared to each other (and listwise deletion) in the 5.0 data release, including, propensity score weighting, and multiple (multilevel) imputation.\n\n\n3.1.8 Quantifying effect sizes longitudinally\nGiven that longitudinal data involve multiple sources of variation, quantifying effect sizes longitudinally is more complex compared to deriving such estimates from cross-sectional data. An effect size can be defined as, “a population parameter (estimated in a sample) encapsulating the practical or clinical importance of a phenomenon under study.” (Kraemer 2014). Common effect size metrics include the Pearson correlation r between two variables and the standardized difference between two means, Cohen’s d Cohen (1988). An extensive discussion of cross-sectional effect sizes and their relevance for ABCD is given in Dick et al. (2021).\nAdjustments to common effect size calculations, such as Cohen’s d, are required even when only two time points are considered (e.g., Morris and DeShon (2002)). Wang et al. (2019) note there are multiple approaches to obtaining standardized within-person effects, and that commonly suggested approaches (e.g., global standardization) can be problematic (see Wang et al. (2019), for more details). Thus, obtaining effect size metrics based on standardized estimates that are relatively simple in cross-sectional data (such as r) becomes more complex in the context of prospective longitudinal data. Feingold (2009) noted that equations for effects sizes used in studies involving growth modeling analysis (e.g., latent growth curve modeling) were not mathematically equivalent, and the effect sizes were not in the same metric as effect sizes from cross-sectional analysis (see Feingold (2009), for more details).\nGiven this issue, there have been various proposals for adjusting effect size measures in repeated assessments. Feingold (2019) reviews the approach for effect size metrics for analyses based on growth modeling, including when considering linear and non-linear (e.g., quadratic) growth factors. Morris and DeShon (2002) review various equations for effect size calculations relevant to combining estimates in meta-analysis with repeated measures and independent-groups designs. Other approaches to quantifying effect sizes longitudinally may be based on standardized estimates from models that more optimally disentangle between- and within-person sources of variance. As an example, within a random-intercept cross-lagged panel model (RI-CLPM) framework, standardized estimates between random intercepts (i.e., the correlation between two random intercepts for two different constructs assessed repeatedly) could be used to index the between-person relation, whereas standardized estimates among the structured residuals could be used as informing the effect sizes of within-person relationships.\n\n\n3.1.9 Longitudinal Data Structures\nAn ideal longitudinal analysis integrates (a) a well-articulated theoretical model, (b) an appropriate longitudinal data structure, and (c) a statistical model that is an operationalization of the theoretical model Collins (2006). To accommodate various research questions and contexts, different types of longitudinal data and data structures have emerged (see Figure 1). An understanding of these data structures is helpful, as they can warrant different types of LDA. Given that identifying a starting point for making comparisons is somewhat arbitrary, Curran and Bauer and Curran (2019) provide a nice on-ramp in first distinguishing between the use of “time-to-event” and “repeated measures” data. Although both model time, the former is concerned with whether and when an event occurs, whereas the later is focused on growth and change Bauer and Curran (2019) Time-to-event structures measure time from a well-defined origin point up to the occurrence of an event of interest. This data structure is most often analyzed using survival analysis methods (e.g., hazard rate models, event history analysis, failure-time models and the time-to-event data can be based on a single assessment or include multiple recurrent or competing events). While much has been written about “time-to-event” data Hosmer Jr, Lemeshow, and May (2008); Rizopoulos (2012), including a recent analysis examining exclusionary discipline in schools using data from the ABCD Study Brislin et al. (2023), our emphasis will be given to the modeling of “repeated measures” data.\n Link\nWhen discussing longitudinal analysis, we are most often talking about data collected on the same unit (e.g., individuals) across multiple measurement occasions. However, repeated-measures analysis is not a monolith, and it will serve us well to distinguish between a few of the most common types. One such approach to repeated measures analysis is the use of time-series models. These models generally consist of a long sequence of repeated measurements (≧ 50-100 measurements) on a single or small number of variables of interest. Time-series analysis is often used to predict temporal trends and cyclic patterns and is geared toward making inferences about prospective outcomes within a population (with relatively less focus on inferring individual-level mechanisms and risk factors).\nA related type of repeated measures analysis is Intensive Longitudinal Data (ILD). Similar to time-series analysis, ILD models involve frequent measurements (~ 30-40 measurements) of the same individuals in a relatively circumspect period (e.g., experience sampling to obtain time series on many individuals). Although ILD models may include slightly fewer measurement occasions than time-series data, ILD models tend to have more subjects than time-series models (~ 50-100 subjects). This allows ILD models to examine short-term patterns by incorporating a time series model that can sometimes fit parameter estimates to each individual’s data to model individual difference outcomes.\nThe final type of repeated measures analysis that we will primarily focus on is the longitudinal panel study. These models follow a group of individuals— a panel (also referred to as a cohort) — across relatively fewer measurement occasions (~ 5-15) and are often focused on examining both change within- and between-individuals. The ABCD Study is primarily a longitudinal panel study, though some data streams (e.g., functional brain imaging, FitBit data) could be analyzed as ILP or even time series methods.\nWhile other longitudinal designs have their own unique strengths and applications, the longitudinal panel design is particularly well-suited for investigating developmental processes in the context of the ABCD Study. In the following sections, we will discuss various analytic methods commonly used to analyze longitudinal panel data, including growth models, mixed models, and a number of additional trajectory models. These methods provide valuable insights into within- and between-individual differences and are highly relevant for researchers working with the ABCD Study dataset. By focusing on these methods, we aim to equip readers with the knowledge necessary to conduct longitudinal research and perform analyses using the rich, longitudinal, and publicly available data from the ABCD Study.",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis of the ABCD&reg; Study"
    ]
  },
  {
    "objectID": "examples/examples.html",
    "href": "examples/examples.html",
    "title": "",
    "section": "",
    "text": "Code",
    "crumbs": [
      "ABCD Examples",
      "<i class=\"bi bi-book\"></i> Examples"
    ]
  },
  {
    "objectID": "examples/examples.html#examples",
    "href": "examples/examples.html#examples",
    "title": "",
    "section": " Examples",
    "text": "Examples\n\n\n\nEach Example uses data from the ABCD Study Dataset and provides a practical solution to a specific longitudinal method or analytic problem.\n\n\n\n\n\n\n\n    \n        \n            \n            \n                Traditional Linear Models\n                \n                \n                    \n                        Difference Scores (Paired T-test)\n                        \n                    \n                        Difference Scores (Simple Regression)\n                        \n                    \n                        Residualized Change Scores\n                        \n                    \n                        Linear Mixed\n                        Models (Random Intercept)\n                    \n                    \n                        Linear Mixed\n                        Models (Random Slope)\n                    \n                \n            \n        \n        \n            \n            \n                Traditional Nonlinear Models\n                \n                \n                \n                  \n                        Signed-Rank\n                        Test\n                        \n                    \n                        Marginal Models\n                        \n                        \n                        Generalized\n                        Estimating Equations\n                        \n                        \n                        Generalized Linear\n                        Mixed Effects Models\n                        \n                \n            \n        \n        \n            \n            \n                Structural Equation Models\n                \n                \n                \n                  \n                        Latent Change Score Models\n                        \n                    \n                        Latent Growth Curve Models\n                        \n                    \n                        Latent Transition Analysis\n                        \n                \n            \n        \n        \n            \n            \n                Advanced SEM\n                \n                \n                \n                  \n                        Random-Intercept Crosslagged Panel Model\n                        \n                        \n                        Latent Curve Models with Structured Residuals\n                        \n                \n            \n        \n        \n            \n            \n                Additional Models\n                \n                \n                \n                  \n                        Twin Designs\n                        \n                    \n                        Zero-Inflation Models\n                        \n                    \n                        Longitudinal Invariance",
    "crumbs": [
      "ABCD Examples",
      "<i class=\"bi bi-book\"></i> Examples"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "index.html#our-mission",
    "href": "index.html#our-mission",
    "title": "",
    "section": "Our Mission",
    "text": "Our Mission\nWe aim to provide accessible resources for those interested in longitudinal data analysis, using publicly available data from the ABCD Study to showcase various methodologies and techniques."
  },
  {
    "objectID": "index.html#why-this-project",
    "href": "index.html#why-this-project",
    "title": "",
    "section": "Why This Project?",
    "text": "Why This Project?\n\nPublicly Available Code: Future updates will include ready-to-use code examples for your research and educational needs. See some initial examples here or in the examples folder of our GitHub repository\nOpen Source Collaboration: Engage with our community to contribute, learn, and share insights on longitudinal data analysis.\nEducational Resource: Gain comprehensive knowledge in using GitHub, R, RMarkdown/Quarto, and various longitudinal analysis methods."
  },
  {
    "objectID": "index.html#how-to-contribute",
    "href": "index.html#how-to-contribute",
    "title": "",
    "section": "How to Contribute",
    "text": "How to Contribute\n\nProvide New Examples: Enhance our repository with your unique analysis examples.\nHelp With Documentation: Contribute to making our documentation more comprehensive and user-friendly.\nRepository Maintenance: Assist in the ongoing maintenance and accessibility of our GitHub repository.\n\nFor more information on how you can make an impact, check out our Contribution Guide."
  },
  {
    "objectID": "index.html#project-resources",
    "href": "index.html#project-resources",
    "title": "",
    "section": "Project Resources",
    "text": "Project Resources\n\nCode Examples: Discover a variety of analysis examples to guide your research.\nDocumentation: Get detailed insights into our project’s progress, tasks, and timelines.\nCommunity Discussion Forum: Connect with fellow researchers and enthusiasts ."
  },
  {
    "objectID": "index.html#about-us",
    "href": "index.html#about-us",
    "title": "",
    "section": "About Us",
    "text": "About Us\nWe are a team driven by the mission to make longitudinal data analysis more accessible and understandable. Our collective effort focuses on fostering an open source community where knowledge and skills in research methodologies can flourish."
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "Difference scores can be used to assess change in a variable across two timepoints. The value of the variable at the first timepoint is substracted from the value at the second timepoint. A one-sample t-test can then be applied to determine whether the mean change is significantly different from zero.\nThis example will examine height values obtained across 2 annual measurement occasions in a sample of youth taking part in the ABCD Study. The primary aim is to determine whether height values in the sample, on average, increase across the two timempoints. A difference score will be calculated between participant’s height values collected at baseline and again at the 1-year follow-up. Next, a one-sample t-test will be used to test whether the difference score is statistically different than a null hypothesis of zero change. Finally, a visual inspection is further conducted via a scatterplot to graphically represent the relationship between participant’s height across assessments."
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html#overview",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html#overview",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "Difference scores can be used to assess change in a variable across two timepoints. The value of the variable at the first timepoint is substracted from the value at the second timepoint. A one-sample t-test can then be applied to determine whether the mean change is significantly different from zero.\nThis example will examine height values obtained across 2 annual measurement occasions in a sample of youth taking part in the ABCD Study. The primary aim is to determine whether height values in the sample, on average, increase across the two timempoints. A difference score will be calculated between participant’s height values collected at baseline and again at the 1-year follow-up. Next, a one-sample t-test will be used to test whether the difference score is statistically different than a null hypothesis of zero change. Finally, a visual inspection is further conducted via a scatterplot to graphically represent the relationship between participant’s height across assessments."
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html#preliminary-setup",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html#preliminary-setup",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nLoad R libraries\n\n\nCode\nlibrary(tidyverse) # Collection of R packages for data science\nlibrary(gtsummary) # Publication-ready tables\nlibrary(rstatix) # Statistical Tests in tidy format\n\n\n\n\nDescriptives\n\n\nCode\ndescriptives_table &lt;- df_long %&gt;%\n    select(event, height) %&gt;%\n    mutate(event = factor(event)) %&gt;%\n    tbl_summary(\n        by = event,\n        missing = \"no\",\n        label = list(height ~ \"Height\"),\n        statistic = list(all_continuous() ~ \"{mean} ({sd})\", all_categorical() ~ \"{p}%\"),\n    ) %&gt;%\n    modify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n    bold_labels() %&gt;%\n    italicize_levels() %&gt;%\n    modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118591\nYear_1\nN = 111421\n\n\n\n\nHeight\n55.2 (3.3)\n57.6 (3.7)\n\n\n\n1 Mean (SD)"
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html#results",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html#results",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "Results",
    "text": "Results\n\nCompute Difference Score\nThis code computes a difference score by subtracting participant’s height at baseline from height at the 1-year follow-up. Next, a one-sample t-test is conducted to determine whether the mean difference score is different from zero. Model output is provided below, as well as a brief summary of results.\n\n\nCode\n# Reshaping data from long to wide\ndf_wide &lt;- df_long %&gt;%\n    pivot_wider(\n        id_cols = id,\n        names_from = event,\n        values_from = height,\n        names_prefix = \"Height_\"\n    )\n\n# Compute the height difference score\ndf_wide &lt;- df_wide %&gt;%\n    mutate(\n        height_diff = Height_Year_1 - Height_Baseline\n    )\n\n# Calculate summary statistics for the difference score\nsummary(df_wide$height_diff)\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n    -52       2       2       2       3      67     729 \n\n\nCode\n# Compute summary statistics for Height by eventname\nsummary &lt;- df_long %&gt;%\n    group_by(event) %&gt;%\n    get_summary_stats(height, type = \"mean_sd\")\n\ndata.frame(summary)\n\n\n\n  \n\n\n\nThe summary statistics provide insights into participant’s height across two annual assessments. At baseline, the average height is 55.24 inches (sd = 3.33). Over the year, there is an increase of 2.35 inches in average height to 57.59 inches at the time of the 1-year follow-up.\n\n\nConduct t-test on Difference Score\nA one-sample t-test is computed on the difference scores to examine whether there is evidence of change in participant’s height between the two timepoints.\n\n\nCode\n# Perform a one-sample t-test on the difference scores for height\nmodel &lt;- t.test(df_wide$height_diff, mu = 0)\nmodel\n\n\n\n    One Sample t-test\n\ndata:  df_wide$height_diff\nt = 99, df = 11135, p-value &lt;2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 2.32 2.41\nsample estimates:\nmean of x \n     2.37 \n\n\nThe results from the one-sample t-test conducted on the height difference scores reveals an increase in height from Baseline to Year 1. The t-test yields a t-value of 98.86 with a p-value less than &lt;.001, indicating that the average height increase of 2.36 inches is significantly different from zero. Additionally, the 95% confidence interval indicates that the true mean difference score in the population lies between approximately 2.31 to 2.41 inches.\n\n\nModel Plots\n\n\nCode\n# Scatterplot to compare height differences across two events\nggplot(df_wide, aes(x = Height_Baseline, y = Height_Year_1)) +\n    geom_point(aes(color = Height_Baseline), alpha = 0.6) + # Color points by event type, adjust for your data\n    labs(\n        x = \"Height at Baseline\",\n        y = \"Height at Year 1\",\n        title = \"Scatterplot of Heights at Baseline and Year 1\",\n        subtitle = \"Each point represents a participant\"\n    ) +\n    theme_minimal() +\n    geom_smooth(method = \"lm\", se = FALSE) + # Add a regression line without confidence interval\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\nThe scatterplot visually depicts the relationship between individuals’ heights at baseline and their heights at year 1. Each point on the plot represents an individual, with their baseline height plotted on the x-axis and their year 1 height on the y-axis. A noticeable positive linear trend can be observed, as highlighted by the blue regression line, indicating that those who were taller at baseline generally remained taller at year 1. The strength and direction of this relationship suggests a strong positive association between baseline and year 1 height values."
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html#wrapping-up",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html#wrapping-up",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThis analysis examined difference scores of participant’s height using a one-sample t-test. Findings showed a significant increase in height values over the one-year interval of 2.36 inches, with confidence intervals ranging from 2.31 to 2.41 (t = 98.864, df = 11135, p-value &lt; 2.2e-16). Further, a scatterplot visualizing the relationship between baseline and Year_1 weights showed a strong positive linear trend. This suggests that participants who were taller at baseline generally remained taller at Year_1, reaffirming the consistent growth trend observed in the data.\nThis difference score approach used in this example quantifies the change in height values over time within a single group and uses a one-sample t-test to test whether this value differs significanctly from 0. More generally, this approach is often implemented when data used to evalaute change is only available at two timepoints, as more flexible approaches are typically implemented when data from additional (&gt;2) time points is available."
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html",
    "href": "examples/2_Examples_ResidualizedChangeScores.html",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "A residualized change score is a statistical approach used to account for the baseline (initial) values of a variable when measuring across two time points. First, a linear regression is conducted with the follow-up score predicted by the baseline score. The residual values from this model can be interpreted as change scores that have been adjusted for the baseline values. In a next step, regression analysis can be applied to determine whether a variable of interest predicts the residualized change score.\nThis example will examine whether handedness predicts changes in height from baseline to the 1 year follow-up, controlling for initial height measurements, in a sample of participants taking part in the ABCD Study. Initially, a linear regression analysis predicts height measurements at the 1 year follow-up from their baseline values to calculate residualized change scores. Subsequently, a second regression assesses whether handedness (left vs. right) predicts these residualized changes in height measurements. The relationship is also visually represented through a violin plot, illustrating differences in the residualized height values between left-handed and right-handed individuals."
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#overview",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "A residualized change score is a statistical approach used to account for the baseline (initial) values of a variable when measuring across two time points. First, a linear regression is conducted with the follow-up score predicted by the baseline score. The residual values from this model can be interpreted as change scores that have been adjusted for the baseline values. In a next step, regression analysis can be applied to determine whether a variable of interest predicts the residualized change score.\nThis example will examine whether handedness predicts changes in height from baseline to the 1 year follow-up, controlling for initial height measurements, in a sample of participants taking part in the ABCD Study. Initially, a linear regression analysis predicts height measurements at the 1 year follow-up from their baseline values to calculate residualized change scores. Subsequently, a second regression assesses whether handedness (left vs. right) predicts these residualized changes in height measurements. The relationship is also visually represented through a violin plot, illustrating differences in the residualized height values between left-handed and right-handed individuals."
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#preliminary-setup",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#preliminary-setup",
    "title": "Residualized Change Scores",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nLoad Packages\n\n\nCode\nlibrary(tidyverse) # Collection of R packages for data science\nlibrary(gtsummary) # Publication-ready tables\nlibrary(rstatix) # Statistical Tests in tidy format\nlibrary(lme4) # Linear mixed-effects models\n\n\n\n\nDescriptives\n\n\nCode\ndescriptives_table &lt;- df_long %&gt;%\n    select(event, handedness, height) %&gt;%\n    mutate(event = factor(event)) %&gt;%\n    mutate(handedness = factor(handedness)) %&gt;%\n    tbl_summary(\n        by = event,\n        missing = \"no\",\n        label = list(handedness ~ \"Handedness\", height ~ \"Height\"),\n        statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n    ) %&gt;%\n    modify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n    bold_labels() %&gt;%\n    italicize_levels() %&gt;%\n    modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 102631\nYear_1\nN = 96291\n\n\n\n\nHandedness\n\n\n\n\n    Right\n92%\n92%\n\n\n    Left\n8.3%\n8.3%\n\n\nHeight\n55.2 (3.3) )\n57.6 (3.6) )\n\n\n\n1 %; Mean (SD) )"
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#results",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#results",
    "title": "Residualized Change Scores",
    "section": "Results",
    "text": "Results\n\nCompute Multiple Regression Model\nThe code below is used to compute a residualized change score by first adjusting participants’ height at the 1-year follow-up for their baseline height through a regression analysis. The residuals from this model represent the adjusted height changes that are not explained by their initial measurements. Subsequently, these residualized change scores are used in a simple regression analysis to explore whether handedness predicts the changes in height between the two timepoints. This approach helps to isolate any effect of handedness on height growth, independent of the baseline height values.\n\n\nCode\n# Reshape data from long to wide format\ndf_wide &lt;- df_long %&gt;%\n    pivot_wider(\n        names_from = event,\n        values_from = height,\n        names_prefix = \"Height_\"\n    )\n\n# Step 1: Fit the linear model to get residuals\nmodel_baseline &lt;- lm(Height_Year_1 ~ Height_Baseline, data = df_wide, na.action = na.exclude)\ndf_wide &lt;- df_wide %&gt;%\n    mutate(residualized_change = residuals(model_baseline))\n\n# Step 2: Model residualized change scores predicted by handedness\nmodel_residualized_change &lt;- lm(residualized_change ~ handedness, data = df_wide, na.action = na.exclude)\n\n# View the summary of the model to see the effect of handedness\nsummary(model_residualized_change)\n\n\n\nCall:\nlm(formula = residualized_change ~ handedness, data = df_wide, \n    na.action = na.exclude)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-53.91  -0.80  -0.09   0.70  65.53 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    -0.00555    0.02477   -0.22     0.82\nhandednessLeft  0.06693    0.08600    0.78     0.44\n\nResidual standard error: 2.33 on 9627 degrees of freedom\n  (634 observations deleted due to missingness)\nMultiple R-squared:  6.29e-05,  Adjusted R-squared:  -4.1e-05 \nF-statistic: 0.606 on 1 and 9627 DF,  p-value: 0.436\n\n\nThe results from the residualized change score analysis suggest that while individual differences in growth occurs, handedness does not appear to be a determining factor. The model intercept, close to zero (-0.005), is consistent with the expectation that if there is no effect for handedness, there would be no change when adjusting for baseline heights. Further, examination of the model residuals (range = -53.90 to 65.53, se = 2.32) and the negligible r-squared value indicates that handedness does not explain a substantive portion of the variance in residualized height changes.\n\n\nModel Plots\n\n\nCode\npar(mfrow = c(2, 2)) # Set up a 2x2 plotting area\nplot(model_baseline) # Generate diagnostic plots\n\n\n\n\n\n\n\n\n\nCode\n# Visualize the residualized change scores across different levels of handedness\n\n# Create a violin plot to show the distribution of residualized change scores by handedness\n# Jittered points are added to provide a more granular view of individual observations\n# Load necessary libraries\nlibrary(RColorBrewer)\n\n# Plotting using ggplot2\nggplot(df_long, aes(x = handedness, y = height, fill = handedness)) +\n    geom_violin() +\n    geom_jitter(position = position_jitter(width = 0.2), size = 1, alpha = 0.5) +\n    scale_fill_brewer(palette = \"Set2\") +\n    labs(\n        title = \"Residualized Change Score by Handedness\",\n        x = \"Handedness\",\n        y = \"Height Change Score\"\n    ) +\n    theme_minimal() +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 1),\n        legend.position = \"none\"\n    )\n\n\n\n\n\n\n\n\n\nThe violin plot visualizes the distribution of residualized change scores in children’s heights by their handedness (Right, Left). Each violin shape provides insight into the density of the data at different (residualized) height values, with wider sections representing higher densities of data points. Superimposed jittered points offer a granular view of individual observations. From the plot, it appears that the overall distributions of the residualized change scores for the height outcome across the two handedness categories are markedly similar."
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#wrapping-up",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#wrapping-up",
    "title": "Residualized Change Scores",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThis analysis evaluated residualized change scores of participants’ height over a one-year period, controlling for initial height measurements at baseline. It then utilized a simple regression analysis to investigate handedness as a predictor of these adjusted changes in height. Findings demonstrated a non-significant effect of handedness on the residualized height values, with left-handed individuals showing an average height change increase of .06 inches (r = .77, se = .08, p = .43) more than right-handed individuals. A visual inspection using a violin plot further supported these results, showing overlapping distributions of residualized height changes across handedness categories, indicating no substantial effect.\nThis approach of using residualized change scores can be particularly valuable when initial measurement levels may influence the outcome. In some context, this analysis can provide a more accurate reflection of change by accounting for baseline values, making it suitable for analyses where measurement of change is a primary aim and where baseline characteristics might otherwise obscure true changes."
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html",
    "href": "examples/4_Examples_SignedRankTest.html",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "It is actually quite common that numeric depend variables need to be transformed or converted into ranks, i.e. ordinal variables, because the distribution of residuals does not allow the application of parametric tests such as t-tests or linear regression. In such cases, as we are dealing with rank (ordinal) data, the application of a chi-square test is unwarranted and we need to use another test. There are different alternatives depending on whether the data are paired (coming from the same individuals) or if all observations are independent.\nThe non-parametric alternative for independent t-tests, i.e. for data where we are dealing with two separate groups and a numeric dependent variable that violates parametric assumptions (or an ordinal dependent variable), is the Mann-Whitney U-test. In contrast, if the groups under investigation represent identical participants that are tested under two conditions, the appropriate alternative is a Wilcoxon Signed Rank test (which is thus the alternative for paired t-test).\nImagine we wanted to determine if two language families differed with respect to the size of their phoneme inventories. You have already ranked the inventory sizes and would now like to now if language family correlates with inventory size. As such, we are dealing with two independent groups and we want to implement a non-parametric alternative of a t-test. To answer this question, you create the table shown below. ####\n\n\n\nThe Signed-Rank Test xxxxxxx. This xxxxxxx.\nIn this example, we will utilize the signed-rank test to analyze xxxxxx obtained across multiple measurement occasions for a sample of youth participating in the ABCD Study. Our primary objective is to understand xxxxxx, while factoring in the clustered nature of observations within individuals over time. The signed-rank test facilitates this by xxxxx.\n\n\n\n\n\nInstall PackagesLoad Packages\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"rstatix\",\"DT\", \"gtsummary\",\"easystats\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(rstatix)      # Pipe-friendly framework for basic statistical tests\nlibrary(DT)           # Rendering interactive data tables\nlibrary(easystats)    #\nlibrary(gtsummary)    #\n\n\n\n\n\n\n\n\n\n\nRead and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"anthroweightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    anthroweightcalc = as.numeric(anthroweightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n#####\n#Creating new ordinal variable for the example\ndf$education &lt;- factor(\n  with(df, ifelse(high.educ.bl %in% c(\"1st grade\", \"2nd grade\", \"3rd grade\", \"4th grade\",\n                                      \"5th grade\",\n                                      \"6th grade\", \"7th grade\", \"8th grade\", \"9th grade\",\n                                      \"10th grade\",\n                                      \"11th grade\", \"12th grade\"), \"lt_highschool\",\n                  ifelse(high.educ.bl == \"High school graduate\", \"highschool\",\n                  ifelse(high.educ.bl == \"GED or equivalent Diploma\", \"GED\",\n                  ifelse(high.educ.bl == \"Some college\", \"some_college\",\n                  ifelse(high.educ.bl %in% c(\"Associate degree: Academic Program\", \n                                              \"Associate degree: Occupational\"),\n                         \"associate_degree\",\n                  ifelse(high.educ.bl == \"Bachelor's degree (ex. BA\", \"Bachelor's_degree\",\n                  ifelse(high.educ.bl == \"Master's degree (ex. MA\", \"Master's_degree\",\n                  ifelse(high.educ.bl %in% c(\"Doctoral degree (ex. PhD\", \"Professional\n                                             School degree (ex. MD\"), \n                         \"Advanced_degree\", NA))))))))))\n  levels = c(\"lt_highschool\", \"highschool\", \"GED\", \"some_college\", \"associate_degree\",\n             \"Bachelor's_degree\", \"Master's_degree\", \"Advanced_degree\")\n  ordered = TRUE\n\n\n####\n\n####\ndf$income &lt;- factor(\n  with(df, ifelse(household.income.bl == \"Less than $5,000\", \"&lt;$5,000\",\n                  ifelse(household.income.bl == \"$5,000 through $11,999\", \"$5,000-$11,999\",\n                  ifelse(household.income.bl == \"$12,000 through $15,999\", \"$12,000-$15,999\",\n                  ifelse(household.income.bl == \"$16,000 through $24,999\", \"$16,000-$24,999\",\n                  ifelse(household.income.bl == \"$25,000 through $34,999\", \"$25,000-$34,999\",\n                  ifelse(household.income.bl == \"$35,000 through $49,999\", \"$35,000-$49,999\",\n                  ifelse(household.income.bl == \"$50,000 through $74,999\", \"$50,000-$74,999\",\n                  ifelse(household.income.bl == \"$75,000 through $99,999\", \"$75,000-$99,999\",\n                  ifelse(household.income.bl == \"$100,000 through $199,999\", \"$100,000-$199,999\",\n                  ifelse(household.income.bl == \"$200,000 and greater\", \"≥$200,000\",\n                  NA))))))))))),\n  levels = c(\"&lt;$5,000\", \"$5,000-$11,999\", \"$12,000-$15,999\", \"$16,000-$24,999\",\n             \"$25,000-$34,999\", \"$35,000-$49,999\", \"$50,000-$74,999\",\n             \"$75,000-$99,999\", \"$100,000-$199,999\", \"≥$200,000\"),\n  ordered = TRUE\n)\n\n####\n\n# Create a mapping from factor levels to numeric values\nincome_levels &lt;- c(\"Less than $5,000\", \"$5,000 through $11,999\", \"$12,000 through $15,999\", \"$16,000 through $24,999\", \"$25,000 through $34,999\", \"$35,000 through $49,999\", \"$50,000 through $74,999\", \"$75,000 through $99,999\", \"$100,000 through $199,999\", \"$200,000 and greater\", \"Don't know\", \"Refuse to answer\", \"No deseo responder\")\n\n# We assign numbers 1 through 10, but we have 12 levels, including \"Don't know\", \"Refuse to answer\", and \"No deseo responder\"\n# Let's assume \"Don't know\" and any refusal to answer will be treated as NA\nincome_numeric_values &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, NA, NA, NA)\n\n# Create a named vector for easy lookup\nincome_values &lt;- setNames(income_numeric_values, income_levels)\n\n# Convert the `income` factor to numeric using the named vector\ndf$income_numeric &lt;- income_values[as.character(df$household.income.bl)]\n\n# Handling NAs and refused to answer\ndf$income_numeric[is.na(df$household.income.bl) | df$household.income.bl %in% c(\"Don't know\", \"Refuse to answer\", \"No deseo responder\")] &lt;- NA\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, income_numeric, education) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", income_numeric ~ \"Income\", \n                 education ~ \"Education\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nIncome\n7.22 (2.42) )\n7.30 (2.38) )\n7.31 (2.36) )\n7.37 (2.32) )\n7.42 (2.26) )\n\n\nEducation\n\n\n\n\n\n\n\n    Advanced_degree\n3.5%\n3.6%\n3.7%\n3.8%\n3.8%\n\n\n    associate_degree\n8.0%\n8.0%\n7.9%\n8.0%\n7.6%\n\n\n    Bachelor's_degree\n31%\n31%\n32%\n32%\n33%\n\n\n    GED\n2.5%\n2.3%\n2.4%\n2.2%\n1.8%\n\n\n    highschool\n9.1%\n8.8%\n8.7%\n8.3%\n7.8%\n\n\n    lt_highschool\n7.2%\n6.7%\n6.6%\n6.2%\n6.1%\n\n\n    Master's_degree\n21%\n22%\n22%\n22%\n22%\n\n\n    some_college\n18%\n18%\n18%\n17%\n17%\n\n\n\n1 %; Mean (SD) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild ModelModel Plots\n\n\n\nThe code fits a xxxx to examine the ‘xxxxx’ variable across time points (‘eventname’). It incorporates xxxxxx. The results of the model are then printed to provide a detailed summary of the fitted model parameters.\nSTEP 1: Convert dataframe from long-to-wide format\n\n\nCode\n# Split the data into static (unchanging) and changing variables\n# Static variables are taken only from the baseline measurement occasion\ndf_static &lt;- df %&gt;%\n  filter(eventname == \"baseline_year_1_arm_1\") %&gt;%\n  select(src_subject_id, site_id_l, sex)\n\ndf_changing &lt;- df %&gt;%\n  select(src_subject_id, eventname, income_numeric, education)\n\n# Convert the changing variables from long format to wide format\ndf_wide_changing &lt;- df_changing %&gt;%\n  gather(variable, value, -src_subject_id, -eventname) %&gt;%\n  unite(\"variable_event\", variable, eventname) %&gt;%\n  spread(variable_event, value)\n\n# Merge the static and changing data frames based on the 'src_subject_id' variable\ndf_wide &lt;- df_static %&gt;%\n  left_join(df_wide_changing, by = \"src_subject_id\")\n\n# Rename columns to shorter names for easier reference\ndf_wide &lt;- df_wide %&gt;% \n        rename(\"income_numeric_0\"=\"income_numeric_baseline_year_1_arm_1\",\n               \"income_numeric_1\"=\"income_numeric_1_year_follow_up_y_arm_1\",\n               \"income_numeric_2\"=\"income_numeric_2_year_follow_up_y_arm_1\",\n               \"income_numeric_3\"=\"income_numeric_3_year_follow_up_y_arm_1\",\n               \"income_numeric_4\"=\"income_numeric_4_year_follow_up_y_arm_1\"\n               )\n\n# Reorder columns in the dataframe\ndf_wide &lt;- df_wide %&gt;% select(src_subject_id, site_id_l, sex, income_numeric_0, income_numeric_1, income_numeric_2, income_numeric_3, income_numeric_4)\n\n\nDescriptive Statistics for the Income Variable\n\n\nCode\n## Summary statistics\n# Compute summary statistics for Income by eventname\nsummary &lt;- df %&gt;%\n    group_by(eventname) %&gt;%\n    get_summary_stats(income_numeric, type = \"mean_sd\")\n\ndata.frame(summary)\n\n\n\n  \n\n\n\nThe summary statistics provide insights into the Weight variable across different eventname categories. At baseline, the average weight is approximately 7.224 units with a standard deviation of 2.423. Over the years, there’s a noticeable increase in average weight: by the first year, it’s about 7.299 units, and it continues to rise, reaching approximately 7.424 units by the fourth year. The standard deviation remains relatively consistent over the years, suggesting similar variability in weight measurements across these time points.\nSTEP 2: Compute Signed Rank Test\n\n\nCode\n#########\ndf_wide$income_numeric_0 &lt;- as.numeric(as.character(df_wide$income_numeric_0))\ndf_wide$income_numeric_1 &lt;- as.numeric(as.character(df_wide$income_numeric_1))\ndf_wide$income_numeric_4 &lt;- as.numeric(as.character(df_wide$income_numeric_4))\ndf_wide_complete &lt;- na.omit(df_wide[, c(\"income_numeric_0\", \"income_numeric_4\")])\n\nmodel &lt;- wilcox.test(df_wide_complete$income_numeric_0, df_wide_complete$income_numeric_4, paired = TRUE)\n\nreport(wilcox.test(df_wide_complete$income_numeric_0, df_wide_complete$income_numeric_4))\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_wide_complete$income_numeric_0 and df_wide_complete$income_numeric_4 suggests that the effect is positive, statistically\nnot significant, and tiny (W = 9.70e+06, p &gt; .999; r (rank biserial) = 0.00, 95% CI [-0.02, 0.02])\n\n\n\n\n\n\nTesttesttest\n\n\n\n\n\n\n\n\n\n\nWrite-up"
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#overview",
    "href": "examples/4_Examples_SignedRankTest.html#overview",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The Signed-Rank Test xxxxxxx. This xxxxxxx.\nIn this example, we will utilize the signed-rank test to analyze xxxxxx obtained across multiple measurement occasions for a sample of youth participating in the ABCD Study. Our primary objective is to understand xxxxxx, while factoring in the clustered nature of observations within individuals over time. The signed-rank test facilitates this by xxxxx."
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#preliminary-setup",
    "href": "examples/4_Examples_SignedRankTest.html#preliminary-setup",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Install PackagesLoad Packages\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"rstatix\",\"DT\", \"gtsummary\",\"easystats\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(rstatix)      # Pipe-friendly framework for basic statistical tests\nlibrary(DT)           # Rendering interactive data tables\nlibrary(easystats)    #\nlibrary(gtsummary)    #"
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#descriptives-overview",
    "href": "examples/4_Examples_SignedRankTest.html#descriptives-overview",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Read and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"anthroweightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    anthroweightcalc = as.numeric(anthroweightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n#####\n#Creating new ordinal variable for the example\ndf$education &lt;- factor(\n  with(df, ifelse(high.educ.bl %in% c(\"1st grade\", \"2nd grade\", \"3rd grade\", \"4th grade\",\n                                      \"5th grade\",\n                                      \"6th grade\", \"7th grade\", \"8th grade\", \"9th grade\",\n                                      \"10th grade\",\n                                      \"11th grade\", \"12th grade\"), \"lt_highschool\",\n                  ifelse(high.educ.bl == \"High school graduate\", \"highschool\",\n                  ifelse(high.educ.bl == \"GED or equivalent Diploma\", \"GED\",\n                  ifelse(high.educ.bl == \"Some college\", \"some_college\",\n                  ifelse(high.educ.bl %in% c(\"Associate degree: Academic Program\", \n                                              \"Associate degree: Occupational\"),\n                         \"associate_degree\",\n                  ifelse(high.educ.bl == \"Bachelor's degree (ex. BA\", \"Bachelor's_degree\",\n                  ifelse(high.educ.bl == \"Master's degree (ex. MA\", \"Master's_degree\",\n                  ifelse(high.educ.bl %in% c(\"Doctoral degree (ex. PhD\", \"Professional\n                                             School degree (ex. MD\"), \n                         \"Advanced_degree\", NA))))))))))\n  levels = c(\"lt_highschool\", \"highschool\", \"GED\", \"some_college\", \"associate_degree\",\n             \"Bachelor's_degree\", \"Master's_degree\", \"Advanced_degree\")\n  ordered = TRUE\n\n\n####\n\n####\ndf$income &lt;- factor(\n  with(df, ifelse(household.income.bl == \"Less than $5,000\", \"&lt;$5,000\",\n                  ifelse(household.income.bl == \"$5,000 through $11,999\", \"$5,000-$11,999\",\n                  ifelse(household.income.bl == \"$12,000 through $15,999\", \"$12,000-$15,999\",\n                  ifelse(household.income.bl == \"$16,000 through $24,999\", \"$16,000-$24,999\",\n                  ifelse(household.income.bl == \"$25,000 through $34,999\", \"$25,000-$34,999\",\n                  ifelse(household.income.bl == \"$35,000 through $49,999\", \"$35,000-$49,999\",\n                  ifelse(household.income.bl == \"$50,000 through $74,999\", \"$50,000-$74,999\",\n                  ifelse(household.income.bl == \"$75,000 through $99,999\", \"$75,000-$99,999\",\n                  ifelse(household.income.bl == \"$100,000 through $199,999\", \"$100,000-$199,999\",\n                  ifelse(household.income.bl == \"$200,000 and greater\", \"≥$200,000\",\n                  NA))))))))))),\n  levels = c(\"&lt;$5,000\", \"$5,000-$11,999\", \"$12,000-$15,999\", \"$16,000-$24,999\",\n             \"$25,000-$34,999\", \"$35,000-$49,999\", \"$50,000-$74,999\",\n             \"$75,000-$99,999\", \"$100,000-$199,999\", \"≥$200,000\"),\n  ordered = TRUE\n)\n\n####\n\n# Create a mapping from factor levels to numeric values\nincome_levels &lt;- c(\"Less than $5,000\", \"$5,000 through $11,999\", \"$12,000 through $15,999\", \"$16,000 through $24,999\", \"$25,000 through $34,999\", \"$35,000 through $49,999\", \"$50,000 through $74,999\", \"$75,000 through $99,999\", \"$100,000 through $199,999\", \"$200,000 and greater\", \"Don't know\", \"Refuse to answer\", \"No deseo responder\")\n\n# We assign numbers 1 through 10, but we have 12 levels, including \"Don't know\", \"Refuse to answer\", and \"No deseo responder\"\n# Let's assume \"Don't know\" and any refusal to answer will be treated as NA\nincome_numeric_values &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, NA, NA, NA)\n\n# Create a named vector for easy lookup\nincome_values &lt;- setNames(income_numeric_values, income_levels)\n\n# Convert the `income` factor to numeric using the named vector\ndf$income_numeric &lt;- income_values[as.character(df$household.income.bl)]\n\n# Handling NAs and refused to answer\ndf$income_numeric[is.na(df$household.income.bl) | df$household.income.bl %in% c(\"Don't know\", \"Refuse to answer\", \"No deseo responder\")] &lt;- NA\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, income_numeric, education) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", income_numeric ~ \"Income\", \n                 education ~ \"Education\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nIncome\n7.22 (2.42) )\n7.30 (2.38) )\n7.31 (2.36) )\n7.37 (2.32) )\n7.42 (2.26) )\n\n\nEducation\n\n\n\n\n\n\n\n    Advanced_degree\n3.5%\n3.6%\n3.7%\n3.8%\n3.8%\n\n\n    associate_degree\n8.0%\n8.0%\n7.9%\n8.0%\n7.6%\n\n\n    Bachelor's_degree\n31%\n31%\n32%\n32%\n33%\n\n\n    GED\n2.5%\n2.3%\n2.4%\n2.2%\n1.8%\n\n\n    highschool\n9.1%\n8.8%\n8.7%\n8.3%\n7.8%\n\n\n    lt_highschool\n7.2%\n6.7%\n6.6%\n6.2%\n6.1%\n\n\n    Master's_degree\n21%\n22%\n22%\n22%\n22%\n\n\n    some_college\n18%\n18%\n18%\n17%\n17%\n\n\n\n1 %; Mean (SD) )"
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#results",
    "href": "examples/4_Examples_SignedRankTest.html#results",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Build ModelModel Plots\n\n\n\nThe code fits a xxxx to examine the ‘xxxxx’ variable across time points (‘eventname’). It incorporates xxxxxx. The results of the model are then printed to provide a detailed summary of the fitted model parameters.\nSTEP 1: Convert dataframe from long-to-wide format\n\n\nCode\n# Split the data into static (unchanging) and changing variables\n# Static variables are taken only from the baseline measurement occasion\ndf_static &lt;- df %&gt;%\n  filter(eventname == \"baseline_year_1_arm_1\") %&gt;%\n  select(src_subject_id, site_id_l, sex)\n\ndf_changing &lt;- df %&gt;%\n  select(src_subject_id, eventname, income_numeric, education)\n\n# Convert the changing variables from long format to wide format\ndf_wide_changing &lt;- df_changing %&gt;%\n  gather(variable, value, -src_subject_id, -eventname) %&gt;%\n  unite(\"variable_event\", variable, eventname) %&gt;%\n  spread(variable_event, value)\n\n# Merge the static and changing data frames based on the 'src_subject_id' variable\ndf_wide &lt;- df_static %&gt;%\n  left_join(df_wide_changing, by = \"src_subject_id\")\n\n# Rename columns to shorter names for easier reference\ndf_wide &lt;- df_wide %&gt;% \n        rename(\"income_numeric_0\"=\"income_numeric_baseline_year_1_arm_1\",\n               \"income_numeric_1\"=\"income_numeric_1_year_follow_up_y_arm_1\",\n               \"income_numeric_2\"=\"income_numeric_2_year_follow_up_y_arm_1\",\n               \"income_numeric_3\"=\"income_numeric_3_year_follow_up_y_arm_1\",\n               \"income_numeric_4\"=\"income_numeric_4_year_follow_up_y_arm_1\"\n               )\n\n# Reorder columns in the dataframe\ndf_wide &lt;- df_wide %&gt;% select(src_subject_id, site_id_l, sex, income_numeric_0, income_numeric_1, income_numeric_2, income_numeric_3, income_numeric_4)\n\n\nDescriptive Statistics for the Income Variable\n\n\nCode\n## Summary statistics\n# Compute summary statistics for Income by eventname\nsummary &lt;- df %&gt;%\n    group_by(eventname) %&gt;%\n    get_summary_stats(income_numeric, type = \"mean_sd\")\n\ndata.frame(summary)\n\n\n\n  \n\n\n\nThe summary statistics provide insights into the Weight variable across different eventname categories. At baseline, the average weight is approximately 7.224 units with a standard deviation of 2.423. Over the years, there’s a noticeable increase in average weight: by the first year, it’s about 7.299 units, and it continues to rise, reaching approximately 7.424 units by the fourth year. The standard deviation remains relatively consistent over the years, suggesting similar variability in weight measurements across these time points.\nSTEP 2: Compute Signed Rank Test\n\n\nCode\n#########\ndf_wide$income_numeric_0 &lt;- as.numeric(as.character(df_wide$income_numeric_0))\ndf_wide$income_numeric_1 &lt;- as.numeric(as.character(df_wide$income_numeric_1))\ndf_wide$income_numeric_4 &lt;- as.numeric(as.character(df_wide$income_numeric_4))\ndf_wide_complete &lt;- na.omit(df_wide[, c(\"income_numeric_0\", \"income_numeric_4\")])\n\nmodel &lt;- wilcox.test(df_wide_complete$income_numeric_0, df_wide_complete$income_numeric_4, paired = TRUE)\n\nreport(wilcox.test(df_wide_complete$income_numeric_0, df_wide_complete$income_numeric_4))\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_wide_complete$income_numeric_0 and df_wide_complete$income_numeric_4 suggests that the effect is positive, statistically\nnot significant, and tiny (W = 9.70e+06, p &gt; .999; r (rank biserial) = 0.00, 95% CI [-0.02, 0.02])\n\n\n\n\n\n\nTesttesttest"
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#wrapping-up",
    "href": "examples/4_Examples_SignedRankTest.html#wrapping-up",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Write-up"
  },
  {
    "objectID": "examples/10_Examples_LatentGrowthCurveModels.html",
    "href": "examples/10_Examples_LatentGrowthCurveModels.html",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "Latent growth curve models (LGCM) are an analytical tool within the framework of structural equation modeling that enable the examination of change over time. This model type effectively separates the true trajectory of a variable from random measurement error, allowing for the estimation of an underlying growth process. The primary components of LGCM include the intercept, which represents the initial status, and the slope, which reflects the rate of change over time.\nThis example investigates a growth trajectory of participant’s height, measured across 4 annual assessments in participants from the ABCD Study. Fitting the latent growth curve model will allow for an examination of the initial status (intercept) and rate of change (slope) of height from baseline through successive yearly follow-ups. Each participant’s height trajectory is modeled to capture both the starting point and the growth pattern over time. The results are illustrated through growth plots that demonstrate the mean trajectory across the cohort, along with the variability in growth rates among individuals, providing insights into the developmental patterns of height over time."
  },
  {
    "objectID": "examples/10_Examples_LatentGrowthCurveModels.html#overview",
    "href": "examples/10_Examples_LatentGrowthCurveModels.html#overview",
    "title": "Latent Growth Curve Models",
    "section": "",
    "text": "Latent growth curve models (LGCM) are an analytical tool within the framework of structural equation modeling that enable the examination of change over time. This model type effectively separates the true trajectory of a variable from random measurement error, allowing for the estimation of an underlying growth process. The primary components of LGCM include the intercept, which represents the initial status, and the slope, which reflects the rate of change over time.\nThis example investigates a growth trajectory of participant’s height, measured across 4 annual assessments in participants from the ABCD Study. Fitting the latent growth curve model will allow for an examination of the initial status (intercept) and rate of change (slope) of height from baseline through successive yearly follow-ups. Each participant’s height trajectory is modeled to capture both the starting point and the growth pattern over time. The results are illustrated through growth plots that demonstrate the mean trajectory across the cohort, along with the variability in growth rates among individuals, providing insights into the developmental patterns of height over time."
  },
  {
    "objectID": "examples/10_Examples_LatentGrowthCurveModels.html#preliminary-setup",
    "href": "examples/10_Examples_LatentGrowthCurveModels.html#preliminary-setup",
    "title": "Latent Growth Curve Models",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nLoad Packages\n\n\nCode\nlibrary(tidyverse) # Collection of R packages for data science\nlibrary(gtsummary) # Publication-ready tables\nlibrary(rstatix) # Statistical Tests in tidy format\nlibrary(lavaan) # Structural Equation Modeling in R\n\n\n\n\nDescriptives\n\n\nCode\ndescriptives_table &lt;- df_long %&gt;%\n    select(event, height) %&gt;%\n    mutate(event = factor(event)) %&gt;%\n    tbl_summary(\n        by = event,\n        missing = \"no\",\n        label = list(height ~ \"Height\"),\n        statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n    ) %&gt;%\n    modify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n    bold_labels() %&gt;%\n    italicize_levels() %&gt;%\n    modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 28181\nYear_1\nN = 28181\nYear_2\nN = 28181\nYear_3\nN = 28181\n\n\n\n\nHeight\n55.1 (3.6) )\n57.5 (3.7) )\n60.3 (3.6) )\n62.3 (4.1) )\n\n\n\n1 Mean (SD) )"
  },
  {
    "objectID": "examples/10_Examples_LatentGrowthCurveModels.html#results",
    "href": "examples/10_Examples_LatentGrowthCurveModels.html#results",
    "title": "Latent Growth Curve Models",
    "section": "Results",
    "text": "Results\n\nCompute Latent Growth Curve Model\nThe code below is used to compute a growth curve model to investigate changes in height across four annual assessments. This statistical approach provides insights into how much individuals vary around the average trajectory and the consistency of their growth patterns across time. This model estimates an overall intercept, representing the initial status, and a slope that captures the rate of growth across time points.\n\n\nCode\n# Reshape data from long to wide format\ndf_wide &lt;- df_long %&gt;%\n    pivot_wider(\n        id_cols = c(id),\n        names_from = event,\n        values_from = height,\n        names_prefix = \"Height_\"\n    )\n\ndf_wide &lt;- na.omit(df_wide)\n\nmodel &lt;- \" i =~ 1*Height_Baseline + 1*Height_Year_1 + 1*Height_Year_2 + 1*Height_Year_3\n           s =~ 0*Height_Baseline + 1*Height_Year_1 + 2*Height_Year_2 + 3*Height_Year_3\n\n           # Intercept and slope variances\n           i ~~ i\n           s ~~ s\n\n           # Residual variances for each observed variable\n           Height_Baseline ~~ var_baseline*Height_Baseline\n           Height_Year_1 ~~ var_year1*Height_Year_1\n           Height_Year_2 ~~ var_year2*Height_Year_2\n           Height_Year_3 ~~ var_year3*Height_Year_3\n\"\n\nfit &lt;- growth(model, data = df_wide)\nsummary(fit)\n\n\nlavaan 0.6.16 ended normally after 97 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         9\n\n  Number of observations                          2818\n\nModel Test User Model:\n                                                      \n  Test statistic                               126.998\n  Degrees of freedom                                 5\n  P-value (Chi-square)                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i =~                                                \n    Height_Baselin    1.000                           \n    Height_Year_1     1.000                           \n    Height_Year_2     1.000                           \n    Height_Year_3     1.000                           \n  s =~                                                \n    Height_Baselin    0.000                           \n    Height_Year_1     1.000                           \n    Height_Year_2     2.000                           \n    Height_Year_3     3.000                           \n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  i ~~                                                \n    s                -0.118    0.089   -1.319    0.187\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .Height_Baselin    0.000                           \n   .Height_Year_1     0.000                           \n   .Height_Year_2     0.000                           \n   .Height_Year_3     0.000                           \n    i                55.157    0.065  846.256    0.000\n    s                 2.491    0.020  122.967    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    i                 9.391    0.334   28.080    0.000\n    s                 0.310    0.040    7.697    0.000\n   .Hght_Bs (vr_b)    3.489    0.182   19.214    0.000\n   .Hgh_Y_1 (vr_1)    3.870    0.132   29.282    0.000\n   .Hgh_Y_2 (vr_2)    2.089    0.100   20.972    0.000\n   .Hgh_Y_3 (vr_3)    6.297    0.234   26.963    0.000\n\n\nThe results from the latent growth curve analysis show an increasing pattern of mean change in participant’s height across assessments (slope = 2.491, p&lt;.001). In addition, the model identified significant variability in both the intercept (estimate = 9.39, se=.33, p&lt;.001), which represents initial height and the slope (estimate = .31, se=.04, p&lt;.001), which measures growth over time. This indicates substantial differences in starting heights and growth rates among individuals. The covariance between the intercept and slope was not statistically significant (estimate = -.11, p = .18), suggesting initial height does not influence the rate of growth.\n\n\nModel Plots\n\n\nCode\n# Plotting the height data over time from the df_long dataframe\nggplot(df_long, aes(x = event, y = height, group = id)) +\n    geom_line(alpha = 0.4, aes(color = \"Actual Height\"), size = 0.5) + # Lines to connect data points for each participant\n    geom_point(alpha = 0.6, color = \"blue\") + # Points for actual heights\n    scale_x_discrete(limits = c(\"Baseline\", \"Year_1\", \"Year_2\", \"Year_3\")) + # Ensuring the order of events\n    labs(\n        title = \"Actual Height Growth Across Timepoints\",\n        x = \"Time (Years from Baseline)\",\n        y = \"Height (inches)\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"bottom\") # Adjust legend position\n\n\n\n\n\n\n\n\n\nThis plot visualizes the height trajectories across four annual timepoints. Each line represents an individual participant’s height trajectory showing overall trends while maintaining focus on individual variations. Blue points mark the actual height measurements at each timepoint, providing a clear view of the data distribution and growth patterns over time. This graph highlights both the general trend of increasing height and the individual differences in growth rates among participants."
  },
  {
    "objectID": "examples/10_Examples_LatentGrowthCurveModels.html#wrapping-up",
    "href": "examples/10_Examples_LatentGrowthCurveModels.html#wrapping-up",
    "title": "Latent Growth Curve Models",
    "section": "Wrapping Up",
    "text": "Wrapping Up\nThis analysis employed a latent growth curve model (LGCM) framework to examine participants’ heights across multiple assessment points. Results revealed an increasing trend in average height changes over time, with a slope parameter of 2.49 (p&lt;.001), indicating a steady growth across all assessments. Significant variability was observed both in the intercept, with an estimate of 9.39 (se = .33, p&lt;.001), representing the initial height, and in the slope, with an estimate of .31 (se = .04, p&lt;.001), which measures growth over time. This highlights notable individual differences in starting heights and growth rates. Furthermore, the lack of a statistically significant covariance between the intercept and slope (estimate = -.11, p = .18) suggests that the initial height does not influence subsequent growth rates.\nLatent growth curve modeling provides a powerful tool for evaluating patterns of growth, allowing for the differentiation between average growth trajectories and individual variability. This method is able to parse out complex relationships, underscoring its utility in longitudinal data analysis, enhancing our interpretation of how individuals change over time."
  }
]