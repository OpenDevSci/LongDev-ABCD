[
  {
    "objectID": "examples/4_Examples_SignedRankTest.html",
    "href": "examples/4_Examples_SignedRankTest.html",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "It is actually quite common that numeric depend variables need to be transformed or converted into ranks, i.e. ordinal variables, because the distribution of residuals does not allow the application of parametric tests such as t-tests or linear regression. In such cases, as we are dealing with rank (ordinal) data, the application of a chi-square test is unwarranted and we need to use another test. There are different alternatives depending on whether the data are paired (coming from the same individuals) or if all observations are independent.\nThe non-parametric alternative for independent t-tests, i.e. for data where we are dealing with two separate groups and a numeric dependent variable that violates parametric assumptions (or an ordinal dependent variable), is the Mann-Whitney U-test. In contrast, if the groups under investigation represent identical participants that are tested under two conditions, the appropriate alternative is a Wilcoxon Signed Rank test (which is thus the alternative for paired t-test).\nImagine we wanted to determine if two language families differed with respect to the size of their phoneme inventories. You have already ranked the inventory sizes and would now like to now if language family correlates with inventory size. As such, we are dealing with two independent groups and we want to implement a non-parametric alternative of a t-test. To answer this question, you create the table shown below. ####\n\n\n\n\nThe Signed-Rank Test xxxxxxx. This xxxxxxx.\nIn this example, we will utilize the signed-rank test to analyze xxxxxx obtained across multiple measurement occasions for a sample of youth participating in the ABCD Study. Our primary objective is to understand xxxxxx, while factoring in the clustered nature of observations within individuals over time. The signed-rank test facilitates this by xxxxx.\n\n\n\n\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"rstatix\",\"DT\", \"gtsummary\",\"easystats\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(rstatix)      # Pipe-friendly framework for basic statistical tests\nlibrary(DT)           # Rendering interactive data tables\nlibrary(easystats)    #\nlibrary(gtsummary)    #\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)\n\n\n\n\n\n\n\n\n\n\nRead and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"anthroweightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    anthroweightcalc = as.numeric(anthroweightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n#####\n#Creating new ordinal variable for the example\ndf$education &lt;- factor(\n  with(df, ifelse(high.educ.bl %in% c(\"1st grade\", \"2nd grade\", \"3rd grade\", \"4th grade\",\n                                      \"5th grade\",\n                                      \"6th grade\", \"7th grade\", \"8th grade\", \"9th grade\",\n                                      \"10th grade\",\n                                      \"11th grade\", \"12th grade\"), \"lt_highschool\",\n                  ifelse(high.educ.bl == \"High school graduate\", \"highschool\",\n                  ifelse(high.educ.bl == \"GED or equivalent Diploma\", \"GED\",\n                  ifelse(high.educ.bl == \"Some college\", \"some_college\",\n                  ifelse(high.educ.bl %in% c(\"Associate degree: Academic Program\", \n                                              \"Associate degree: Occupational\"),\n                         \"associate_degree\",\n                  ifelse(high.educ.bl == \"Bachelor's degree (ex. BA\", \"Bachelor's_degree\",\n                  ifelse(high.educ.bl == \"Master's degree (ex. MA\", \"Master's_degree\",\n                  ifelse(high.educ.bl %in% c(\"Doctoral degree (ex. PhD\", \"Professional\n                                             School degree (ex. MD\"), \n                         \"Advanced_degree\", NA))))))))))\n  levels = c(\"lt_highschool\", \"highschool\", \"GED\", \"some_college\", \"associate_degree\",\n             \"Bachelor's_degree\", \"Master's_degree\", \"Advanced_degree\")\n  ordered = TRUE\n\n\n####\n\n####\ndf$income &lt;- factor(\n  with(df, ifelse(household.income.bl == \"Less than $5,000\", \"&lt;$5,000\",\n                  ifelse(household.income.bl == \"$5,000 through $11,999\", \"$5,000-$11,999\",\n                  ifelse(household.income.bl == \"$12,000 through $15,999\", \"$12,000-$15,999\",\n                  ifelse(household.income.bl == \"$16,000 through $24,999\", \"$16,000-$24,999\",\n                  ifelse(household.income.bl == \"$25,000 through $34,999\", \"$25,000-$34,999\",\n                  ifelse(household.income.bl == \"$35,000 through $49,999\", \"$35,000-$49,999\",\n                  ifelse(household.income.bl == \"$50,000 through $74,999\", \"$50,000-$74,999\",\n                  ifelse(household.income.bl == \"$75,000 through $99,999\", \"$75,000-$99,999\",\n                  ifelse(household.income.bl == \"$100,000 through $199,999\", \"$100,000-$199,999\",\n                  ifelse(household.income.bl == \"$200,000 and greater\", \"≥$200,000\",\n                  NA))))))))))),\n  levels = c(\"&lt;$5,000\", \"$5,000-$11,999\", \"$12,000-$15,999\", \"$16,000-$24,999\",\n             \"$25,000-$34,999\", \"$35,000-$49,999\", \"$50,000-$74,999\",\n             \"$75,000-$99,999\", \"$100,000-$199,999\", \"≥$200,000\"),\n  ordered = TRUE\n)\n\n####\n\n# Create a mapping from factor levels to numeric values\nincome_levels &lt;- c(\"Less than $5,000\", \"$5,000 through $11,999\", \"$12,000 through $15,999\", \"$16,000 through $24,999\", \"$25,000 through $34,999\", \"$35,000 through $49,999\", \"$50,000 through $74,999\", \"$75,000 through $99,999\", \"$100,000 through $199,999\", \"$200,000 and greater\", \"Don't know\", \"Refuse to answer\", \"No deseo responder\")\n\n# We assign numbers 1 through 10, but we have 12 levels, including \"Don't know\", \"Refuse to answer\", and \"No deseo responder\"\n# Let's assume \"Don't know\" and any refusal to answer will be treated as NA\nincome_numeric_values &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, NA, NA, NA)\n\n# Create a named vector for easy lookup\nincome_values &lt;- setNames(income_numeric_values, income_levels)\n\n# Convert the `income` factor to numeric using the named vector\ndf$income_numeric &lt;- income_values[as.character(df$household.income.bl)]\n\n# Handling NAs and refused to answer\ndf$income_numeric[is.na(df$household.income.bl) | df$household.income.bl %in% c(\"Don't know\", \"Refuse to answer\", \"No deseo responder\")] &lt;- NA\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, income_numeric, education) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", income_numeric ~ \"Income\", \n                 education ~ \"Education\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nIncome\n7.22 (2.42) )\n7.30 (2.38) )\n7.31 (2.36) )\n7.37 (2.32) )\n7.42 (2.26) )\n\n\nEducation\n\n\n\n\n\n\n\n    Advanced_degree\n3.5%\n3.6%\n3.7%\n3.8%\n3.8%\n\n\n    associate_degree\n8.0%\n8.0%\n7.9%\n8.0%\n7.6%\n\n\n    Bachelor's_degree\n31%\n31%\n32%\n32%\n33%\n\n\n    GED\n2.5%\n2.3%\n2.4%\n2.2%\n1.8%\n\n\n    highschool\n9.1%\n8.8%\n8.7%\n8.3%\n7.8%\n\n\n    lt_highschool\n7.2%\n6.7%\n6.6%\n6.2%\n6.1%\n\n\n    Master's_degree\n21%\n22%\n22%\n22%\n22%\n\n\n    some_college\n18%\n18%\n18%\n17%\n17%\n\n\n\n1 %; Mean (SD) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild ModelModel Plots\n\n\n\nThe code fits a xxxx to examine the ‘xxxxx’ variable across time points (‘eventname’). It incorporates xxxxxx. The results of the model are then printed to provide a detailed summary of the fitted model parameters.\nSTEP 1: Convert dataframe from long-to-wide format\n\n\nCode\n# Split the data into static (unchanging) and changing variables\n# Static variables are taken only from the baseline measurement occasion\ndf_static &lt;- df %&gt;%\n  filter(eventname == \"baseline_year_1_arm_1\") %&gt;%\n  select(src_subject_id, site_id_l, sex)\n\ndf_changing &lt;- df %&gt;%\n  select(src_subject_id, eventname, income_numeric, education)\n\n# Convert the changing variables from long format to wide format\ndf_wide_changing &lt;- df_changing %&gt;%\n  gather(variable, value, -src_subject_id, -eventname) %&gt;%\n  unite(\"variable_event\", variable, eventname) %&gt;%\n  spread(variable_event, value)\n\n# Merge the static and changing data frames based on the 'src_subject_id' variable\ndf_wide &lt;- df_static %&gt;%\n  left_join(df_wide_changing, by = \"src_subject_id\")\n\n# Rename columns to shorter names for easier reference\ndf_wide &lt;- df_wide %&gt;% \n        rename(\"income_numeric_0\"=\"income_numeric_baseline_year_1_arm_1\",\n               \"income_numeric_1\"=\"income_numeric_1_year_follow_up_y_arm_1\",\n               \"income_numeric_2\"=\"income_numeric_2_year_follow_up_y_arm_1\",\n               \"income_numeric_3\"=\"income_numeric_3_year_follow_up_y_arm_1\",\n               \"income_numeric_4\"=\"income_numeric_4_year_follow_up_y_arm_1\"\n               )\n\n# Reorder columns in the dataframe\ndf_wide &lt;- df_wide %&gt;% select(src_subject_id, site_id_l, sex, income_numeric_0, income_numeric_1, income_numeric_2, income_numeric_3, income_numeric_4)\n\n\nDescriptive Statistics for the Income Variable\n\n\nCode\n## Summary statistics\n# Compute summary statistics for Income by eventname\nsummary &lt;- df %&gt;%\n    group_by(eventname) %&gt;%\n    get_summary_stats(income_numeric, type = \"mean_sd\")\n\ndata.frame(summary)\n\n\n\n  \n\n\n\nThe summary statistics provide insights into the Weight variable across different eventname categories. At baseline, the average weight is approximately 7.224 units with a standard deviation of 2.423. Over the years, there’s a noticeable increase in average weight: by the first year, it’s about 7.299 units, and it continues to rise, reaching approximately 7.424 units by the fourth year. The standard deviation remains relatively consistent over the years, suggesting similar variability in weight measurements across these time points.\nSTEP 2: Compute Signed Rank Test\n\n\nCode\n#########\ndf_wide$income_numeric_0 &lt;- as.numeric(as.character(df_wide$income_numeric_0))\ndf_wide$income_numeric_1 &lt;- as.numeric(as.character(df_wide$income_numeric_1))\ndf_wide$income_numeric_4 &lt;- as.numeric(as.character(df_wide$income_numeric_4))\ndf_wide_complete &lt;- na.omit(df_wide[, c(\"income_numeric_0\", \"income_numeric_4\")])\n\nmodel &lt;- wilcox.test(df_wide_complete$income_numeric_0, df_wide_complete$income_numeric_4, paired = TRUE)\n\nreport(wilcox.test(df_wide_complete$income_numeric_0, df_wide_complete$income_numeric_4))\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_wide_complete$income_numeric_0 and df_wide_complete$income_numeric_4 suggests that the effect is positive, statistically\nnot significant, and tiny (W = 9.70e+06, p &gt; .999; r (rank biserial) = 0.00, 95% CI [-0.02, 0.02])\n\n\n\n\n\n\nTesttesttest\n\n\n\n\n\n\n\n\n\n\nWrite-up"
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#overview",
    "href": "examples/4_Examples_SignedRankTest.html#overview",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "The Signed-Rank Test xxxxxxx. This xxxxxxx.\nIn this example, we will utilize the signed-rank test to analyze xxxxxx obtained across multiple measurement occasions for a sample of youth participating in the ABCD Study. Our primary objective is to understand xxxxxx, while factoring in the clustered nature of observations within individuals over time. The signed-rank test facilitates this by xxxxx."
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#preliminary-setup",
    "href": "examples/4_Examples_SignedRankTest.html#preliminary-setup",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Install PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"rstatix\",\"DT\", \"gtsummary\",\"easystats\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(rstatix)      # Pipe-friendly framework for basic statistical tests\nlibrary(DT)           # Rendering interactive data tables\nlibrary(easystats)    #\nlibrary(gtsummary)    #\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#descriptives-overview",
    "href": "examples/4_Examples_SignedRankTest.html#descriptives-overview",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Read and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"anthroweightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    anthroweightcalc = as.numeric(anthroweightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n#####\n#Creating new ordinal variable for the example\ndf$education &lt;- factor(\n  with(df, ifelse(high.educ.bl %in% c(\"1st grade\", \"2nd grade\", \"3rd grade\", \"4th grade\",\n                                      \"5th grade\",\n                                      \"6th grade\", \"7th grade\", \"8th grade\", \"9th grade\",\n                                      \"10th grade\",\n                                      \"11th grade\", \"12th grade\"), \"lt_highschool\",\n                  ifelse(high.educ.bl == \"High school graduate\", \"highschool\",\n                  ifelse(high.educ.bl == \"GED or equivalent Diploma\", \"GED\",\n                  ifelse(high.educ.bl == \"Some college\", \"some_college\",\n                  ifelse(high.educ.bl %in% c(\"Associate degree: Academic Program\", \n                                              \"Associate degree: Occupational\"),\n                         \"associate_degree\",\n                  ifelse(high.educ.bl == \"Bachelor's degree (ex. BA\", \"Bachelor's_degree\",\n                  ifelse(high.educ.bl == \"Master's degree (ex. MA\", \"Master's_degree\",\n                  ifelse(high.educ.bl %in% c(\"Doctoral degree (ex. PhD\", \"Professional\n                                             School degree (ex. MD\"), \n                         \"Advanced_degree\", NA))))))))))\n  levels = c(\"lt_highschool\", \"highschool\", \"GED\", \"some_college\", \"associate_degree\",\n             \"Bachelor's_degree\", \"Master's_degree\", \"Advanced_degree\")\n  ordered = TRUE\n\n\n####\n\n####\ndf$income &lt;- factor(\n  with(df, ifelse(household.income.bl == \"Less than $5,000\", \"&lt;$5,000\",\n                  ifelse(household.income.bl == \"$5,000 through $11,999\", \"$5,000-$11,999\",\n                  ifelse(household.income.bl == \"$12,000 through $15,999\", \"$12,000-$15,999\",\n                  ifelse(household.income.bl == \"$16,000 through $24,999\", \"$16,000-$24,999\",\n                  ifelse(household.income.bl == \"$25,000 through $34,999\", \"$25,000-$34,999\",\n                  ifelse(household.income.bl == \"$35,000 through $49,999\", \"$35,000-$49,999\",\n                  ifelse(household.income.bl == \"$50,000 through $74,999\", \"$50,000-$74,999\",\n                  ifelse(household.income.bl == \"$75,000 through $99,999\", \"$75,000-$99,999\",\n                  ifelse(household.income.bl == \"$100,000 through $199,999\", \"$100,000-$199,999\",\n                  ifelse(household.income.bl == \"$200,000 and greater\", \"≥$200,000\",\n                  NA))))))))))),\n  levels = c(\"&lt;$5,000\", \"$5,000-$11,999\", \"$12,000-$15,999\", \"$16,000-$24,999\",\n             \"$25,000-$34,999\", \"$35,000-$49,999\", \"$50,000-$74,999\",\n             \"$75,000-$99,999\", \"$100,000-$199,999\", \"≥$200,000\"),\n  ordered = TRUE\n)\n\n####\n\n# Create a mapping from factor levels to numeric values\nincome_levels &lt;- c(\"Less than $5,000\", \"$5,000 through $11,999\", \"$12,000 through $15,999\", \"$16,000 through $24,999\", \"$25,000 through $34,999\", \"$35,000 through $49,999\", \"$50,000 through $74,999\", \"$75,000 through $99,999\", \"$100,000 through $199,999\", \"$200,000 and greater\", \"Don't know\", \"Refuse to answer\", \"No deseo responder\")\n\n# We assign numbers 1 through 10, but we have 12 levels, including \"Don't know\", \"Refuse to answer\", and \"No deseo responder\"\n# Let's assume \"Don't know\" and any refusal to answer will be treated as NA\nincome_numeric_values &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, NA, NA, NA)\n\n# Create a named vector for easy lookup\nincome_values &lt;- setNames(income_numeric_values, income_levels)\n\n# Convert the `income` factor to numeric using the named vector\ndf$income_numeric &lt;- income_values[as.character(df$household.income.bl)]\n\n# Handling NAs and refused to answer\ndf$income_numeric[is.na(df$household.income.bl) | df$household.income.bl %in% c(\"Don't know\", \"Refuse to answer\", \"No deseo responder\")] &lt;- NA\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, income_numeric, education) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", income_numeric ~ \"Income\", \n                 education ~ \"Education\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nIncome\n7.22 (2.42) )\n7.30 (2.38) )\n7.31 (2.36) )\n7.37 (2.32) )\n7.42 (2.26) )\n\n\nEducation\n\n\n\n\n\n\n\n    Advanced_degree\n3.5%\n3.6%\n3.7%\n3.8%\n3.8%\n\n\n    associate_degree\n8.0%\n8.0%\n7.9%\n8.0%\n7.6%\n\n\n    Bachelor's_degree\n31%\n31%\n32%\n32%\n33%\n\n\n    GED\n2.5%\n2.3%\n2.4%\n2.2%\n1.8%\n\n\n    highschool\n9.1%\n8.8%\n8.7%\n8.3%\n7.8%\n\n\n    lt_highschool\n7.2%\n6.7%\n6.6%\n6.2%\n6.1%\n\n\n    Master's_degree\n21%\n22%\n22%\n22%\n22%\n\n\n    some_college\n18%\n18%\n18%\n17%\n17%\n\n\n\n1 %; Mean (SD) )"
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#results",
    "href": "examples/4_Examples_SignedRankTest.html#results",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Build ModelModel Plots\n\n\n\nThe code fits a xxxx to examine the ‘xxxxx’ variable across time points (‘eventname’). It incorporates xxxxxx. The results of the model are then printed to provide a detailed summary of the fitted model parameters.\nSTEP 1: Convert dataframe from long-to-wide format\n\n\nCode\n# Split the data into static (unchanging) and changing variables\n# Static variables are taken only from the baseline measurement occasion\ndf_static &lt;- df %&gt;%\n  filter(eventname == \"baseline_year_1_arm_1\") %&gt;%\n  select(src_subject_id, site_id_l, sex)\n\ndf_changing &lt;- df %&gt;%\n  select(src_subject_id, eventname, income_numeric, education)\n\n# Convert the changing variables from long format to wide format\ndf_wide_changing &lt;- df_changing %&gt;%\n  gather(variable, value, -src_subject_id, -eventname) %&gt;%\n  unite(\"variable_event\", variable, eventname) %&gt;%\n  spread(variable_event, value)\n\n# Merge the static and changing data frames based on the 'src_subject_id' variable\ndf_wide &lt;- df_static %&gt;%\n  left_join(df_wide_changing, by = \"src_subject_id\")\n\n# Rename columns to shorter names for easier reference\ndf_wide &lt;- df_wide %&gt;% \n        rename(\"income_numeric_0\"=\"income_numeric_baseline_year_1_arm_1\",\n               \"income_numeric_1\"=\"income_numeric_1_year_follow_up_y_arm_1\",\n               \"income_numeric_2\"=\"income_numeric_2_year_follow_up_y_arm_1\",\n               \"income_numeric_3\"=\"income_numeric_3_year_follow_up_y_arm_1\",\n               \"income_numeric_4\"=\"income_numeric_4_year_follow_up_y_arm_1\"\n               )\n\n# Reorder columns in the dataframe\ndf_wide &lt;- df_wide %&gt;% select(src_subject_id, site_id_l, sex, income_numeric_0, income_numeric_1, income_numeric_2, income_numeric_3, income_numeric_4)\n\n\nDescriptive Statistics for the Income Variable\n\n\nCode\n## Summary statistics\n# Compute summary statistics for Income by eventname\nsummary &lt;- df %&gt;%\n    group_by(eventname) %&gt;%\n    get_summary_stats(income_numeric, type = \"mean_sd\")\n\ndata.frame(summary)\n\n\n\n  \n\n\n\nThe summary statistics provide insights into the Weight variable across different eventname categories. At baseline, the average weight is approximately 7.224 units with a standard deviation of 2.423. Over the years, there’s a noticeable increase in average weight: by the first year, it’s about 7.299 units, and it continues to rise, reaching approximately 7.424 units by the fourth year. The standard deviation remains relatively consistent over the years, suggesting similar variability in weight measurements across these time points.\nSTEP 2: Compute Signed Rank Test\n\n\nCode\n#########\ndf_wide$income_numeric_0 &lt;- as.numeric(as.character(df_wide$income_numeric_0))\ndf_wide$income_numeric_1 &lt;- as.numeric(as.character(df_wide$income_numeric_1))\ndf_wide$income_numeric_4 &lt;- as.numeric(as.character(df_wide$income_numeric_4))\ndf_wide_complete &lt;- na.omit(df_wide[, c(\"income_numeric_0\", \"income_numeric_4\")])\n\nmodel &lt;- wilcox.test(df_wide_complete$income_numeric_0, df_wide_complete$income_numeric_4, paired = TRUE)\n\nreport(wilcox.test(df_wide_complete$income_numeric_0, df_wide_complete$income_numeric_4))\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Wilcoxon rank sum test with continuity correction testing the difference in ranks between df_wide_complete$income_numeric_0 and df_wide_complete$income_numeric_4 suggests that the effect is positive, statistically\nnot significant, and tiny (W = 9.70e+06, p &gt; .999; r (rank biserial) = 0.00, 95% CI [-0.02, 0.02])\n\n\n\n\n\n\nTesttesttest"
  },
  {
    "objectID": "examples/4_Examples_SignedRankTest.html#wrapping-up",
    "href": "examples/4_Examples_SignedRankTest.html#wrapping-up",
    "title": "Signed-Rank Test",
    "section": "",
    "text": "Write-up"
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html",
    "href": "examples/3a_Examples_LinearMixedModels.html",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "",
    "text": "The LMM:ri is similar to traditional (fixed-effect) linear regression extending on this approach by including a subject-specific random-effect that allows each participant to have their own unique intercept value, in addition to the overall mean-level (fixed-effect) intercept value zzzzt\nIn this example, we will use the LMM:ri to analyze trajectories of height obtained across multiple measurement occasions in a sample of youth taking part in the ABCD Study. Our primary aim is to characterize stability and change in height assessments, while accounting for observations that are clustered within youth over time. To do so, we will use the LMM:ri to simultaneously model an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory."
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#overview",
    "href": "examples/3a_Examples_LinearMixedModels.html#overview",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "",
    "text": "The LMM:ri is similar to traditional (fixed-effect) linear regression extending on this approach by including a subject-specific random-effect that allows each participant to have their own unique intercept value, in addition to the overall mean-level (fixed-effect) intercept value zzzzt\nIn this example, we will use the LMM:ri to analyze trajectories of height obtained across multiple measurement occasions in a sample of youth taking part in the ABCD Study. Our primary aim is to characterize stability and change in height assessments, while accounting for observations that are clustered within youth over time. To do so, we will use the LMM:ri to simultaneously model an overall sample mean trajectory (fixed effect) and subject-specific (random) effects that vary randomly about the sample mean trajectory."
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#preliminary-setup",
    "href": "examples/3a_Examples_LinearMixedModels.html#preliminary-setup",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"easystats\",\"lme4\",\"gtsummary\",\"report\",\"broom\",\"gridExtra\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(easystats)    # Collection of R packages statistical modeling, visualization, and reporting\nlibrary(lme4)         # Linear mixed-effects models\nlibrary(gtsummary)    # Publication-ready tables\nlibrary(report)       # Easy reporting of regression analyses\nlibrary(broom)        # Tidy and augment statistical models output\nlibrary(gridExtra)    # Arrange multiple grid-based plots on a page\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#descriptives-overview",
    "href": "examples/3a_Examples_LinearMixedModels.html#descriptives-overview",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Descriptives Overview",
    "text": "Descriptives Overview\n\nRead and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"nihtbx_totalcomp_fc\", \"anthroweightcalc\", \"anthroheightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),\n    anthroweightcalc = as.numeric(anthroweightcalc),\n    anthroheightcalc = as.numeric(anthroheightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, hisp, anthroweightcalc) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", hisp ~ \"Hispanic\", \n                 anthroweightcalc ~ \"Weight\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nHispanic\n21%\n20%\n20%\n20%\n21%\n\n\nWeight\n83 (24) )\n94 (28) )\n109 (49) )\n123 (38) )\n139 (111) )\n\n\n\n1 %; Mean (SD) )"
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#results",
    "href": "examples/3a_Examples_LinearMixedModels.html#results",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Results",
    "text": "Results\n\nBuild ModelModel Plots\n\n\n\nThe code fits a linear mixed model to predict the ‘Height’ variable based on time points (‘eventname’) and handedness (‘Handedness’), while accounting for individual-level variability by including random intercepts for each participant (‘src_subject_id’). The results of the model are then printed to provide a summary of the fitted model parameters.\nSTEP 1: Compute LMM Model with Random Intercepts\n\n\nCode\n## Linear Mixed Model with a random intercept (LMM-ri)\nmodel &lt;- lmer(anthroweightcalc ~ 1 + eventname + sex + (1|src_subject_id), data = df, REML=T)\n\n\n\n\ntesting\n## Output and reports extending from the LMM-ri analyses\n#summary(model)\n#confint(model, level = 0.95, method = \"Wald\")\n\nmodel_performance(model)\n\n\n\n  \n\n\n\ntesting\nmodel_parameters(model)\n\n\n\n  \n\n\n\ntesting\nmodel_parameters(model,standardize = \"refit\")\n\n\n\n  \n\n\n\nThe code provided executes a linear mixed model (LMM) to predict children’s height across different time points (Baseline, Year_1, Year_2, Year_3, and Year_4), and also takes into account their sex. This model accounts for individual variability in height by including a random intercept for each subject (src_subject_id). The output indicates that the model was fit using the REML (Restricted Maximum Likelihood) criterion.\n\n\n\n\nThe following set of plots are used to facilitate model diagnostics. The first is a histogram showcasing the distribution of random intercepts for individual subjects, indicating variations in height not explained by the fixed effects. The second depicts residuals versus fitted values, helping assess the model’s fit and potential heteroscedasticity. The third contrasts observed and predicted height values across different time points, offering a side-by-side evaluation of the model’s predictions against actual observations.\n\n\nCode\n# Extract the random effects\nrandom_effects &lt;- ranef(model)[[1]]\n\n# Convert to dataframe\nrandom_effects_df &lt;- data.frame(Intercept = random_effects$`(Intercept)`)\n\n# Plot 1: Histogram\nhist_plot &lt;- ggplot(random_effects_df, aes(x = Intercept)) +\n  geom_histogram(aes(y = ..density..), bins = 30, color = \"black\", fill = \"lightblue\") + labs(title = \"Histogram of Random Effects\", x = \"Random Intercept Values\", y = \"Density\") +\n  theme_minimal()\n\n# Plot 2: Residuals vs Fitted Values\nresid_plot &lt;- ggplot(NULL, aes(x = fitted_values, y = residuals)) +\n  geom_point(alpha = 0.5) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(title = \"Residuals vs Fitted Values\", x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n\nCode\nlibrary(ggplot2)\ntheme_set(theme_modern(base_size = 6))\n\nplot(parameters(model)) +\n  ggplot2::labs(title = \"A Dot-and-Whisker Plot\")\n\n\n\n\n\n\n\n\n\nCode\n#plot(model)\n\nresult &lt;- estimate_expectation(model, data = \"grid\")\nplot(result)\n\n\n\n\n\n\n\n\n\nCode\n#plot(result, type = \"qq\")\n#plot(result, type = \"pp\")\n\nnormality &lt;- check_normality(model, effects = \"random\")\n#plot(normality)\n\nheteroscedasticity &lt;- check_heteroscedasticity(model)\n#plot(heteroscedasticity)\n\nhomogeneity &lt;- check_homogeneity(model)\n#plot(homogeneity, type = \"density\")\n\ndistribution &lt;- check_distribution(model)\n#plot(distribution)\n\n#contrasts &lt;- estimate_contrasts(model, contrast = \"sex\")\n#means &lt;- estimate_means(model)\n#plot(means)\n#plot(contrasts, means)\n\nparams &lt;- model_parameters(model, effects = \"fixed\")\n#plot(params, show_labels = TRUE, size_text = 4)\n\n#check_model(model)\n\n\n\n\n\nCode\n# Extract the data frame used in the model\nmodel_data &lt;- model@frame\n\n# Extract unique subject IDs from the model's data\noriginal_subject_ids &lt;- unique(model_data$src_subject_id)\n\n# Subset the original data to include only those subjects\ndf_subset &lt;- df %&gt;% filter(src_subject_id %in% original_subject_ids)\n\neventname_map &lt;- c(\n  \"baseline_year_1_arm_1\" = \"Baseline\",\n  \"1_year_follow_up_y_arm_1\" = \"Year_1\",\n  \"2_year_follow_up_y_arm_1\" = \"Year_2\",\n  \"3_year_follow_up_y_arm_1\" = \"Year_3\",\n  \"4_year_follow_up_y_arm_1\" = \"Year_4\"\n)\n\n# Apply the recoding to the eventname variable\ndf_subset$eventname &lt;- factor(df_subset$eventname, levels = names(eventname_map), labels = eventname_map)\n\n# Verify the recoding\ntable(df_subset$eventname)\n\n\n\nBaseline   Year_1   Year_2   Year_3   Year_4 \n   11867    11220    10973    10336     4754 \n\n\nCode\n# Generate the plot\nggplot(df_subset, aes(x = eventname, y = anthroheightcalc, group = src_subject_id)) +\n  # Individual estimated height trajectories in faded lines\n  geom_line(aes(group = src_subject_id), alpha = 0.3, color = \"grey50\") +\n  # Overall group-mean trajectory in blue with increased thickness\n  stat_summary(aes(group = 1), fun = mean, geom = \"line\", color = \"blue\", linewidth = 1) +\n  labs(title = \"Individual and Group-Mean Height Trajectories\",\n       x = \"Event Name\",\n       y = \"Height\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nreport(model)\n\n\nWe fitted a linear mixed model (estimated using REML and nloptwrap optimizer) to predict anthroweightcalc with eventname and sex (formula: anthroweightcalc ~ 1 + eventname + sex). The model included src_subject_id as\nrandom effect (formula: ~1 | src_subject_id). The model's total explanatory power is substantial (conditional R2 = 0.39) and the part related to the fixed effects alone (marginal R2) is of 0.12. The model's intercept,\ncorresponding to eventname = and sex = Female, is at 110.77 (95% CI [109.81, 111.72], t(37534) = 227.91, p &lt; .001). Within this model:\n\n  - The effect of eventname [linear] is statistically significant and positive (beta = 45.14, 95% CI [43.97, 46.30], t(37534) = 76.01, p &lt; .001; Std. beta = 0.90, 95% CI [0.88, 0.93])\n  - The effect of eventname [quadratic] is statistically significant and positive (beta = 2.63, 95% CI [1.57, 3.68], t(37534) = 4.87, p &lt; .001; Std. beta = 0.05, 95% CI [0.03, 0.07])\n  - The effect of eventname [cubic] is statistically non-significant and positive (beta = 0.22, 95% CI [-1.10, 1.53], t(37534) = 0.32, p = 0.748; Std. beta = 4.32e-03, 95% CI [-0.02, 0.03])\n  - The effect of eventname [4th degree] is statistically non-significant and positive (beta = 0.92, 95% CI [-0.18, 2.03], t(37534) = 1.64, p = 0.102; Std. beta = 0.02, 95% CI [-3.66e-03, 0.04])\n  - The effect of sex [Male or other] is statistically significant and negative (beta = -2.14, 95% CI [-3.37, -0.91], t(37534) = -3.42, p &lt; .001; Std. beta = -0.04, 95% CI [-0.07, -0.02])\n\nStandardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using a Wald t-distribution approximation."
  },
  {
    "objectID": "examples/3a_Examples_LinearMixedModels.html#wrapping-up",
    "href": "examples/3a_Examples_LinearMixedModels.html#wrapping-up",
    "title": "Linear Mixed Models: Random Intercept",
    "section": "Wrapping Up",
    "text": "Wrapping Up\n\n\n\nWrite-up\n\n\n\nThe estimate of the random intercept was 110.767 (SE 0.486). The fixed effects section provides the coefficients for the intercept, eventname, and the sex variable.\nThe linear mixed model analysis was conducted to predict children’s height across different time points (Baseline, Year_1, Year_2, Year_3, and Year_4) using the event name (eventname) and height (Height) variables. The intercept, corresponding to the reference levels of the predictors is estimated at 110.767 units, and this effect is highly significant. Regarding sex, boys show an increase in height of about -2.139 (SE 0.486) units compared to girls.\n\n\nCode\nreport_performance(model)\n\n\nThe model's total explanatory power is substantial (conditional R2 = 0.39) and the part related to the fixed effects alone (marginal R2) is of 0.12"
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "This example assesses whether growth in a subsample of ABCD participants from Baseline (T0) to the 1-Year follow-up (T1) differs significantly based on handedness, using height (“anthroheightcalc”) as a representative metric of growth. The analysis is conducted in two primary steps: 1) a difference score is calculated between baseline and Year_1 height measurements for each participant; 2) a simple regression analysis is used to test whether sex (boy, girl) predicts the average difference value in participants height from baseline to the 1-Year follow-up. Finally, a visual inspection is further conducted via a violin plot to graphically represent the relationship between difference scores and sex. The ensuing analysis and interpretations are detailed in the subsequent sections.\n\n\n\n\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# rm(list = ls())\n\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"easystats\",\"lme4\",\"gtsummary\",\"report\",\"broom\",\"gridExtra\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(easystats)    # Collection of R packages statistical modeling, visualization, and reporting\nlibrary(rstatix)      # Pipe-friendly framework for performing common stats\nlibrary(gtsummary)    # Publication-ready tables\nlibrary(report)       # Easy reporting of regression analyses\nlibrary(broom)        # Tidy and augment statistical models output\nlibrary(gridExtra)    # Arrange multiple grid-based plots on a page\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)\n\n\n\n\n\n\n\n\n\n\nRead and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"nihtbx_totalcomp_fc\", \"anthroweightcalc\", \"anthroheightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),\n    anthroweightcalc = as.numeric(anthroweightcalc),\n    anthroheightcalc = as.numeric(anthroheightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, hisp, anthroweightcalc) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", hisp ~ \"Hispanic\", \n                 anthroweightcalc ~ \"Weight\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nHispanic\n21%\n20%\n20%\n20%\n21%\n\n\nWeight\n83 (24) )\n94 (28) )\n109 (49) )\n123 (38) )\n139 (111) )\n\n\n\n1 %; Mean (SD) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild Model: Step 1Build Model: Step 2Model Plots\n\n\n\nThe code snippet below tells R to compute a difference score by subtracting each participant’s height at T1 from their height at T0. Relevant summary statistics are also provided.\nSTEP 1: Compute Difference Score\n\n\nCode\n# Define the function to compute difference scores for a given variable and provide a summary\n# Function to compute difference scores for a given variable and provide a summary\ncompute_difference_and_summary &lt;- function(df, variable_name) {\n    # Define the event names of interest\n    baseline_event &lt;- \"baseline_year_1_arm_1\"\n    followup_event &lt;- \"1_year_follow_up_y_arm_1\"\n\n    # Compute the difference between Baseline and Year 1 data for the given variable\n    diff_data &lt;- df %&gt;%\n        filter(eventname %in% c(baseline_event, followup_event)) %&gt;% # Filter for specific event names\n        select(src_subject_id, eventname, all_of(variable_name)) %&gt;% # Select required columns\n        spread(eventname, variable_name) %&gt;% # Convert data from long to wide format\n        mutate(diff = get(followup_event) - get(baseline_event)) %&gt;% # Compute difference between the two time points\n        drop_na(diff) # Exclude rows with NA in the computed difference\n\n    # Summarize the computed difference scores\n    diff_summary &lt;- summary(diff_data$diff)\n\n    # Return the difference data and its summary\n    list(data = diff_data, summary = diff_summary)\n}\n\n# List of variables for which difference scores are to be computed\nvariables_of_interest &lt;- c(\"anthroheightcalc\")\n\n# Compute and store difference scores and summaries for each variable in a list\ndifference_and_summary_list &lt;- lapply(variables_of_interest, function(var) {\n    compute_difference_and_summary(df, var)\n})\n\n# Extract the difference data for the 'anthroheightcalc' variable\nheight_diff_data &lt;- difference_and_summary_list[[1]]$data\n\n# Merge the 'diff' column back to the main df using 'src_subject_id' as the key\ndf &lt;- left_join(df, height_diff_data %&gt;% select(src_subject_id, diff), by = \"src_subject_id\")\n\n\nDescriptive Statistics for the Difference Score\n\n\nCode\n# Compute statistical summaries for the difference score variable\nlapply(difference_and_summary_list, function(item) {\n    print(item$summary)\n})\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  -51.9     1.8     2.2     2.4     3.0    67.0 \n\n\n[[1]]\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  -51.9     1.8     2.2     2.4     3.0    67.0 \n\n\nThis summary of the difference score variable indicates that the differences range from a decrease of -51.875 units to an increase of 67 units. The median difference is 2.25 units, and the average difference is approximately 2.3660611 units. There are 0 missing values in this difference score dataset.\nDescriptive Statistics for the Height Variable\n\n\nCode\n## Summary statistics\n# Compute summary statistics for Height by eventname\nsummary &lt;- df %&gt;%\n    group_by(eventname) %&gt;%\n    get_summary_stats(anthroheightcalc, type = \"mean_sd\")\n\ndata.frame(summary)\n\n\n\n  \n\n\n\nThe summary statistics provide insights into the Height variable across different eventname categories. At baseline, the average height is approximately 55.241 units with a standard deviation of 3.331. Over the years, there’s a noticeable increase in average height: by the first year, it’s about 57.595 units, and it continues to rise, reaching approximately 64.694 units by the fourth year. The standard deviation remains relatively consistent over the years, suggesting similar variability in height measurements across these time points.\n\n\n\n\nA simple regression analyses is conducted to examine whether a grouping variable (sex) significantly predicts the difference score value (indicating significant group differences in the average difference score).\nSTEP 2: Conduct regression on Difference Score\n\n\nCode\n# Merge the 'sex' variable from the original dataframe 'df' to 'height_diff_data'\nmerged_data &lt;- height_diff_data %&gt;%\n  left_join(df %&gt;% select(src_subject_id, sex), by = \"src_subject_id\")\n\n# Ensure 'sex' is a factor\nmerged_data$sex &lt;- as.factor(merged_data$sex)\n\n# Run the regression\nmodel &lt;- lm(diff ~ sex, data = merged_data)\n\n# Get the summary of the regression model\nmodel_summary &lt;- summary(model)\n\nmodel_summary\n\n\n\nCall:\nlm(formula = diff ~ sex, data = merged_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-54.41  -0.59  -0.11   0.47  64.47 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        2.5308     0.0167   151.8   &lt;2e-16 ***\nsexMale or other  -0.3376     0.0230   -14.7   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.51 on 47586 degrees of freedom\nMultiple R-squared:  0.00449,   Adjusted R-squared:  0.00447 \nF-statistic:  215 on 1 and 47586 DF,  p-value: &lt;2e-16\n\n\nThis regression analysis evaluates whether sex (boy, girl) predicts the average difference in participants’ height from baseline to the 1-Year follow-up. The output from our model provides:\n\nan F-statistic of 214.6560227;\ndegrees of freedom of 47586;\na parameter estimate of -0.3376126;\nstandard error of 0.0230434;\np-value of 1.6900378^{-48}.\n\nCompared to boys (the reference group), girls have an average increase in height difference of approximately -0.338 units. This effect was marginally significant with a p-value of 0. Overall, the model explained a very small portion of the variance in height difference, with an adjusted R-squared value of 0.00447, and the overall model significance was not statistically significant with a p-value of 1.6900378^{-48}.\n\n\n\n\n\n\ntesting\n# Visualize the difference scores across different levels of sex\n\n# Create a violin plot to show the distribution of difference scores by sex\n# Jittered points are added to provide a more granular view of individual observations\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\n# Merge the 'sex' variable from the original dataframe 'df' to 'height_diff_data'\nmerged_data &lt;- height_diff_data %&gt;%\n  left_join(df %&gt;% select(src_subject_id, sex), by = \"src_subject_id\")\n\n# Plotting using ggplot2\nggplot(merged_data, aes(x = sex, y = diff, fill = sex)) +\n  geom_violin() +\n  geom_jitter(position = position_jitter(width = 0.2), size = 1, alpha = 0.5) +\n  scale_fill_brewer(palette = \"Set2\") + \n  labs(\n    title = \"Difference Scores by Sex\",\n    x = \"Sex\",\n    y = \"Difference Score\"\n  ) +\n  theme_minimal() + \n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\nThe violin plot visualizes the distribution of difference scores in children’s heights by their sex: Right, Left, and Mixed. Each violin shape provides insight into the density of the data at different height differences, with wider sections representing higher densities of data points. Superimposed jittered points offer a granular view of individual observations. From the plot, it appears that the distributions of height differences across the three handedness categories are somewhat similar, though there might be subtle variations in median and spread.\n\n\n\n\n\n\n\n\nWrite-up\n\n\n\nDifferences in children’s heights between baseline and a subsequent 1-year follow-up, we sought to understand the potential influence of sex on this difference. Descriptive statistics revealed that height differences ranged from a decrease of -51.875 units to an increase of 67 units, with a median difference of 2.25 units and an average difference of approximately 2.3542189 units. Subsequent regression analysis indicated that, when compared to boys, girls had an average increase in height difference of approximately -0.338 units, though this effect was marginally significant (p = 0). Complementary to these findings, violin plots visually underscored the subtle variations in height differences across sex categories, suggesting broadly similar distributions but with nuanced variations in central tendency and spread. In conclusion, while sex exhibited a potential influence on height difference over the year, the observed effect was notably minor."
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#overview",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#overview",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "This example assesses whether growth in a subsample of ABCD participants from Baseline (T0) to the 1-Year follow-up (T1) differs significantly based on handedness, using height (“anthroheightcalc”) as a representative metric of growth. The analysis is conducted in two primary steps: 1) a difference score is calculated between baseline and Year_1 height measurements for each participant; 2) a simple regression analysis is used to test whether sex (boy, girl) predicts the average difference value in participants height from baseline to the 1-Year follow-up. Finally, a visual inspection is further conducted via a violin plot to graphically represent the relationship between difference scores and sex. The ensuing analysis and interpretations are detailed in the subsequent sections."
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#preliminary-setup",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#preliminary-setup",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Install PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# rm(list = ls())\n\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"easystats\",\"lme4\",\"gtsummary\",\"report\",\"broom\",\"gridExtra\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(easystats)    # Collection of R packages statistical modeling, visualization, and reporting\nlibrary(rstatix)      # Pipe-friendly framework for performing common stats\nlibrary(gtsummary)    # Publication-ready tables\nlibrary(report)       # Easy reporting of regression analyses\nlibrary(broom)        # Tidy and augment statistical models output\nlibrary(gridExtra)    # Arrange multiple grid-based plots on a page\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#descriptives-overview",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#descriptives-overview",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Read and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"nihtbx_totalcomp_fc\", \"anthroweightcalc\", \"anthroheightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),\n    anthroweightcalc = as.numeric(anthroweightcalc),\n    anthroheightcalc = as.numeric(anthroheightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, hisp, anthroweightcalc) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", hisp ~ \"Hispanic\", \n                 anthroweightcalc ~ \"Weight\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nHispanic\n21%\n20%\n20%\n20%\n21%\n\n\nWeight\n83 (24) )\n94 (28) )\n109 (49) )\n123 (38) )\n139 (111) )\n\n\n\n1 %; Mean (SD) )"
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#results",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#results",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Build Model: Step 1Build Model: Step 2Model Plots\n\n\n\nThe code snippet below tells R to compute a difference score by subtracting each participant’s height at T1 from their height at T0. Relevant summary statistics are also provided.\nSTEP 1: Compute Difference Score\n\n\nCode\n# Define the function to compute difference scores for a given variable and provide a summary\n# Function to compute difference scores for a given variable and provide a summary\ncompute_difference_and_summary &lt;- function(df, variable_name) {\n    # Define the event names of interest\n    baseline_event &lt;- \"baseline_year_1_arm_1\"\n    followup_event &lt;- \"1_year_follow_up_y_arm_1\"\n\n    # Compute the difference between Baseline and Year 1 data for the given variable\n    diff_data &lt;- df %&gt;%\n        filter(eventname %in% c(baseline_event, followup_event)) %&gt;% # Filter for specific event names\n        select(src_subject_id, eventname, all_of(variable_name)) %&gt;% # Select required columns\n        spread(eventname, variable_name) %&gt;% # Convert data from long to wide format\n        mutate(diff = get(followup_event) - get(baseline_event)) %&gt;% # Compute difference between the two time points\n        drop_na(diff) # Exclude rows with NA in the computed difference\n\n    # Summarize the computed difference scores\n    diff_summary &lt;- summary(diff_data$diff)\n\n    # Return the difference data and its summary\n    list(data = diff_data, summary = diff_summary)\n}\n\n# List of variables for which difference scores are to be computed\nvariables_of_interest &lt;- c(\"anthroheightcalc\")\n\n# Compute and store difference scores and summaries for each variable in a list\ndifference_and_summary_list &lt;- lapply(variables_of_interest, function(var) {\n    compute_difference_and_summary(df, var)\n})\n\n# Extract the difference data for the 'anthroheightcalc' variable\nheight_diff_data &lt;- difference_and_summary_list[[1]]$data\n\n# Merge the 'diff' column back to the main df using 'src_subject_id' as the key\ndf &lt;- left_join(df, height_diff_data %&gt;% select(src_subject_id, diff), by = \"src_subject_id\")\n\n\nDescriptive Statistics for the Difference Score\n\n\nCode\n# Compute statistical summaries for the difference score variable\nlapply(difference_and_summary_list, function(item) {\n    print(item$summary)\n})\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  -51.9     1.8     2.2     2.4     3.0    67.0 \n\n\n[[1]]\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  -51.9     1.8     2.2     2.4     3.0    67.0 \n\n\nThis summary of the difference score variable indicates that the differences range from a decrease of -51.875 units to an increase of 67 units. The median difference is 2.25 units, and the average difference is approximately 2.3660611 units. There are 0 missing values in this difference score dataset.\nDescriptive Statistics for the Height Variable\n\n\nCode\n## Summary statistics\n# Compute summary statistics for Height by eventname\nsummary &lt;- df %&gt;%\n    group_by(eventname) %&gt;%\n    get_summary_stats(anthroheightcalc, type = \"mean_sd\")\n\ndata.frame(summary)\n\n\n\n  \n\n\n\nThe summary statistics provide insights into the Height variable across different eventname categories. At baseline, the average height is approximately 55.241 units with a standard deviation of 3.331. Over the years, there’s a noticeable increase in average height: by the first year, it’s about 57.595 units, and it continues to rise, reaching approximately 64.694 units by the fourth year. The standard deviation remains relatively consistent over the years, suggesting similar variability in height measurements across these time points.\n\n\n\n\nA simple regression analyses is conducted to examine whether a grouping variable (sex) significantly predicts the difference score value (indicating significant group differences in the average difference score).\nSTEP 2: Conduct regression on Difference Score\n\n\nCode\n# Merge the 'sex' variable from the original dataframe 'df' to 'height_diff_data'\nmerged_data &lt;- height_diff_data %&gt;%\n  left_join(df %&gt;% select(src_subject_id, sex), by = \"src_subject_id\")\n\n# Ensure 'sex' is a factor\nmerged_data$sex &lt;- as.factor(merged_data$sex)\n\n# Run the regression\nmodel &lt;- lm(diff ~ sex, data = merged_data)\n\n# Get the summary of the regression model\nmodel_summary &lt;- summary(model)\n\nmodel_summary\n\n\n\nCall:\nlm(formula = diff ~ sex, data = merged_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-54.41  -0.59  -0.11   0.47  64.47 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        2.5308     0.0167   151.8   &lt;2e-16 ***\nsexMale or other  -0.3376     0.0230   -14.7   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.51 on 47586 degrees of freedom\nMultiple R-squared:  0.00449,   Adjusted R-squared:  0.00447 \nF-statistic:  215 on 1 and 47586 DF,  p-value: &lt;2e-16\n\n\nThis regression analysis evaluates whether sex (boy, girl) predicts the average difference in participants’ height from baseline to the 1-Year follow-up. The output from our model provides:\n\nan F-statistic of 214.6560227;\ndegrees of freedom of 47586;\na parameter estimate of -0.3376126;\nstandard error of 0.0230434;\np-value of 1.6900378^{-48}.\n\nCompared to boys (the reference group), girls have an average increase in height difference of approximately -0.338 units. This effect was marginally significant with a p-value of 0. Overall, the model explained a very small portion of the variance in height difference, with an adjusted R-squared value of 0.00447, and the overall model significance was not statistically significant with a p-value of 1.6900378^{-48}.\n\n\n\n\n\n\ntesting\n# Visualize the difference scores across different levels of sex\n\n# Create a violin plot to show the distribution of difference scores by sex\n# Jittered points are added to provide a more granular view of individual observations\n# Load necessary libraries\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(RColorBrewer)\n\n# Merge the 'sex' variable from the original dataframe 'df' to 'height_diff_data'\nmerged_data &lt;- height_diff_data %&gt;%\n  left_join(df %&gt;% select(src_subject_id, sex), by = \"src_subject_id\")\n\n# Plotting using ggplot2\nggplot(merged_data, aes(x = sex, y = diff, fill = sex)) +\n  geom_violin() +\n  geom_jitter(position = position_jitter(width = 0.2), size = 1, alpha = 0.5) +\n  scale_fill_brewer(palette = \"Set2\") + \n  labs(\n    title = \"Difference Scores by Sex\",\n    x = \"Sex\",\n    y = \"Difference Score\"\n  ) +\n  theme_minimal() + \n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"none\"\n  )\n\n\n\n\n\n\n\n\n\nThe violin plot visualizes the distribution of difference scores in children’s heights by their sex: Right, Left, and Mixed. Each violin shape provides insight into the density of the data at different height differences, with wider sections representing higher densities of data points. Superimposed jittered points offer a granular view of individual observations. From the plot, it appears that the distributions of height differences across the three handedness categories are somewhat similar, though there might be subtle variations in median and spread."
  },
  {
    "objectID": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#wrapping-up",
    "href": "examples/1b_Examples_DifferenceScores_SimpleRegression.html#wrapping-up",
    "title": "Difference Scores: Simple Regression",
    "section": "",
    "text": "Write-up\n\n\n\nDifferences in children’s heights between baseline and a subsequent 1-year follow-up, we sought to understand the potential influence of sex on this difference. Descriptive statistics revealed that height differences ranged from a decrease of -51.875 units to an increase of 67 units, with a median difference of 2.25 units and an average difference of approximately 2.3542189 units. Subsequent regression analysis indicated that, when compared to boys, girls had an average increase in height difference of approximately -0.338 units, though this effect was marginally significant (p = 0). Complementary to these findings, violin plots visually underscored the subtle variations in height differences across sex categories, suggesting broadly similar distributions but with nuanced variations in central tendency and spread. In conclusion, while sex exhibited a potential influence on height difference over the year, the observed effect was notably minor."
  },
  {
    "objectID": "manuscript/manuscript.html",
    "href": "manuscript/manuscript.html",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "The Adolescent Brain Cognitive Development (ABCD) Study® is the largest longitudinal investigation of neurodevelopment and child health in the United States. Conceived and initiated by the National Institutes of Health (NIH), this landmark prospective longitudinal study aims to transform our understanding of the genetic and environmental factors impacting neurodevelopment and their roles in behavioral and health outcomes across ten years of adolescence (Volkow et al. (2018)). At its heart, the study is designed to chart the course of human development across multiple interacting domains from late childhood to early adulthood and to identify factors that lead to both positive and negative outcomes. Central to achieving these goals is the commitment of the ABCD Study© and its NIH funders to an open science framework, intended to facilitate sharing of data and analytical methods by espousing practices that increase access, integrity, and reproducibility of scientific research. In this context, the ABCD Study is a collaboration with the broader research community.\nThe size and scope of the ABCD Study data allow the research community to perform a large variety of developmental analyses of both substantive and methodological interest, presenting a unique opportunity to significantly advance our understanding of how a multitude of biopsychosocial processes unfold across critical periods of development. In this paper, we describe models and methods for longitudinal analysis of ABCD Study data that can address these fundamental scientific aims, including: 1) characterization of the genetic and environmental factors associated with variation in developmental trajectories; 2) assessment of how the level and timing of exposures may impact subsequent neurodevelopment; 3) quantification of how variation in developmental domains may be associated with outcomes, including mediation models and reciprocal relationships. We instantiate these longitudinal analyses in worked examples using the ABCD Release 5.0 data with accompanying R scripts. Worked examples are available in Quarto files, accessible in the project’s GitHub repository\n\n\nThe ABCD Study enrolled a cohort of n=11,880 participants born between 2006-2008 and aged between 9-10 years at baseline, each with a parent/guardian. The study sample was recruited from household populations in defined catchment areas for each of the 21 (originally 22) study sites across the United States. Information regarding funding agencies, recruitment sites, investigators, and project organizations can be obtained at https://abcdstudy.org. The ABCD Study design is described in more detail in Garavan et al. (2018) and Dick et al. (2021).\nThe ABCD Study is currently collecting longitudinal data on a rich variety of outcomes that will enable the construction of complex statistical models, potentially incorporating factors from many domains. Each new wave of data collection provides another building block for characterizing developmental trajectories and implementing longitudinal analyses that allow researchers to characterize normative development, to identify variables that presage deviations from normative development, and to assess a range of variables associated with biopsychosocial outcomes of interest. These data include: 1) a neurocognitive battery (Luciana et al. (2018); Wesley K. Thompson et al. (2019)); 2) mental and physical health assessments (Barch et al. (2018)); 3) measures of culture and environment (Gonzalez et al. (2021); Zucker et al. (2018)); 4) substance use (Lisdahl et al. (2021)); 5) gender identity and sexual health (Potter et al. (2022)); 6) biospecimens (Uban et al. (2018)); 7) structural and functional brain imaging (Casey et al. (2018); Hagler et al. (2019); Palmer et al. (2022)); 8) geolocation-based environmental exposure data (Fan et al. (2021)); 9) wearables and mobile technology (Bagot et al. (2018)); and 10) whole-genome genotyping (Loughnan et al. (2020)). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual brief telephone or online assessments.\nData are publicly released approximately annually, currently through the NIMH Data Archive (NDA). The study’s earliest data releases consisted primarily of one or two visits per participant. However, the most recent public release as of the writing of this paper (Release 5.1) contains data collected across five annual visits, including three brain imaging assessments (baseline, year 2 follow-up, and year 4 follow-up visits) for at least a subset of the cohort. Hence, starting with Release 5.0, it is feasible for researchers to begin focusing on the characterization of neurodevelopmental and other trajectories.\n\n\n\n\n\n\n\n\n\nOrganization and Aims\n\n\n\n\n\n• Part I. Longitudinal Research\n\nFundamental concepts\n\n• Part II. Longitudinal Data\n\nMethod and analysis\n\n• Part III. Longitudinal Analysis\n\nMethods & Analysis\n\n• Part IV. Supplemental materials\n\nLinked open-source resources",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#the-abcd-study-data",
    "href": "manuscript/manuscript.html#the-abcd-study-data",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "The ABCD Study enrolled a cohort of n=11,880 participants born between 2006-2008 and aged between 9-10 years at baseline, each with a parent/guardian. The study sample was recruited from household populations in defined catchment areas for each of the 21 (originally 22) study sites across the United States. Information regarding funding agencies, recruitment sites, investigators, and project organizations can be obtained at https://abcdstudy.org. The ABCD Study design is described in more detail in Garavan et al. (2018) and Dick et al. (2021).\nThe ABCD Study is currently collecting longitudinal data on a rich variety of outcomes that will enable the construction of complex statistical models, potentially incorporating factors from many domains. Each new wave of data collection provides another building block for characterizing developmental trajectories and implementing longitudinal analyses that allow researchers to characterize normative development, to identify variables that presage deviations from normative development, and to assess a range of variables associated with biopsychosocial outcomes of interest. These data include: 1) a neurocognitive battery (Luciana et al. (2018); Wesley K. Thompson et al. (2019)); 2) mental and physical health assessments (Barch et al. (2018)); 3) measures of culture and environment (Gonzalez et al. (2021); Zucker et al. (2018)); 4) substance use (Lisdahl et al. (2021)); 5) gender identity and sexual health (Potter et al. (2022)); 6) biospecimens (Uban et al. (2018)); 7) structural and functional brain imaging (Casey et al. (2018); Hagler et al. (2019); Palmer et al. (2022)); 8) geolocation-based environmental exposure data (Fan et al. (2021)); 9) wearables and mobile technology (Bagot et al. (2018)); and 10) whole-genome genotyping (Loughnan et al. (2020)). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual brief telephone or online assessments.\nData are publicly released approximately annually, currently through the NIMH Data Archive (NDA). The study’s earliest data releases consisted primarily of one or two visits per participant. However, the most recent public release as of the writing of this paper (Release 5.1) contains data collected across five annual visits, including three brain imaging assessments (baseline, year 2 follow-up, and year 4 follow-up visits) for at least a subset of the cohort. Hence, starting with Release 5.0, it is feasible for researchers to begin focusing on the characterization of neurodevelopmental and other trajectories.",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#section",
    "href": "manuscript/manuscript.html#section",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "Organization and Aims\n\n\n\n\n\n• Part I. Longitudinal Research\n\nFundamental concepts\n\n• Part II. Longitudinal Data\n\nMethod and analysis\n\n• Part III. Longitudinal Analysis\n\nMethods & Analysis\n\n• Part IV. Supplemental materials\n\nLinked open-source resources",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#basic-concepts-and-considerations",
    "href": "manuscript/manuscript.html#basic-concepts-and-considerations",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "2.1 Basic Concepts and Considerations",
    "text": "2.1 Basic Concepts and Considerations\nThere are several important concepts to consider when conducting longitudinal analyses in a developmental context. These include different ways of thinking about the developmental course, whether certain periods of development are relatively sensitive or insensitive to various types of insults or stressors, whether some time periods or situations inhibit the expression of individual differences due to extreme environmental pressures, and whether the same behavior manifested at different times represents the same or different phenomena.\nMoreover, in the case of developmentally-focused longitudinal research, each new measurement occasion not only provides a more extended portrait of the child’s life course but also brings with it greater methodological opportunities to make use of statistical models that distinguish within- from between-person effects and that loosen constraints that need to be imposed on the furtherance of critical scientific questions.\nFor example, collecting two or more within-person observations on the same construct at different times enables estimation of individual rates of change (slopes) where more observations allow for more precise estimates of individual slopes (random slopes), as well as characterization of non-linear development. Rate of change or other trajectory characteristics may be more informative about individuals than the simple snapshots of level differences that cross-sectional data are limited to informing about. Cross-sectional age-related differences across individuals are poor substitutes for longitudinal trajectory estimates, except under highly restrictive assumptions, e.g., parallel trajectories and lack of age, cohort and experience effects (Wesley K. Thompson et al. (2011)). Appreciation of these and other issues can help to guide the analysis and interpretation of data and aid translation to clinical and public health applications.\n\n2.1.1 Vulnerable periods.\nAdolescent development progresses normatively from less mature to more mature levels of functioning. However, unique epochs and experiences can alter the course of this idealized form of development. Consider research that shows cannabis use during adolescence is associated with later psychosis to a greater degree than cannabis use initiated later in development (Arseneault et al. (2002); Bechtold et al. (2016); Hasan et al. (2020); Semple, McIntosh, and Lawrie (2005)). Similarly, rodent brains are especially sensitive to the neurotoxic effects of alcohol on brain structure and learning early in development, corresponding to early adolescence in humans (Spear (2016); Crews et al. (2000); Ji et al. (2018)). In another example, longitudinal data from the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) show that binge drinking is associated more strongly with decrements in gray matter volume early in adolescence compared to later (Infante et al. (2022)). These examples highlight the importance of considering the role of vulnerable periods – e.g., temporal windows of rapid brain development or remodeling during which the effects of environmental stimuli on the developing brain may be particularly pronounced– when trying to establish an accurate understanding of the association between exposures and outcomes.\n\n\n2.1.2 Developmental disturbances.\nWhereas vulnerable periods heighten neurobiological susceptibility to environmental influences, at other times, environmental exposures will tend to suppress stability and disrupt the orderly stochastic process of normative development (e.g., Schulenberg et al. (2019)). This situation reflects a developmental disturbance in that the normal course of development is “altered” for a time by some time-limited process. In such cases, we might find that prediction of behavior in the period of the disturbance is reduced and/or, similarly, the behavior exhibited during the disturbance might have less predictive power with respect to distal outcomes compared to the behavior exhibited before and following the disrupted period. That is, once the environmental pressures are removed (or the individual is removed from the environment), patterns of individual differences (and autoregressive effects) recover to levels similar to those prior to entering the environment.\n\n\n2.1.3 Developmental snares and cascade effects.\nNormative development can also be upended by experiences (e.g., drug use) that, through various mechanisms, disrupt the normal flow of development wherein each stage establishes a platform for the next. For instance, substance use could lead to association with deviant peers, precluding opportunities for learning various adaptive skills and prosocial behaviors, in effect creating a “snare” that delays psychosocial development, such as maturing out of adolescent antisocial behavior (Moffitt (2015)). Relatedly, the consequences of these types of events can cascade (e.g., school dropout, involvement in the criminal justice system) so that the effects of the snare are amplified (e.g., Masten et al. (2005); Rogosch, Oshri, and Cicchetti (2010)). Although conceptually distinct from vulnerable periods, both types of developmental considerations highlight the importance of viewing behavior in the context of development and attempting to determine how various developmental pathways unfold. Longitudinal data are crucial in this context to assess individual levels of development prior to and following onset of experiences or other environmental factors; e.g., the ABCD Study collected data starting at ages 9-10 and hence before the onset of substance use for the vast majority of participants.\n\n\n2.1.4 Mediational Processes.\nQuestions regarding the biological mechanisms whereby exposures impact outcomes can often be framed in terms of mediation analyses (MacKinnon, Fairchild, and Fritz (2007); VanderWeele (2016)). Mediation analyses can be implemented using the causal steps approach (Baron and Kenny (1986)) and structural equation models (SEM) (Preacher, Zhang, and Zyphur (2011)). More recently, mediation models have been adapted for longitudinal exposures, mediators, and/or outcomes (Bind et al. (2016); VanderWeele and Tchetgen Tchetgen (2017)). All of these modeling approaches decompose the total effects of an exposure on an outcome into direct and indirect effects, where indirect effects of an exposure flow through its impact on a mediating process. VanderWeele and Tchetgen Tchetgen (2017) details conditions under which the direct and indirect causal effects can be in a longitudinal setting. An important example of mediational analyses in the ABCD Study is the impact of exposures on behavioral outcomes (e.g., neurocognition, mental health, substance use) via their impact on the brain, as quantified by imaging-derived phenotypes (IDPs). Methods for mediational analyses using multi-dimensional IDPs have been developed and applied to functional MRI data (Lindquist (2012); Zhao et al. (2018)).",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#considerations-and-challenges",
    "href": "manuscript/manuscript.html#considerations-and-challenges",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "3.1 Considerations and Challenges",
    "text": "3.1 Considerations and Challenges\nThe hallmark characteristic of longitudinal data analysis (LDA) is the administration of repeated measurements of the same constructs on assessment targets (e.g., individuals, families) across time. The primary rationale for collecting longitudinal data is to assess within-person change over time, allowing researchers to estimate individual developmental trajectories and the genetic and person-level factors that may impact these trajectories. Administering repeated measurements more frequently or over longer periods enables researchers to ask more nuanced questions and to make stronger inferences.\n\n3.1.1 Two Time Points versus Three or More.\nAlthough the clear leap from cross-sectional to the realm of longitudinal data involves going from one assessment to two or more assessments, there are also notable distinctions in designs based on two-assessment points versus three or more measurement occasions. Just as cross-sectional data can be informative in some situations, two waves of data can be beneficial in contexts such as when an exposure is involved (e.g., pre/post tests), or if the central goal is prediction (e.g., trying to predict scores on Variable A at time T as a function of prior scores on Variable A and Variable B at time T-1). At the same time, analyses of data based on two assessments are inherently limited on multiple fronts. As Rogosa, Brandt, and Zimowski (1982) noted over forty years ago, “Two waves of data are better than one, but maybe not much better” (p. 744).\nThese sentiments are reflected in more contemporary recommendations regarding best-practice guidelines for prospective data, which increasingly emphasize the benefits of additional measurement occasions for trajectory estimation, model identification and accurate parameter inferences. This is also consistent with recommendations that developmental studies include three or more assessment points, given it is impossible for data based on two-time points to determine the shape of development (given that linear change is the only estimable form for two assessment waves; (see Duncan and Duncan (2009)). Research designs that include three (but preferably more) time points allow for non-linear trajectory estimation and increasingly nuanced analyses that more adequately tease apart sources of variation and covariation among the repeated assessments (King et al. (2018))– a key aspect of developmental research.\nTo illustrate, developmental theories are useful for understanding patterns of within-individual change over time (discussed in further detail, below); however, two data points provide meager information on change at the person level. This point is further underscored in a recent review of statistical models commonly touted as distinguishing within-individual vs between-individual sources of variance in which the study authors concluded “… researchers are limited when attempting to differentiate these sources of variation in psychological phenomenon when using two waves of data” and perhaps more concerning, “…the models discussed here do not offer a feasible way to overcome these inherent limitations” (Andrew K. Littlefield et al. (2021)). It is important to note, however, that despite the current focus on two-wave designs versus three or more assessment waves, garnering three assessment points is not a panacea for longitudinal modeling. Indeed, several contemporary longitudinal models designed to isolate within-individual variability (e.g., the Latent Curve Model with Structured Residuals [LCM: SR]; Patrick J. Curran et al. (2014)) require at least four assessments to parameterize fully and, more generally, increasingly accurate and nuanced parameter estimates are obtained as more assessment occasions are used (Duncan and Duncan (2009)).\n\n\n3.1.2 Types of stability and change\nIf one were to try to sum up what developmental trajectories in a living organism are exactly, one could plausibly argue they are the patterns of stability and change in its phenotypes as the organism traverses the life course. Symbolically, developmental trajectories can be expressed as fi(t), a possibly multivariate function of time t, specific to the ith individual and typically taking values in the real numbers for continuous phenotypes and the integers for discrete phenotypes. Ideally, t is a biologically meaningful temporal index (e.g., calendar age) as opposed to an exogenous progression of events (e.g., study visit number). Properties of interest might include rate of change over time, degree of smoothness (e.g., continuously differentiable), shape (e.g., polynomial or asymptotic behavior), how and how much f(t) differs across individuals, and what factors predict either within-individual variation (at different times) or between-individual variation (either overall or at specific times).\nThere are a few different ways to think about patterns of stability and change (see Figure 1). Consider measuring school disengagement at the start of middle school and the end of middle school. A common first step may be to compare sixth graders’ average disengagement values and eighth graders’ disengagement values. This comparison of the average scores for the same group of individuals at multiple time points is referred to as “mean-level”, as it provides information about change over time (or lack thereof) for an outcome of interest aggregated across members of a group. In contrast, “between-individual” stability could be assessed, e.g., by calculating the Spearman correlation between the values obtained at different time points (e.g., ‘disengagement in sixth grade’ with ’disengagement in eighth grade). This analysis focuses on the degree to which individuals retain their relative placement in a group across time. Consider someone who reported the lowest frequencies of disengagement in 6th grade and may report significantly higher disengagement over middle school (i.e., exhibit high levels of change), but report the lowest frequencies of disengagement in eighth grade. That is, the individual is manifesting rank-order stability, even in the context of high mean-level change.\nBoth types of stability and change are important. Mean-level change in certain traits might help to explain why, in general, populations of individuals tend to be particularly vulnerable to the effects of environmental factors in specific age ranges; rank-order stability might help to quantify the extent to which certain characteristics of the individual are more or less trait-like compared to others. For example, in some areas of development, considerable mean-level change occurs over time (e.g., changes in Big 5 personality traits (Bleidorn et al. (2022)), but exhibit relatively high rank-order stability, at least over shorter measurement intervals (Bleidorn et al. (2022); Roberts and DelVecchio (2000); Roberts, Walton, and Viechtbauer (2006)).\nDespite the useful information afforded by examining mean-level and rank-order stability and change, these approaches are limited in that they provide little information about the overall patterns of within-individual change and, in turn, can result in fundamental misinterpretations about substantial or meaningful changes in an outcome of interest (Patrick J. Curran and Bauer (2011)). For example, questions related to the impact of early-onset substance use on brain development focus on changes within a given individual (i.e., intraindividual differences). The ABCD Study will provide researchers with over ten time points for certain constructs (e.g., substance use) across a ten-year period, allowing for a detailed study of some within-person processes.\n\n\n\nFigure 3 Statistical modeling of brain imaging data\n\n\n\n\n\n\n\nTypes of Stability and Change\n\n\n\n\n\nTypes of Stability and Change\n\n\n\n\n\nTypes of Stability and Change\n\n\n\n\n\n3.1.3 Use of appropriate longitudinal models\nThere is growing recognition that statistical models commonly applied to longitudinal data often fail to align with the developmental theory they are being used to assess (e.g., Patrick J. Curran and Bauer (2011); Hoffman (2015); Andrew K. Littlefield et al. (2021)). First, developmental studies typically involve the use of prospective data to inform theories that are concerned with clear within-person processes (e.g., how phenotypes change or remain stable within individuals over time, (e.g., Patrick J. Curran and Bauer (2011))). Despite this, methods generally unsuited for disaggregating between- and within-person effects (e.g., cross-lagged panel models [CLPM]) remain common within various extant literatures. Fortunately, there exists a range of models that have been proposed to tease apart between- and within-person sources of variance across time (see Andrew K. Littlefield et al. (2021); Orth et al. (2021)). Most of these contemporary alternatives incorporate time-specific latent variables to capture between-person sources of variance and model within-person deviations around an individual’s mean (or trait) level across time (e.g., random-intercept cross-lagged panel model [RI-CLPM], Hamaker, Kuiper, and Grasman (2015)); latent curve models with structured residuals [LCM-SR], Patrick J. Curran et al. (2014)). It is important to note however that these models require multiple assessments waves (e.g., four or more to fully specify the LCM-SR), additional expertise to overcome issues with model convergence, and appreciation of modeling assumptions when attempting to adjudicate among potential models in each research context (see Andrew K. Littlefield et al. (2021), for further discussion).\nSecond, many statistical models assume certain characteristics about the data to which they are being applied. Common assumptions of parametric statistical models (e.g., linear mixed-effects models) include normality and equality of variances. These assumptions should be carefully considered before finalizing analytical approaches, so that valid inferences can be made from the data, as violation of a model’s assumptions can substantively invalidate the interpretation of results. For example, longitudinal data can exhibit heterogeneous variability (i.e., the variance of the response changes over the duration of the study) that may need to be accounted for within a model. Another pertinent modeling assumption is whether trajectories are linear or non-linear. With two or three assessments per individual, usually only a linear model of within-person change is feasible.\nAs the study progresses and more time points are assessed, the potentially nonlinear aspects of trajectories can be assessed, for example using quadratic functions of time. Methods that make even fewer assumptions about trajectory shapes, such as nonparametric curve estimation at the mean (e.g., Generalized Additive Mixed Models [GAMMs]; (Wood (2017))) and at the individual level (e.g., Functional Data Analysis [FDA]; Ramsay and Silverman (2002)) may also become useful. Note, baseline age in the ABCD Study ranges over two full years; for some outcomes it may be feasible to include a possibly nonlinear effect of baseline age along with a linear effect of within-person change in age even with only two or three assessment times (Wesley K. Thompson et al. (2013)).\n\n\n3.1.4 Continuous and Discrete Outcomes\nRepeated assessments within the ABCD Study can be based on continuous or discrete measures. Examples of discrete measures include repeated assessments of binary variables (e.g., past 12-month alcohol use disorder status measured across ten years), ordinal variables (e.g., caregiver-reported items measuring emotional and behavioral concerns via the Child Behavior Checklist including the categories of “Not True”, “Somewhat True”, and “Very True”), and count variables (e.g., number of cigarettes smoked per day). In many ways, the distributional assumptions of indicators used in longitudinal designs mirror the decision points and considerations when delineating across different types of discrete outcome variables, a topic that spans entire textbooks (e.g., see Lenz (2016)). For example, the Mplus manual (L. K. Muthén (2017)) includes examples of a) censored and censored-inflated models, b) linear growth models for binary or ordinal variables, c) linear growth models for a count outcome assuming a Poisson model, and d) linear growth models for a count outcome assuming a zero-inflated Poisson model. Beyond these highlighted examples, other distributions (e.g., negative binomial) can be assumed for the indicators when modeling longitudinal data (Ren et al. (2022)). These models account for issues that may occur when working with discrete outcomes, including overdispersion, i.e., when the variance is higher than would be expected based on a given parametric distribution (see Lenz (2016)). Given the sheer breadth of issues relevant to determining adequate models for discrete outcomes, it is not uncommon for texts on LDA to only cover models and approaches that assume continuous variables (e.g., T. D. Little (2013)). However, some textbooks on categorical data analysis provide more detailed coverage of the myriad issues and modeling choices to consider when working with discrete outcomes: Lenz (2016), Chapter 11 for matched pair/two-assessment designs; Chapter 12 for marginal and transitional models for repeated designs, such as generalized estimating equations, and Chapter 13 for random effects models for discrete outcomes.\n\n\n3.1.5 Issues in attributing longitudinal change to development\nSystematic changes over time in a variable of interest are not always attributable to development: various pitfalls with longitudinal data can complicate or even invalidate this conclusion. For example, if data missingness or participant dropout are related to the values of the outcome, changing sample composition as the study progresses can bias mean trajectory estimates (we describe this in more detail in Section 3.1.7 below). Another prerequisite for valid developmental interpretations of longitudinal data is to establish whether a construct is measured consistently over time, i.e., longitudinal measurement invariance (Liu et al. (2017); Van De Schoot et al. (2015); Willoughby, Wirth, and Blair (2012)). Establishing longitudinal measurement invariance ensures that change over time for a given construct is attributable to individual development rather than merely a measurement artifact. For instance, one study using data from the ABCD Study (Brislin et al. (2023)) found differential item functioning in two items from a brief delinquency measure, revealing significant bias in an arrest item across Black and White youth. More specifically, Black youth were more likely to report being arrested compared to White youth with similar levels of delinquency. Prevalence rates of delinquent behavior would have been severely biased if measurement invariance had not been tested. Alternatively, Vize et al. (2023) showed partially strong to strong evidence of longitudinal measurement invariance across broad externalizing dimensions in youth taking in the ABCD Study, suggesting that changes observed over time in these constructs were not due to systematic measurement error, but likely reflect true developmental change.\nObserved patterns of growth and decline often differ between cross-sectional vs. longitudinal effects (Salthouse (2014)) where subjects gain increasing experience with the assessment with each successive measurement occasion. Such experience effects on cognitive functioning have been demonstrated in adolescent longitudinal samples similar to ABCD (Sullivan et al. (2017)) and highlight the need to consider these effects and address them analytically. In the case of performance-based measures (e.g., matrix reasoning related to neurocognitive functioning; see Salthouse (2014)), this can be due to “learning” the task from previous test administrations (e.g., someone taking the test a second time performs better than they did the first time simply as a function of having taken it before). Even in the case of non-performance-based measures (e.g., levels of depression), where one cannot easily make the argument that one has acquired some task-specific skill through learning, it has been observed that respondents tend to endorse lower levels on subsequent assessments (e.g., A. T. Beck et al. (1961); French and Sutton (2010)) and this phenomenon has been well documented in research using structured diagnostic interviews (Robins (1985)). While it is typically assumed that individuals are rescinding or telling us less information on follow-up interviews, there is reason to suspect that in some cases the initial assessment may be artifactually elevated (see Shrout et al. (2018)).\nSome longitudinal studies, e.g., accelerated longitudinal designs (ALDs; Wesley K. Thompson et al. (2011)) are especially well suited for discovering these effects and modeling them. While ABCD is not an ALD, the variability in age (and grade in school) at the time of baseline recruitment (9 to 11 years) allows some measures, collected every year, to be conceptualized as an ALD (e.g., substance use; prosocial behavior; family conflict; screen time). It is also possible that in later waves, analyses will allow for disaggregating the confounded effects of age and the number of prior assessments. However, ABCD is fundamentally a single-cohort, longitudinal design, wherein number of prior assessments and age are mostly confounded, and for, perhaps, most analyses, the possible influence of experience effects needs to be kept in mind.\n\n\n3.1.6 Modeling Covariance\nA central issue for repeated measurements on an individual is how to account for the correlated nature of the data. Lack of independence of residuals across time occurs for longitudinal data with repeated assessments on individuals and in other situations with nested data (e.g., visits nested within participants, children nested within schools; siblings nested within families). Note, the ABCD Study has multiple levels of nesting, depending on the analysis, including within-participant, within-family, within-school, within-MRI scanner, and within-site.\nStatistical models for nested data include two main components, coupling a model for the mean response and its dependence on covariates with a model for the covariance among repeated outcomes on an individual. In contrast, traditional methods, such as multiple regression and ANOVAs, assume residuals are independent and thus are generally inappropriate for designs that incorporate some type of nesting. Specifically, given that residuals are no longer independent in a repeated measures design, standard errors from these models are biased and can produce misleading inferences. Therefore, an initial question to be addressed by a researcher analyzing prospective data is how to best model their covariance structure. A range of methods can be used to model covariance structures, each with its own set of tradeoffs between model fit and parsimony and which may be more or less appropriate for each specific application (e.g., see Kincaid (2005)).\nThe most common approach is to use random effects. Essentially, random effects allow for covariance estimates around fixed effects. A classic example (from Bryk and Raudenbush (1992); Singer (1998)) involves math achievement measured among students nested within schools. In a basic, intercept-only model with no covariates, there would be one fixed effect (the grand mean, or intercept, of math achievement), one school random effect (representing variation in the intercept between schools) and the within-school student residuals (variation left over after accounting for fixed and random effects). In this framework, each student’s score would be the sum of the fixed effect (the grand mean), the school random effect and the student’s within-school residual. Assumptions about the variance and covariance components of this model dictate the form of the variance/covariance structure. For example, if we assume the random effects are independent and identically distributed, the implied structure would be compound symmetry, where it is assumed the covariance of any two students in a single school is captured by a school random intercept and the covariance of any two students in different schools is zero. The assumptions of this relatively simple covariance structure can be relaxed depending on the nesting structure of the data, resulting in different covariance structures with additional parameters (see Singer (1998)).\nIn longitudinal studies, visits are nested within individuals. Mixed-effect models can be fitted to longitudinal data that couple a model for growth (development) at the mean level with a model for capturing within-individual covariance of assessments. For example, a linear growth model would involve two fixed effects – one for the intercept (the average score when time is coded zero) and one for the linear slope (the change in scores for each unit increase in time). Random effects could include a random effect for intercept, capturing individual variation in scores at time zero, and a random effect for the linear slope, capturing individual variation in linear change across time. Within-individual residuals account for the remaining variation in assessments after accounting for the fixed and random intercepts and slopes. Assumptions regarding the covariation among the random effects also indicate different covariance structures. For example, it is typical to assume that the random intercept and slope components covary, i.e., an individual’s score at time zero relates to the amount of change exhibited across time. Further, particularly in structural equation model forms of this model, it is sometimes assumed that the variance of the residuals varies across assessments (Patrick J. Curran (2003)).\nAn alternative to random effects is the autoregressive structure, which allows for correlations between repeated assessments to diminish across time. As the name suggests, the structure assumes the residual of a subsequent measurement occasion (e.g., visit 2) is regressed onto the residual of a prior measurement occasion (e.g., baseline visit). The most common type of autoregressive structure is the AR(1), where residuals at time t + 1 are regressed on residuals at time t. Identical to compound symmetry, this model assumes the variances are homogenous across time; however, it differs from compound symmetry in that the correlations between repeated assessments decline exponentially across visits rather than remaining constant. That is, we can think of the underlying process as a stochastic one that wears itself out over time. For example, per the AR(1) structure, if the correlation between visit 1 and visit 2 data is thought to be .5, then the correlation between visit 1 and visit 3 data would be assumed to be .5 × .5 = .25, and the correlation between visit 1 and visit 4 data would be assumed to be .5 × .5 × .5 = .125. As with compound symmetry, the basic AR(1) model is parsimonious in that it only requires two parameters: the variance of the residuals and the autoregressive coefficient.\nNotably, the assumption of constant autoregressive relations between assessments is often relaxed in commonly employed designs that use autoregressive modeling (e.g., CLPM). These designs still typically assume an AR(1) process. However, the magnitude of these relations is often allowed to differ across different AR(1) pairs of assessment (e.g., the relation between visit 1 and visit 2 can be different from the relation between visit 2 and visit 3). These models also often relax the assumption of equal variances of the repeated assessments.\nAlthough the AR(1) structure may involve a more realistic set of assumptions compared to compound symmetry, in that the AR(1) model allows for diminishing correlations across time, the basic AR(1) model, as well as autoregressive models more generally, can also suffer from several limitations in contexts that are common in prospective designs. In particular, recent work demonstrates that if a construct being assessed prospectively across time is trait-like in nature, then a simple AR(1) process fail to adequately account for this trait-like structure, with the downstream consequence that estimates derived from models based on AR structures (such as the CLPM) can be misleading and fail to adequately demarcate between- vs. within-person sources of variance (Hamaker, Kuiper, and Grasman (2015)). Note also, discrete-time autoregressive structures such as AR(1) implicitly assumes relatively constant time gaps between visits; this may not be true in many applications using the ABCD Study data.\n\n\n3.1.7 Missing Data/Attrition\nAttrition from a longitudinal study such as ABCD is inevitable and represents a potential threat to the external validity of analyses conducted at later visits, especially since attrition can only be expected to grow over time (Andrew K. Littlefield et al. (2022)). The ABCD Retention Workgroup employs a data-driven approach to examine, track, and intervene in these issues and while preliminary findings show participant race and parent education level to be associated with late and missing visits, although to date, formal attrition in ABCD has been minimal (Ewing et al. (2022)). Ideally, one tries to minimize attrition through good retention practices from the outset via strategies designed to maintain engagement in the project (Cotter et al. (2005); Hill et al. (2016); Watson et al. (2018)). However, even the best-executed studies need to anticipate growing attrition over the length of the study and implement analytic strategies designed to provide the most valid inferences.\nPerhaps the most key concern when dealing with data that is missing due to attrition is determining the degree of bias in retained variables that is a consequence of attrition. Such bias can attenuate generalizability, particularly if the pattern of missingness is not random (e.g., certain subsets of the population are more likely to drop out/not attend a visit). Assuming that the data are not missing completely at random, attention to the nature of the missingness and employing techniques designed to mitigate attrition-related biases need to be considered in all longitudinal analyses.\nThree types of missingness are considered in the literature (R. J. Little and Rubin (1989); T. D. Little (2013)), namely: a) missing completely at random (MCAR), b) missing at random (MAR), and c) missing not at random (MNAR). Data that are MCAR are a simple random sample of all data in a given dataset. MAR implies missing data are a random sample (i.e., does not hinge on some unmeasured variables) within strata of the measured covariates in a dataset (e.g., biological sex). Data that are MNAR are missing as a function of unobserved variables and may bias associations even after conditioning on the observed covariates. Graham (2009) provides an excellent and easy-to-digest overview of further details involving missing data considerations.\nModern approaches for handling missing data, such as full-information maximum likelihood, propensity weighting, auxiliary variables and multiple imputation avoid the biases of older approaches (see Enders (2010); Graham (2009)). Graham (2009) noted several “myths” regarding missing data. For example, Graham notes many assume the data must be minimally MAR to permit estimating procedures (such as maximum likelihood or multiple imputation) compared to other, more traditional approaches (e.g., using only complete case data). Violations of MAR impact both traditional and more modern data estimation procedures, though as noted by Graham, violations of MAR tend to have a greater effect on older methods. Graham thus suggests that imputing missing data is a better approach compared to listwise deletion in most circumstances, regardless of the model of missingness (i.e., MCAR, MAR, MNAR; see Graham (2009)). The ABCD Biostatistics Workgroup is currently implementing several missing data approaches which are being implemented and compared to each other (and listwise deletion) in the 5.0 data release, including, propensity score weighting, and multiple (multilevel) imputation.\n\n\n3.1.8 Quantifying effect sizes longitudinally\nGiven that longitudinal data involve multiple sources of variation, quantifying effect sizes longitudinally is more complex compared to deriving such estimates from cross-sectional data. An effect size can be defined as, “a population parameter (estimated in a sample) encapsulating the practical or clinical importance of a phenomenon under study.” (Kraemer 2014). Common effect size metrics include the Pearson correlation r between two variables and the standardized difference between two means, Cohen’s d (Cohen (1988)). An extensive discussion of cross-sectional effect sizes and their relevance for ABCD is given in Dick et al. (2021).\nAdjustments to common effect size calculations, such as Cohen’s d, are required even when only two time points are considered (e.g., Morris and DeShon (2002)). Wang et al. (2019) note there are multiple approaches to obtaining standardized within-person effects, and that commonly suggested approaches (e.g., global standardization) can be problematic (see Wang et al. (2019), for more details). Thus, obtaining effect size metrics based on standardized estimates that are relatively simple in cross-sectional data (such as r) becomes more complex in the context of prospective longitudinal data. Feingold (2009) noted that equations for effects sizes used in studies involving growth modeling analysis (e.g., latent growth curve modeling) were not mathematically equivalent, and the effect sizes were not in the same metric as effect sizes from cross-sectional analysis (see Feingold (2009), for more details).\nGiven this issue, there have been various proposals for adjusting effect size measures in repeated assessments. Feingold (2019) reviews the approach for effect size metrics for analyses based on growth modeling, including when considering linear and non-linear (e.g., quadratic) growth factors. Morris and DeShon (2002) review various equations for effect size calculations relevant to combining estimates in meta-analysis with repeated measures and independent-groups designs. Other approaches to quantifying effect sizes longitudinally may be based on standardized estimates from models that more optimally disentangle between- and within-person sources of variance. As an example, within a random-intercept cross-lagged panel model (RI-CLPM) framework, standardized estimates between random intercepts (i.e., the correlation between two random intercepts for two different constructs assessed repeatedly) could be used to index the between-person relation, whereas standardized estimates among the structured residuals could be used as informing the effect sizes of within-person relationships.\n\n\n3.1.9 Longitudinal Data Structures\nAn ideal longitudinal analysis integrates (a) a well-articulated theoretical model, (b) an appropriate longitudinal data structure, and (c) a statistical model that is an operationalization of the theoretical model (Collins (2006)). To accommodate various research questions and contexts, different types of longitudinal data and data structures have emerged (see Figure 1). An understanding of these data structures is helpful, as they can warrant different types of LDA. Given that identifying a starting point for making comparisons is somewhat arbitrary, Curran and Bauer and Curran (2019) provide a nice on-ramp in first distinguishing between the use of “time-to-event” and “repeated measures” data. Although both model time, the former is concerned with whether and when an event occurs, whereas the later is focused on growth and change (Bauer and Curran (2019) Time-to-event structures measure time from a well-defined origin point up to the occurrence of an event of interest. This data structure is most often analyzed using survival analysis methods (e.g., hazard rate models, event history analysis, failure-time models) and the time-to-event data can be based on a single assessment or include multiple recurrent or competing events. While much has been written about “time-to-event” data (Hosmer Jr, Lemeshow, and May (2008); Rizopoulos (2012)), including a recent analysis examining exclusionary discipline in schools using data from the ABCD Study (Brislin et al. (2023)), our emphasis will be given to the modeling of “repeated measures” data.\n\n\n\nLongitudinal Data Analysis Structural Diagram\n\n\nWhen discussing longitudinal analysis, we are most often talking about data collected on the same unit (e.g., individuals) across multiple measurement occasions. However, repeated-measures analysis is not a monolith, and it will serve us well to distinguish between a few of the most common types. One such approach to repeated measures analysis is the use of time-series models. These models generally consist of a long sequence of repeated measurements (≧ 50-100 measurements) on a single or small number of variables of interest. Time-series analysis is often used to predict temporal trends and cyclic patterns and is geared toward making inferences about prospective outcomes within a population (with relatively less focus on inferring individual-level mechanisms and risk factors).\nA related type of repeated measures analysis is Intensive Longitudinal Data (ILD). Similar to time-series analysis, ILD models involve frequent measurements (~ 30-40 measurements) of the same individuals in a relatively circumspect period (e.g., experience sampling to obtain time series on many individuals). Although ILD models may include slightly fewer measurement occasions than time-series data, ILD models tend to have more subjects than time-series models (~ 50-100 subjects). This allows ILD models to examine short-term patterns by incorporating a time series model that can sometimes fit parameter estimates to each individual’s data to model individual difference outcomes.\nThe final type of repeated measures analysis that we will primarily focus on is the longitudinal panel study. These models follow a group of individuals— a panel (also referred to as a cohort) — across relatively fewer measurement occasions (~ 5-15) and are often focused on examining both change within- and between-individuals. The ABCD Study is primarily a longitudinal panel study, though some data streams (e.g., functional brain imaging, FitBit data) could be analyzed as ILP or even time series methods.\nWhile other longitudinal designs have their own unique strengths and applications, the longitudinal panel design is particularly well-suited for investigating developmental processes in the context of the ABCD Study. In the following sections, we will discuss various analytic methods commonly used to analyze longitudinal panel data, including growth models, mixed models, and a number of additional trajectory models. These methods provide valuable insights into within- and between-individual differences and are highly relevant for researchers working with the ABCD Study dataset. By focusing on these methods, we aim to equip readers with the knowledge necessary to conduct longitudinal research and perform analyses using the rich, longitudinal, and publicly available data from the ABCD Study.",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "examples/examples.html",
    "href": "examples/examples.html",
    "title": "",
    "section": "",
    "text": "Code",
    "crumbs": [
      "ABCD Examples",
      "<i class=\"bi bi-book\"></i> Examples"
    ]
  },
  {
    "objectID": "examples/examples.html#examples",
    "href": "examples/examples.html#examples",
    "title": "",
    "section": " Examples",
    "text": "Examples\n\n\n\nEach Example uses data from the ABCD Study Dataset and provides a practical solution to a specific longitudinal method or analytic problem.\n\n\n\n\n\n\n\n    \n        \n            \n            \n                Traditional Linear Models\n                \n                \n                    \n                        Difference Scores (Paired T-test)\n                        \n                    \n                        Difference Scores (Simple Regression)\n                        \n                    \n                        Residualized Change Scores\n                        \n                    \n                        Linear Mixed\n                        Models (Random Intercept)\n                    \n                    \n                        Linear Mixed\n                        Models (Random Slope)\n                    \n                \n            \n        \n        \n            \n            \n                Traditional Nonlinear Models\n                \n                \n                \n                  \n                        Signed-Rank\n                        Test\n                        \n                    \n                        Marginal Models\n                        \n                        \n                        Generalized\n                        Estimating Equations\n                        \n                        \n                        Generalized Linear\n                        Mixed Effects Models\n                        \n                \n            \n        \n        \n            \n            \n                Structural Equation Models\n                \n                \n                \n                  \n                        Latent Change Score Models\n                        \n                    \n                        Latent Growth Curve Models\n                        \n                    \n                        Latent Transition Analysis\n                        \n                \n            \n        \n        \n            \n            \n                Advanced SEM\n                \n                \n                \n                  \n                        Random-Intercept Crosslagged Panel Model\n                        \n                        \n                        Latent Curve Models with Structured Residuals\n                        \n                \n            \n        \n        \n            \n            \n                Additional Models\n                \n                \n                \n                  \n                    \n                \n            \n        \n        \n    \n\n\n\n    \n        Pure CSS Gradient Background Animation\n        \n             SOURCE CODE\n            FULL SCREEN \n        \n        \n            — Pen by Manuel Pinto —",
    "crumbs": [
      "ABCD Examples",
      "<i class=\"bi bi-book\"></i> Examples"
    ]
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "This example assesses growth in a subsample of ABCD participants from Baseline (T0) to the 1-Year follow-up (T1), using weight as a representative metric. The analysis is conducted in two primary steps: 1) a difference score is calculated between baseline and Year_1 weight measurements for each participant; 2) a one-sample t-test is used to test whether the difference score is statistically different than a null hypothesis of zero change. Finally, a visual inspection is further conducted via a scatterplot to graphically represent the relationship between participant’s weight at Baseline and Year_1. The ensuing analysis and interpretations are detailed in the subsequent sections."
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html#overview",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html#overview",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "",
    "text": "This example assesses growth in a subsample of ABCD participants from Baseline (T0) to the 1-Year follow-up (T1), using weight as a representative metric. The analysis is conducted in two primary steps: 1) a difference score is calculated between baseline and Year_1 weight measurements for each participant; 2) a one-sample t-test is used to test whether the difference score is statistically different than a null hypothesis of zero change. Finally, a visual inspection is further conducted via a scatterplot to graphically represent the relationship between participant’s weight at Baseline and Year_1. The ensuing analysis and interpretations are detailed in the subsequent sections."
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html#preliminary-setup",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html#preliminary-setup",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "Preliminary Setup",
    "text": "Preliminary Setup\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\", \"easystats\", \"lme4\", \"gtsummary\", \"report\", \"broom\", \"gridExtra\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse) # Collection of R packages for data science\nlibrary(easystats) # Collection of R packages statistical modeling, visualization, and reporting\nlibrary(gtsummary) # Publication-ready tables\nlibrary(report) # Easy reporting of regression analyses\nlibrary(broom) # Tidy and augment statistical models output\nlibrary(gridExtra) # Arrange multiple grid-based plots on a page\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(\n    echo = T, message = F, warning = F, error = F,\n    comment = NA, cache = T, code_folding = T,\n    R.options = list(width = 220, digits = 3),\n    fig.align = \"center\",\n    out.width = \"75%\", fig.asp = .75\n)"
  },
  {
    "objectID": "examples/1a_Examples_DifferenceScores_PairedTtests.html#descriptives-overview",
    "href": "examples/1a_Examples_DifferenceScores_PairedTtests.html#descriptives-overview",
    "title": "Difference Scores: Paired Samples T-test",
    "section": "Descriptives Overview",
    "text": "Descriptives Overview\n\nRead and View DataDescriptivesResults\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"nihtbx_totalcomp_fc\", \"anthroweightcalc\", \"anthroweightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n    full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\n    \"baseline_year_1_arm_1\",\n    \"1_year_follow_up_y_arm_1\",\n    \"2_year_follow_up_y_arm_1\",\n    \"3_year_follow_up_y_arm_1\",\n    \"4_year_follow_up_y_arm_1\"\n)\n\ndf &lt;- merged_data %&gt;%\n    filter(eventname %in% eventnames_to_include) %&gt;%\n    mutate(\n        src_subject_id = as.factor(src_subject_id),\n        eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n        age = as.numeric(age),\n        sex = as.factor(sex),\n        race.4level = as.factor(race.4level),\n        hisp = as.factor(hisp),\n        high.educ.bl = as.factor(high.educ.bl),\n        household.income.bl = as.factor(household.income.bl),\n        acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n        rel_family_id.bl = as.factor(rel_family_id.bl),\n        site_id_l = as.factor(site_id_l),\n        nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),\n        anthroweightcalc = as.numeric(anthroweightcalc),\n        anthroweightcalc = as.numeric(anthroweightcalc)\n    ) %&gt;%\n    # Exclude cases from unused assessment waves\n    filter(!is.na(eventname))\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n    select(eventname, sex, race.4level, hisp, anthroweightcalc) %&gt;%\n    mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\", \"Year 2\", \"Year 3\", \"Year 4\"))) %&gt;%\n    mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n    tbl_summary(\n        by = eventname,\n        missing = \"no\",\n        label = list(\n            sex ~ \"Sex\", race.4level ~ \"Race\", hisp ~ \"Hispanic\",\n            anthroweightcalc ~ \"Weight\"\n        ),\n        statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n    ) %&gt;%\n    modify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n    bold_labels() %&gt;%\n    italicize_levels() %&gt;%\n    modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nHispanic\n21%\n20%\n20%\n20%\n21%\n\n\nWeight\n83 (24) )\n94 (28) )\n109 (49) )\n123 (38) )\n139 (111) )\n\n\n\n1 %; Mean (SD) )\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe code snippet below tells R to compute a difference score by subtracting each participant’s weight at T1 from their weight at T0. Relevant summary statistics are also provided.\nSTEP 1: Compute Difference Score\n\n\nCode\n# Function to compute difference scores\ncompute_difference &lt;- function(df, variable_name) {\n    # Define the event names of interest\n    baseline_event &lt;- \"baseline_year_1_arm_1\"\n    followup_event &lt;- \"1_year_follow_up_y_arm_1\"\n\n    # Compute the difference between Baseline and Year 1 data for the given variable\n    diff_data &lt;- df %&gt;%\n        filter(eventname %in% c(baseline_event, followup_event)) %&gt;% # Filter for specific event names\n        select(src_subject_id, eventname, all_of(variable_name)) %&gt;% # Select required columns\n        spread(eventname, variable_name) %&gt;% # Convert data from long to wide format\n        mutate(diff = get(followup_event) - get(baseline_event)) %&gt;% # Compute difference between the two time points\n        mutate(group_resid = (diff) - mean(diff)) %&gt;% # compute residuals (group_resid).\n        drop_na(diff) # Exclude rows with NA in the computed difference\n\n    # Summarize the computed difference scores\n    diff_summary &lt;- summary(diff_data$diff)\n\n    # Return the difference data and its summary\n    list(data = diff_data, summary = diff_summary)\n}\n\n# List of variables for which difference scores are to be computed\nvariables_of_interest &lt;- c(\"anthroweightcalc\")\n\n# Compute and store difference scores and summaries for each variable in a list\ndifference_and_summary_list &lt;- lapply(variables_of_interest, function(var) {\n    compute_difference(df, var)\n})\n\n# Extract the difference data for the 'anthroweightcalc' variable\nweight_diff_data &lt;- difference_and_summary_list[[1]]$data\n\n# Merge the 'diff' column back to the main df using 'src_subject_id' as the key\ndf &lt;- left_join(df, weight_diff_data %&gt;% select(src_subject_id, diff), by = \"src_subject_id\")"
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html",
    "href": "examples/2_Examples_ResidualizedChangeScores.html",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "This example assesses whether height, measured at the 1-Year follow-up (T1) in a subsample of ABCD participants, is predicted by weight and height measured at baseline (T0). A visual inspection is further conducted via a scatterplot to graphically represent the relationship between height at Year_1 and weight at baseline, controlling for height at baseline. The ensuing analysis and interpretations are detailed in the subsequent sections.\n\n\n\n\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"easystats\",\"lme4\",\"gtsummary\",\"report\",\"broom\",\"gridExtra\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(easystats)    # Collection of R packages statistical modeling, visualization, and reporting\nlibrary(gtsummary)    # Publication-ready tables\nlibrary(report)       # Easy reporting of regression analyses\nlibrary(broom)        # Tidy and augment statistical models output\nlibrary(gridExtra)    # Arrange multiple grid-based plots on a page\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)\n\n\n\n\n\n\n\n\n\n\nRead and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"nihtbx_totalcomp_fc\", \"anthroweightcalc\", \"anthroheightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),\n    anthroweightcalc = as.numeric(anthroweightcalc),\n    anthroheightcalc = as.numeric(anthroheightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, hisp, anthroweightcalc) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", hisp ~ \"Hispanic\", \n                 anthroweightcalc ~ \"Weight\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nHispanic\n21%\n20%\n20%\n20%\n21%\n\n\nWeight\n83 (24) )\n94 (28) )\n109 (49) )\n123 (38) )\n139 (111) )\n\n\n\n1 %; Mean (SD) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild ModelModel SummaryModel Plots\n\n\n\nThe code snippet below tells R to conduct a multiple regression analysis by subtracting each participant’s height at T1 from their height at T0. Relevant summary statistics are also provided.\nCompute Multiple Regression Model\n\n\nCode\n# Split data using the correct eventname values\nbaseline_data &lt;- df %&gt;% \n  filter(eventname == \"baseline_year_1_arm_1\") %&gt;% \n  select(src_subject_id, Height_baseline = anthroheightcalc, Weight_baseline = anthroweightcalc)\n\nfollowup_data &lt;- df %&gt;% \n  filter(eventname == \"1_year_follow_up_y_arm_1\") %&gt;% \n  select(src_subject_id, Height_followup = anthroheightcalc)\n\n# Merge baseline and follow-up data\nmerged_data &lt;- baseline_data %&gt;%\n  left_join(followup_data, by = \"src_subject_id\")\n\n# Check the first few rows of the merged data\n#head(merged_data)\n\n# Fit the regression model excluding NA values\nmodel &lt;- lm(Height_followup ~ Height_baseline + Weight_baseline, data = merged_data, na.action = na.exclude)\n\n\n\n\n\n\nA plot to show xxxxx.\n\n\nCode\nmodel_summary &lt;- summary(model)\nprint(model_summary)\n\n\n\nCall:\nlm(formula = Height_followup ~ Height_baseline + Weight_baseline, \n    data = merged_data, na.action = na.exclude)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-53.49  -0.83  -0.09   0.74  65.88 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     17.18159    0.41712    41.2   &lt;2e-16 ***\nHeight_baseline  0.68665    0.00847    81.0   &lt;2e-16 ***\nWeight_baseline  0.03026    0.00120    25.3   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.38 on 11130 degrees of freedom\n  (735 observations deleted due to missingness)\nMultiple R-squared:  0.575, Adjusted R-squared:  0.575 \nF-statistic: 7.54e+03 on 2 and 11130 DF,  p-value: &lt;2e-16\n\n\nCode\npar(mfrow = c(2, 2))  # Set up a 2x2 plotting area\nplot(model)  # Generate diagnostic plots\n\n\n\n\n\n\n\n\n\nThis regression analysis evaluates how baseline height and weight predict children’s height at a 1-year follow-up. The output from our model provides several key statistics:\n\nan F-statistic of 7539.2168865;\ndegrees of freedom of 11130;\nparameter estimates for baseline height and weight;\nstandard errors for these estimates; and\np-values for the significance of these estimates.\n\nFor every one unit increase in baseline height, there’s an associated increase of approximately 0.687 units in the follow-up height, and this effect was statistically significant with a p-value of 0. Similarly, for every one unit increase in baseline weight, there’s an associated increase of approximately 0.0303 units in the follow-up height, which is also statistically significant with a p-value of 3.9902186^{-137}. Overall, this model explains a substantial portion of the variance in follow-up height, with an adjusted R-squared value of 0.5753. The overall model is highly significant with a p-value less than 0, indicating that the predictors, collectively, have a significant relationship with the dependent variable.\n\n\n\n\n\n\nCode\n# Scatterplot with regression line for Weight_baseline\nggplot(merged_data, aes(x = Weight_baseline, y = Height_followup)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", color = \"black\") + \n  labs(title = \"Relationship between Baseline Weight and Follow-up Height\",\n       x = \"Baseline Weight\",\n       y = \"Follow-up Height\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe scatterplot visually depicts the relationship between children’s weights at baseline (Weight_baseline) and their heights at Year_1 (Height_followup). Each point on the plot represents a child, with their baseline weight plotted on the x-axis and their Year_1 height on the y-axis. The clear positive linear trend, as illustrated by the black regression line, indicates that children who had higher weights at baseline generally had higher heights at Year_1. While further statistical analyses can quantify the strength and direction of this relationship, visually, the data suggests a pronounced positive association between baseline weight and follow-up height.\n\n\n\n\n\n\n\n\n\n\nWrite-up\n\n\n\nThe regression analysis was conducted to predict children’s height at the 1-Year follow-up using their baseline height (Height_baseline) and weight (Weight_baseline). Both predictors were statistically significant. Specifically, for every one-unit increase in baseline height, the height at Year_1 increased by approximately 0.687 units, while holding weight constant. Similarly, for every one-unit increase in baseline weight, the height at Year_1 increased by about 0.0303 units, while holding baseline height constant. The overall model explained a substantial 57.53% of the variance in height at the 1-Year follow-up, as indicated by the adjusted R-squared value."
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#overview",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "This example assesses whether height, measured at the 1-Year follow-up (T1) in a subsample of ABCD participants, is predicted by weight and height measured at baseline (T0). A visual inspection is further conducted via a scatterplot to graphically represent the relationship between height at Year_1 and weight at baseline, controlling for height at baseline. The ensuing analysis and interpretations are detailed in the subsequent sections."
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#preliminary-setup",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#preliminary-setup",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Install PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"easystats\",\"lme4\",\"gtsummary\",\"report\",\"broom\",\"gridExtra\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(easystats)    # Collection of R packages statistical modeling, visualization, and reporting\nlibrary(gtsummary)    # Publication-ready tables\nlibrary(report)       # Easy reporting of regression analyses\nlibrary(broom)        # Tidy and augment statistical models output\nlibrary(gridExtra)    # Arrange multiple grid-based plots on a page\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#descriptives-overview",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#descriptives-overview",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Read and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"nihtbx_totalcomp_fc\", \"anthroweightcalc\", \"anthroheightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),\n    anthroweightcalc = as.numeric(anthroweightcalc),\n    anthroheightcalc = as.numeric(anthroheightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, hisp, anthroweightcalc) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", hisp ~ \"Hispanic\", \n                 anthroweightcalc ~ \"Weight\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nHispanic\n21%\n20%\n20%\n20%\n21%\n\n\nWeight\n83 (24) )\n94 (28) )\n109 (49) )\n123 (38) )\n139 (111) )\n\n\n\n1 %; Mean (SD) )"
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#results",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#results",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Build ModelModel SummaryModel Plots\n\n\n\nThe code snippet below tells R to conduct a multiple regression analysis by subtracting each participant’s height at T1 from their height at T0. Relevant summary statistics are also provided.\nCompute Multiple Regression Model\n\n\nCode\n# Split data using the correct eventname values\nbaseline_data &lt;- df %&gt;% \n  filter(eventname == \"baseline_year_1_arm_1\") %&gt;% \n  select(src_subject_id, Height_baseline = anthroheightcalc, Weight_baseline = anthroweightcalc)\n\nfollowup_data &lt;- df %&gt;% \n  filter(eventname == \"1_year_follow_up_y_arm_1\") %&gt;% \n  select(src_subject_id, Height_followup = anthroheightcalc)\n\n# Merge baseline and follow-up data\nmerged_data &lt;- baseline_data %&gt;%\n  left_join(followup_data, by = \"src_subject_id\")\n\n# Check the first few rows of the merged data\n#head(merged_data)\n\n# Fit the regression model excluding NA values\nmodel &lt;- lm(Height_followup ~ Height_baseline + Weight_baseline, data = merged_data, na.action = na.exclude)\n\n\n\n\n\n\nA plot to show xxxxx.\n\n\nCode\nmodel_summary &lt;- summary(model)\nprint(model_summary)\n\n\n\nCall:\nlm(formula = Height_followup ~ Height_baseline + Weight_baseline, \n    data = merged_data, na.action = na.exclude)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-53.49  -0.83  -0.09   0.74  65.88 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     17.18159    0.41712    41.2   &lt;2e-16 ***\nHeight_baseline  0.68665    0.00847    81.0   &lt;2e-16 ***\nWeight_baseline  0.03026    0.00120    25.3   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.38 on 11130 degrees of freedom\n  (735 observations deleted due to missingness)\nMultiple R-squared:  0.575, Adjusted R-squared:  0.575 \nF-statistic: 7.54e+03 on 2 and 11130 DF,  p-value: &lt;2e-16\n\n\nCode\npar(mfrow = c(2, 2))  # Set up a 2x2 plotting area\nplot(model)  # Generate diagnostic plots\n\n\n\n\n\n\n\n\n\nThis regression analysis evaluates how baseline height and weight predict children’s height at a 1-year follow-up. The output from our model provides several key statistics:\n\nan F-statistic of 7539.2168865;\ndegrees of freedom of 11130;\nparameter estimates for baseline height and weight;\nstandard errors for these estimates; and\np-values for the significance of these estimates.\n\nFor every one unit increase in baseline height, there’s an associated increase of approximately 0.687 units in the follow-up height, and this effect was statistically significant with a p-value of 0. Similarly, for every one unit increase in baseline weight, there’s an associated increase of approximately 0.0303 units in the follow-up height, which is also statistically significant with a p-value of 3.9902186^{-137}. Overall, this model explains a substantial portion of the variance in follow-up height, with an adjusted R-squared value of 0.5753. The overall model is highly significant with a p-value less than 0, indicating that the predictors, collectively, have a significant relationship with the dependent variable.\n\n\n\n\n\n\nCode\n# Scatterplot with regression line for Weight_baseline\nggplot(merged_data, aes(x = Weight_baseline, y = Height_followup)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", color = \"black\") + \n  labs(title = \"Relationship between Baseline Weight and Follow-up Height\",\n       x = \"Baseline Weight\",\n       y = \"Follow-up Height\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe scatterplot visually depicts the relationship between children’s weights at baseline (Weight_baseline) and their heights at Year_1 (Height_followup). Each point on the plot represents a child, with their baseline weight plotted on the x-axis and their Year_1 height on the y-axis. The clear positive linear trend, as illustrated by the black regression line, indicates that children who had higher weights at baseline generally had higher heights at Year_1. While further statistical analyses can quantify the strength and direction of this relationship, visually, the data suggests a pronounced positive association between baseline weight and follow-up height."
  },
  {
    "objectID": "examples/2_Examples_ResidualizedChangeScores.html#wrapping-up",
    "href": "examples/2_Examples_ResidualizedChangeScores.html#wrapping-up",
    "title": "Residualized Change Scores",
    "section": "",
    "text": "Write-up\n\n\n\nThe regression analysis was conducted to predict children’s height at the 1-Year follow-up using their baseline height (Height_baseline) and weight (Weight_baseline). Both predictors were statistically significant. Specifically, for every one-unit increase in baseline height, the height at Year_1 increased by approximately 0.687 units, while holding weight constant. Similarly, for every one-unit increase in baseline weight, the height at Year_1 increased by about 0.0303 units, while holding baseline height constant. The overall model explained a substantial 57.53% of the variance in height at the 1-Year follow-up, as indicated by the adjusted R-squared value."
  },
  {
    "objectID": "examples/3b_Examples_LinearMixedModels.html",
    "href": "examples/3b_Examples_LinearMixedModels.html",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "The Linear Mixed Model with a random intercept and slope (LMM:ris) extends the traditional fixed-effect linear regression by incorporating both a subject-specific random intercept and a random slope. This allows each participant to have their own unique intercept and slope values, reflecting individual starting points and rates of change, in addition to the overall mean-level (fixed-effect) trajectory.\nIn this example, we will utilize the LMM:ris to analyze height trajectories obtained across multiple measurement occasions for a sample of youth participating in the ABCD Study. Our primary objective is to understand the stability and evolution in height measurements, while factoring in the clustered nature of observations within individuals over time. The LMM:ris facilitates this by concurrently modeling an overarching sample mean trajectory (fixed effect) and individual variations (random effects) in both starting points (intercepts) and growth rates (slopes) around this mean trajectory.\n\n\n\n\n\nInstall PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"rstatix\",\"DT\",\"lme4\",\"report\",\"broom\",\"gridExtra\",\"easystats\",\"gtsummary\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(rstatix)      # Pipe-friendly framework for basic statistical tests\nlibrary(DT)           # Rendering interactive data tables\nlibrary(lme4)         # Linear mixed-effects models\nlibrary(report)       # Easy reporting of regression analyses\nlibrary(broom)        # Tidy and augment statistical models output\nlibrary(gridExtra)    # Arrange multiple grid-based plots on a page\nlibrary(easystats)    #\nlibrary(gtsummary)    #\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)\n\n\n\n\n\n\n\n\n\n\nRead and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"nihtbx_totalcomp_fc\", \"anthroweightcalc\", \"anthroheightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),\n    anthroweightcalc = as.numeric(anthroweightcalc),\n    anthroheightcalc = as.numeric(anthroheightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, hisp, anthroweightcalc) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", hisp ~ \"Hispanic\", \n                 anthroweightcalc ~ \"Weight\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nHispanic\n21%\n20%\n20%\n20%\n21%\n\n\nWeight\n83 (24) )\n94 (28) )\n109 (49) )\n123 (38) )\n139 (111) )\n\n\n\n1 %; Mean (SD) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild ModelModel Plots\n\n\n\nThe code fits a linear mixed model to examine the ‘Height’ variable across time points (‘eventname’). It incorporates both random intercepts and slopes for the time points (‘eventname’) within each participant (‘src_subject_id’) to capture individual-level variability in both starting values and rates of change over time. The results of the model are then printed to provide a detailed summary of the fitted model parameters.\nSTEP 1: Compute LMM with Random Intercepts and Slopes\n\n\nCode\n## Linear Mixed Model with a random intercept and random slope (LMM-ris)\nrandom_intercepts_slopes &lt;- lmer(anthroheightcalc ~ 1 + eventname + (1|src_subject_id), data = df, REML=T)\n\nprint(random_intercepts_slopes)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: anthroheightcalc ~ 1 + eventname + (1 | src_subject_id)\n   Data: df\nREML criterion at convergence: 201982\nRandom effects:\n Groups         Name        Std.Dev.\n src_subject_id (Intercept) 2.96    \n Residual                   2.26    \nNumber of obs: 40172, groups:  src_subject_id, 11867\nFixed Effects:\n(Intercept)  eventname.L  eventname.Q  eventname.C  eventname^4  \n    60.0627       7.5412      -0.1736      -0.0703       0.1542  \n\n\n\n\nCode\n## Output and reports extending from the LMM-ris analyses\nsummary(random_intercepts_slopes)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: anthroheightcalc ~ 1 + eventname + (1 | src_subject_id)\n   Data: df\n\nREML criterion at convergence: 201982\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-21.00  -0.31  -0.01   0.32  65.93 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n src_subject_id (Intercept) 8.76     2.96    \n Residual                   5.12     2.26    \nNumber of obs: 40172, groups:  src_subject_id, 11867\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  60.0627     0.0304 1972.86\neventname.L   7.5412     0.0308  244.55\neventname.Q  -0.1736     0.0290   -5.99\neventname.C  -0.0703     0.0320   -2.20\neventname^4   0.1542     0.0286    5.39\n\nCorrelation of Fixed Effects:\n            (Intr) evnt.L evnt.Q evnt.C\neventname.L  0.218                     \neventname.Q  0.024  0.258              \neventname.C -0.075 -0.031  0.389       \neventname^4 -0.072 -0.089  0.208  0.435\n\n\nCode\nconfint(random_intercepts_slopes, level = 0.95, method = \"Wald\")\n\n\n              2.5 %   97.5 %\n.sig01           NA       NA\n.sigma           NA       NA\n(Intercept) 60.0030 60.12236\neventname.L  7.4808  7.60168\neventname.Q -0.2304 -0.11682\neventname.C -0.1330 -0.00762\neventname^4  0.0981  0.21032\n\n\nCode\nreport_performance(random_intercepts_slopes)\n\n\nThe model's total explanatory power is substantial (conditional R2 = 0.78) and the part related to the fixed effects alone (marginal R2) is of 0.41\n\n\nThe code fits a Linear Mixed Model (LMM:ris) to predict children’s height based on different time points (denoted as eventname). Individual variability is captured through random intercepts associated with each participant (src_subject_id). The results suggest a significant change in height across the time points, with the model accounting for 89% (r round(conditional_R2, 2)) of the total variation and 37% (r round(marginal_R2, 2)) attributed to the fixed effects alone.\nIn the model, the linear term for eventname has an estimated effect of r round(model_summary$coefficients[“eventname.L”, “Estimate”], 2), indicating a significant increase in height across time points. Additionally, there’s variability in initial height across participants, reflected by a random intercept standard deviation of r round(random_effects[“src_subject_id”, “Std.Dev.”], 2).\n\n\n\n\nThe following set of plots are used to facilitate model diagnostics. The first is a histogram showcasing the distribution of random intercepts for individual subjects, indicating variations in height not explained by the fixed effects. The second depicts residuals versus fitted values, helping assess the model’s fit and potential heteroscedasticity. The third contrasts observed and predicted height values across different time points, offering a side-by-side evaluation of the model’s predictions against actual observations.\n\n\nCode\n# Assuming your model is named `random_intercepts_slope`\n# 1. Extract the random effects\nrandom_effects &lt;- ranef(random_intercepts_slopes)[[1]]\n\n# 2. Convert to dataframe\nrandom_effects_df &lt;- data.frame(Intercept = random_effects$`(Intercept)`)\n\n# Plot 1: Histogram\n# Plot 1: Histogram\nhist_plot &lt;- ggplot(random_effects_df, aes(x = Intercept)) +\n  geom_histogram(aes(y = ..density..), bins = 30, color = \"black\", fill = \"lightblue\") +\n  labs(title = \"Histogram of Random Effects\", x = \"Random Intercept Values\", y = \"Density\") +\n  theme_minimal()\n\nprint(hist_plot)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Extract the data frame used in the model\nmodel_data &lt;- random_intercepts_slopes@frame\n\n# Extract unique subject IDs from the model's data\noriginal_subject_ids &lt;- unique(model_data$src_subject_id)\n\n# Subset the original data to include only those subjects\ndf_subset &lt;- df %&gt;% filter(src_subject_id %in% original_subject_ids)\n\neventname_map &lt;- c(\n  \"baseline_year_1_arm_1\" = \"Baseline\",\n  \"1_year_follow_up_y_arm_1\" = \"Year_1\",\n  \"2_year_follow_up_y_arm_1\" = \"Year_2\",\n  \"3_year_follow_up_y_arm_1\" = \"Year_3\",\n  \"4_year_follow_up_y_arm_1\" = \"Year_4\"\n)\n\n# Plot\nggplot(df, aes(x = eventname, y = anthroheightcalc, group = src_subject_id)) +\n  \n# Individual estimated height trajectories in faded lines\ngeom_line(aes(group = src_subject_id), alpha = 0.3, color = \"grey50\") +\n\n# Overall group-mean trajectory in blue with increased thickness\nstat_summary(aes(group = 1), fun = mean, geom = \"line\", color = \"blue\", linewidth = 1) +\nlabs(title = \"Individual and Group-Mean Height Trajectories\",\n     x = \"Event Name\",\n     y = \"Height\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe provided code visualizes individual and group-mean height trajectories over different event names. Individual height trajectories for each subject are depicted as faded gray lines, allowing for a clear view of the variability among subjects. In contrast, the overall group-mean trajectory, which represents the average trend across all individuals for each event name, is highlighted in blue. The average height at r mean(df_descriptableHeight) has increased by r mean(df_descriptableHeight_followup - df_descriptable$Height) units from baseline.\n\n\n\n\n\n\n\n\n\nWrite-up\n\n\n\nThe linear mixed model analysis was conducted to predict children’s height across different time points (Baseline, Year_1, Year_2, Year_3, and Year_4). The eventname predictor was statistically significant with a p-value of r format.pval(fixed_effectsPr(&gt;|t|)[2], digits = 3). The model's overall ability to explain the variance in height was xxxxx, with a conditional R^2 of r report_performance(random_intercepts)Conditional R2[1], indicating that it accounted for this proportion of the variability in height when considering both fixed and random effects. The marginal R^2 was r report_performance(random_intercepts)$Marginal R2[1], meaning that the fixed effects alone explained this proportion of the variability."
  },
  {
    "objectID": "examples/3b_Examples_LinearMixedModels.html#overview",
    "href": "examples/3b_Examples_LinearMixedModels.html#overview",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "The Linear Mixed Model with a random intercept and slope (LMM:ris) extends the traditional fixed-effect linear regression by incorporating both a subject-specific random intercept and a random slope. This allows each participant to have their own unique intercept and slope values, reflecting individual starting points and rates of change, in addition to the overall mean-level (fixed-effect) trajectory.\nIn this example, we will utilize the LMM:ris to analyze height trajectories obtained across multiple measurement occasions for a sample of youth participating in the ABCD Study. Our primary objective is to understand the stability and evolution in height measurements, while factoring in the clustered nature of observations within individuals over time. The LMM:ris facilitates this by concurrently modeling an overarching sample mean trajectory (fixed effect) and individual variations (random effects) in both starting points (intercepts) and growth rates (slopes) around this mean trajectory."
  },
  {
    "objectID": "examples/3b_Examples_LinearMixedModels.html#preliminary-setup",
    "href": "examples/3b_Examples_LinearMixedModels.html#preliminary-setup",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "Install PackagesLoad PackagesConfig Options\n\n\n\n\nThis code installs the r packages necessary for this example, if they are not already installed\n\n\n\nCode\n# Create a list of required packages\npackages_required &lt;- c(\"tidyverse\",\"rstatix\",\"DT\",\"lme4\",\"report\",\"broom\",\"gridExtra\",\"easystats\",\"gtsummary\")\n\n# Check which packages are not installed and install them\npackages_to_install &lt;- setdiff(packages_required, rownames(installed.packages()))\nif (length(packages_to_install) &gt; 0) {\n    install.packages(packages_to_install)\n}\n\n# Load the required packages\nlapply(packages_required, library, character.only = TRUE)\n\n\n\n\n\n\nThis code loads the r libraries necessary for this example\n\n\nCode\nlibrary(tidyverse)    # Collection of R packages for data science\nlibrary(rstatix)      # Pipe-friendly framework for basic statistical tests\nlibrary(DT)           # Rendering interactive data tables\nlibrary(lme4)         # Linear mixed-effects models\nlibrary(report)       # Easy reporting of regression analyses\nlibrary(broom)        # Tidy and augment statistical models output\nlibrary(gridExtra)    # Arrange multiple grid-based plots on a page\nlibrary(easystats)    #\nlibrary(gtsummary)    #\n\n\n\n\n\n\nThis code configures knitr code chunk options\n\n\nCode\nknitr::opts_chunk$set(echo = T, message=F, warning=F, error=F, \n                      comment=NA, cache=T, code_folding=T,\n                      R.options=list(width=220, digits = 3),\n                      fig.align='center', \n                      out.width='75%', fig.asp=.75)"
  },
  {
    "objectID": "examples/3b_Examples_LinearMixedModels.html#descriptives-overview",
    "href": "examples/3b_Examples_LinearMixedModels.html#descriptives-overview",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "Read and View DataDescriptives\n\n\n\nThis code reads in and shows the data to be used in the current example\n\n\nCode\n# Set the data paths\ndata_path_1 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/demo5.0.rds\"\ndata_path_2 &lt;- \"/Users/shawes/ABCD/data/rds/abcd_5.0_rds/core-rds-5.0/non-imaging_excluding_nt_5.0.rds\"\n\n# Read the data\ndata_demographics &lt;- readRDS(data_path_1)\ndata_nonimaging &lt;- readRDS(data_path_2)\n\n# Subset the nonimaging data to include desired variables\nselected_vars &lt;- c(\"src_subject_id\", \"eventname\", \"nihtbx_totalcomp_fc\", \"anthroweightcalc\", \"anthroheightcalc\")\nsubset_data &lt;- data_nonimaging[, selected_vars]\n\nlibrary(dplyr)\n# # Merge the datasets on 'src_subject_id' and 'eventname'\nmerged_data &lt;- data_demographics %&gt;%\n  full_join(subset_data, by = c(\"src_subject_id\", \"eventname\"))\n\n# Inspect the merged data structure\nstr(merged_data)\n\n# Define event names to be retained in the analysis and convert variables to appropriate data types\neventnames_to_include &lt;- c(\"baseline_year_1_arm_1\",\n                           \"1_year_follow_up_y_arm_1\",\n                           \"2_year_follow_up_y_arm_1\",\n                           \"3_year_follow_up_y_arm_1\",\n                           \"4_year_follow_up_y_arm_1\")\n\ndf &lt;- merged_data %&gt;%\n  filter(eventname %in% eventnames_to_include) %&gt;%\n  mutate(\n    src_subject_id = as.factor(src_subject_id),\n    eventname = factor(eventname, levels = eventnames_to_include, ordered = TRUE),\n    age = as.numeric(age),\n    sex = as.factor(sex),\n    race.4level = as.factor(race.4level),\n    hisp = as.factor(hisp),\n    high.educ.bl = as.factor(high.educ.bl),\n    household.income.bl = as.factor(household.income.bl),\n    acs_raked_propensity_score = as.numeric(acs_raked_propensity_score),\n    rel_family_id.bl = as.factor(rel_family_id.bl),\n    site_id_l = as.factor(site_id_l),\n    nihtbx_totalcomp_fc = as.numeric(nihtbx_totalcomp_fc),\n    anthroweightcalc = as.numeric(anthroweightcalc),\n    anthroheightcalc = as.numeric(anthroheightcalc)\n  ) %&gt;%\n  # Exclude cases from unused assessment waves\n  filter(!is.na(eventname))\n\n\n\n\n\n\nThis code creates a descriptives table\n\n\nCode\ndescriptives_table &lt;- df %&gt;%\n  select(eventname, sex, race.4level, hisp, anthroweightcalc) %&gt;%\n  mutate(eventname = factor(eventname, labels = c(\"Baseline\", \"Year 1\",\"Year 2\",\"Year 3\",\"Year 4\"))) %&gt;%\n  mutate(sex = factor(sex, labels = c(\"Female\", \"Male\"))) %&gt;%\n  tbl_summary(\n    by = eventname,\n    missing = \"no\",\n    label = list(sex ~ \"Sex\", race.4level ~ \"Race\", hisp ~ \"Hispanic\", \n                 anthroweightcalc ~ \"Weight\"),\n    statistic = list(all_continuous() ~ \"{mean} ({sd}) )\", all_categorical() ~ \"{p}%\"),\n  ) %&gt;%\nmodify_header(all_stat_cols() ~ \"**{level}**&lt;br&gt;N = {n}\") %&gt;%\n  bold_labels() %&gt;%\n  italicize_levels() %&gt;%\n  modify_spanning_header(all_stat_cols() ~ \"**Assessment Wave**\")\ntheme_gtsummary_compact()\n\ndescriptives_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nAssessment Wave\n\n\nBaseline\nN = 118681\nYear 1\nN = 112201\nYear 2\nN = 109731\nYear 3\nN = 103361\nYear 4\nN = 47541\n\n\n\n\nSex\n\n\n\n\n\n\n\n    Female\n48%\n48%\n48%\n47%\n48%\n\n\n    Male\n52%\n52%\n52%\n53%\n52%\n\n\nRace\n\n\n\n\n\n\n\n    Asian\n0.5%\n0.4%\n0.4%\n0.5%\n0.4%\n\n\n    Black\n16%\n15%\n15%\n14%\n12%\n\n\n    Other/Mixed\n17%\n17%\n17%\n17%\n16%\n\n\n    White\n66%\n67%\n67%\n68%\n72%\n\n\nHispanic\n21%\n20%\n20%\n20%\n21%\n\n\nWeight\n83 (24) )\n94 (28) )\n109 (49) )\n123 (38) )\n139 (111) )\n\n\n\n1 %; Mean (SD) )"
  },
  {
    "objectID": "examples/3b_Examples_LinearMixedModels.html#results",
    "href": "examples/3b_Examples_LinearMixedModels.html#results",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "Build ModelModel Plots\n\n\n\nThe code fits a linear mixed model to examine the ‘Height’ variable across time points (‘eventname’). It incorporates both random intercepts and slopes for the time points (‘eventname’) within each participant (‘src_subject_id’) to capture individual-level variability in both starting values and rates of change over time. The results of the model are then printed to provide a detailed summary of the fitted model parameters.\nSTEP 1: Compute LMM with Random Intercepts and Slopes\n\n\nCode\n## Linear Mixed Model with a random intercept and random slope (LMM-ris)\nrandom_intercepts_slopes &lt;- lmer(anthroheightcalc ~ 1 + eventname + (1|src_subject_id), data = df, REML=T)\n\nprint(random_intercepts_slopes)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: anthroheightcalc ~ 1 + eventname + (1 | src_subject_id)\n   Data: df\nREML criterion at convergence: 201982\nRandom effects:\n Groups         Name        Std.Dev.\n src_subject_id (Intercept) 2.96    \n Residual                   2.26    \nNumber of obs: 40172, groups:  src_subject_id, 11867\nFixed Effects:\n(Intercept)  eventname.L  eventname.Q  eventname.C  eventname^4  \n    60.0627       7.5412      -0.1736      -0.0703       0.1542  \n\n\n\n\nCode\n## Output and reports extending from the LMM-ris analyses\nsummary(random_intercepts_slopes)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: anthroheightcalc ~ 1 + eventname + (1 | src_subject_id)\n   Data: df\n\nREML criterion at convergence: 201982\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-21.00  -0.31  -0.01   0.32  65.93 \n\nRandom effects:\n Groups         Name        Variance Std.Dev.\n src_subject_id (Intercept) 8.76     2.96    \n Residual                   5.12     2.26    \nNumber of obs: 40172, groups:  src_subject_id, 11867\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  60.0627     0.0304 1972.86\neventname.L   7.5412     0.0308  244.55\neventname.Q  -0.1736     0.0290   -5.99\neventname.C  -0.0703     0.0320   -2.20\neventname^4   0.1542     0.0286    5.39\n\nCorrelation of Fixed Effects:\n            (Intr) evnt.L evnt.Q evnt.C\neventname.L  0.218                     \neventname.Q  0.024  0.258              \neventname.C -0.075 -0.031  0.389       \neventname^4 -0.072 -0.089  0.208  0.435\n\n\nCode\nconfint(random_intercepts_slopes, level = 0.95, method = \"Wald\")\n\n\n              2.5 %   97.5 %\n.sig01           NA       NA\n.sigma           NA       NA\n(Intercept) 60.0030 60.12236\neventname.L  7.4808  7.60168\neventname.Q -0.2304 -0.11682\neventname.C -0.1330 -0.00762\neventname^4  0.0981  0.21032\n\n\nCode\nreport_performance(random_intercepts_slopes)\n\n\nThe model's total explanatory power is substantial (conditional R2 = 0.78) and the part related to the fixed effects alone (marginal R2) is of 0.41\n\n\nThe code fits a Linear Mixed Model (LMM:ris) to predict children’s height based on different time points (denoted as eventname). Individual variability is captured through random intercepts associated with each participant (src_subject_id). The results suggest a significant change in height across the time points, with the model accounting for 89% (r round(conditional_R2, 2)) of the total variation and 37% (r round(marginal_R2, 2)) attributed to the fixed effects alone.\nIn the model, the linear term for eventname has an estimated effect of r round(model_summary$coefficients[“eventname.L”, “Estimate”], 2), indicating a significant increase in height across time points. Additionally, there’s variability in initial height across participants, reflected by a random intercept standard deviation of r round(random_effects[“src_subject_id”, “Std.Dev.”], 2).\n\n\n\n\nThe following set of plots are used to facilitate model diagnostics. The first is a histogram showcasing the distribution of random intercepts for individual subjects, indicating variations in height not explained by the fixed effects. The second depicts residuals versus fitted values, helping assess the model’s fit and potential heteroscedasticity. The third contrasts observed and predicted height values across different time points, offering a side-by-side evaluation of the model’s predictions against actual observations.\n\n\nCode\n# Assuming your model is named `random_intercepts_slope`\n# 1. Extract the random effects\nrandom_effects &lt;- ranef(random_intercepts_slopes)[[1]]\n\n# 2. Convert to dataframe\nrandom_effects_df &lt;- data.frame(Intercept = random_effects$`(Intercept)`)\n\n# Plot 1: Histogram\n# Plot 1: Histogram\nhist_plot &lt;- ggplot(random_effects_df, aes(x = Intercept)) +\n  geom_histogram(aes(y = ..density..), bins = 30, color = \"black\", fill = \"lightblue\") +\n  labs(title = \"Histogram of Random Effects\", x = \"Random Intercept Values\", y = \"Density\") +\n  theme_minimal()\n\nprint(hist_plot)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Extract the data frame used in the model\nmodel_data &lt;- random_intercepts_slopes@frame\n\n# Extract unique subject IDs from the model's data\noriginal_subject_ids &lt;- unique(model_data$src_subject_id)\n\n# Subset the original data to include only those subjects\ndf_subset &lt;- df %&gt;% filter(src_subject_id %in% original_subject_ids)\n\neventname_map &lt;- c(\n  \"baseline_year_1_arm_1\" = \"Baseline\",\n  \"1_year_follow_up_y_arm_1\" = \"Year_1\",\n  \"2_year_follow_up_y_arm_1\" = \"Year_2\",\n  \"3_year_follow_up_y_arm_1\" = \"Year_3\",\n  \"4_year_follow_up_y_arm_1\" = \"Year_4\"\n)\n\n# Plot\nggplot(df, aes(x = eventname, y = anthroheightcalc, group = src_subject_id)) +\n  \n# Individual estimated height trajectories in faded lines\ngeom_line(aes(group = src_subject_id), alpha = 0.3, color = \"grey50\") +\n\n# Overall group-mean trajectory in blue with increased thickness\nstat_summary(aes(group = 1), fun = mean, geom = \"line\", color = \"blue\", linewidth = 1) +\nlabs(title = \"Individual and Group-Mean Height Trajectories\",\n     x = \"Event Name\",\n     y = \"Height\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe provided code visualizes individual and group-mean height trajectories over different event names. Individual height trajectories for each subject are depicted as faded gray lines, allowing for a clear view of the variability among subjects. In contrast, the overall group-mean trajectory, which represents the average trend across all individuals for each event name, is highlighted in blue. The average height at r mean(df_descriptableHeight) has increased by r mean(df_descriptableHeight_followup - df_descriptable$Height) units from baseline."
  },
  {
    "objectID": "examples/3b_Examples_LinearMixedModels.html#wrapping-up",
    "href": "examples/3b_Examples_LinearMixedModels.html#wrapping-up",
    "title": "Linear Mixed Models: Random Intercept and Slope",
    "section": "",
    "text": "Write-up\n\n\n\nThe linear mixed model analysis was conducted to predict children’s height across different time points (Baseline, Year_1, Year_2, Year_3, and Year_4). The eventname predictor was statistically significant with a p-value of r format.pval(fixed_effectsPr(&gt;|t|)[2], digits = 3). The model's overall ability to explain the variance in height was xxxxx, with a conditional R^2 of r report_performance(random_intercepts)Conditional R2[1], indicating that it accounted for this proportion of the variability in height when considering both fixed and random effects. The marginal R^2 was r report_performance(random_intercepts)$Marginal R2[1], meaning that the fixed effects alone explained this proportion of the variability."
  }
]