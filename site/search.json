[
  {
    "objectID": "manuscript/manuscript.html",
    "href": "manuscript/manuscript.html",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "The Adolescent Brain Cognitive Development (ABCD) Study® is the largest long-term investigation of neurodevelopment and child health in the United States. Conceived and initiated by the National Institutes of Health (NIH), this landmark prospective longitudinal study aims to transform our understanding of the genetic and environmental factors impacting neurodevelopment and their roles in behavioral and health outcomes across ten years of adolescence (Volkow et al. 2018). At its heart, the study is designed to chart the course of human development across multiple interacting domains from late childhood to early adulthood and to identify factors that lead to both positive and negative outcomes. Central to achieving these goals is the commitment of the ABCD Study® and its NIH funders to an open science framework, intended to facilitate sharing of data and analytical methods, by espousing practices that increase access, integrity, and reproducibility of scientific research. In this sense, the ABCD Study is a collaboration with the larger research community.\nThe size and scope of the ABCD Study data allow the research community to perform a large variety of developmental analyses of both substantive and methodological interest, presenting a unique opportunity to significantly advance our understanding of how a multitude of biopsychosocial processes unfold across critical periods of development. In this paper, we describe models and methods for longitudinal analysis of ABCD Study data that can address these fundamental scientific aims, including: 1) characterization of the genetic and environmental factors associated with variation in developmental trajectories; 2) assessment of how the level and timing of exposures may impact subsequent neurodevelopment; 3) quantification of how variation in developmental domains may be associated with outcomes, including mediation models and reciprocal relationships. We instantiate these longitudinal analyses in worked examples using the ABCD Release 5.0 data with accompanying R scripts. Worked examples are available in Quarto files, accessible at XXXX.\n\n\nThe ABCD Study enrolled a cohort of n=11,880 participants born between 2006-2008 and aged between 9-11 years at baseline, as well as their parents/guardians. The study sample was recruited from household populations in defined catchment areas for each of the 21 (originally 22) study sites across the United States. Information regarding funding agencies, recruitment sites, investigators, and project organization can be obtained at https://abcdstudy.org/. The ABCD Study design is described in more detail in Garavan et al. (2018) and Dick et al. (2021).\nThe ABCD Study is currently collecting longitudinal data on a rich variety of outcomes that will enable the construction of complex statistical models potentially incorporating factors from many domains. Each new wave of data collection provides another building block for characterizing developmental trajectories and implementing longitudinal analyses that allow researchers to characterize normative development, to identify variables that presage deviations from normative development, and to assess a range of variables associated with biopsychosocial outcomes of interest. These data include: 1) a neurocognitive battery (Luciana et al. 2018; Wesley K. Thompson et al. 2019); 2) mental and physical health assessments (Barch et al. 2018); 3) measures of culture and environment (Gonzalez et al. 2021; Zucker et al. 2018); 4) substance use (Lisdahl et al. 2021); 5) gender identity and sexual health (Potter et al. 2022); 6) biospecimens (Uban et al. 2018); 7) structural and functional brain imaging (Casey et al. 2018; Hagler et al. 2019); 8) geolocation-based environmental exposure data (Fan et al. 2021); 9) wearables, and mobile technology (Bagot et al. 2018); and 10) whole genome genotyping (Loughnan et al. 2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual telephone interviews between in-person visits.\nData are publicly released roughly annually, currently through the NIMH Data Archive (NDA). By necessity, the study’s earliest data releases consisted primarily of one or two visits per participant. However, the most recent public release as of the writing of this paper (Release 5.0) contains data collected across five annual visits, including three brain imaging assessments (baseline, year 2 follow-up, and year 4 follow-up visits) for at least a subset of the cohort. Hence, starting with Release 5.0, it is feasible for researchers to begin focusing on the estimation of neurodevelopmental and other trajectories.\n\n\n\n\n\n\n\n\n\nOrganization and Aims\n\n\n\n\n\n• Part I. Longitudinal Research\n\nIdentify fundamental concepts\n\n• Part II. Longitudinal Data\n\nHighlight key challenges\n\n• Part III. Longitudinal Analysis\n\nMethods & Analysis\n\n• Part IV. Supplemental materials\n\nLinked open-source resources",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#the-abcd-study-data",
    "href": "manuscript/manuscript.html#the-abcd-study-data",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "The ABCD Study enrolled a cohort of n=11,880 participants born between 2006-2008 and aged between 9-11 years at baseline, as well as their parents/guardians. The study sample was recruited from household populations in defined catchment areas for each of the 21 (originally 22) study sites across the United States. Information regarding funding agencies, recruitment sites, investigators, and project organization can be obtained at https://abcdstudy.org/. The ABCD Study design is described in more detail in Garavan et al. (2018) and Dick et al. (2021).\nThe ABCD Study is currently collecting longitudinal data on a rich variety of outcomes that will enable the construction of complex statistical models potentially incorporating factors from many domains. Each new wave of data collection provides another building block for characterizing developmental trajectories and implementing longitudinal analyses that allow researchers to characterize normative development, to identify variables that presage deviations from normative development, and to assess a range of variables associated with biopsychosocial outcomes of interest. These data include: 1) a neurocognitive battery (Luciana et al. 2018; Wesley K. Thompson et al. 2019); 2) mental and physical health assessments (Barch et al. 2018); 3) measures of culture and environment (Gonzalez et al. 2021; Zucker et al. 2018); 4) substance use (Lisdahl et al. 2021); 5) gender identity and sexual health (Potter et al. 2022); 6) biospecimens (Uban et al. 2018); 7) structural and functional brain imaging (Casey et al. 2018; Hagler et al. 2019); 8) geolocation-based environmental exposure data (Fan et al. 2021); 9) wearables, and mobile technology (Bagot et al. 2018); and 10) whole genome genotyping (Loughnan et al. 2020). Many of these measures are collected at in-person annual visits, with brain imaging collected at baseline and every other year going forward. A limited number of assessments are collected in semi-annual telephone interviews between in-person visits.\nData are publicly released roughly annually, currently through the NIMH Data Archive (NDA). By necessity, the study’s earliest data releases consisted primarily of one or two visits per participant. However, the most recent public release as of the writing of this paper (Release 5.0) contains data collected across five annual visits, including three brain imaging assessments (baseline, year 2 follow-up, and year 4 follow-up visits) for at least a subset of the cohort. Hence, starting with Release 5.0, it is feasible for researchers to begin focusing on the estimation of neurodevelopmental and other trajectories.",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#section",
    "href": "manuscript/manuscript.html#section",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "",
    "text": "Organization and Aims\n\n\n\n\n\n• Part I. Longitudinal Research\n\nIdentify fundamental concepts\n\n• Part II. Longitudinal Data\n\nHighlight key challenges\n\n• Part III. Longitudinal Analysis\n\nMethods & Analysis\n\n• Part IV. Supplemental materials\n\nLinked open-source resources",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#basic-concepts-and-considerations",
    "href": "manuscript/manuscript.html#basic-concepts-and-considerations",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "2.1 Basic Concepts and Considerations",
    "text": "2.1 Basic Concepts and Considerations\nThere are several important concepts to consider when conducting longitudinal analyses in a developmental context. These include different ways of thinking about developmental course, whether certain periods of development are relatively sensitive or insensitive to various types of insults or stressors, whether some time periods or situations inhibit the expression of individual differences due to extreme environmental pressures, and whether the same behavior manifested at different times represents the same or different phenomena.\nMoreover, in the case of developmentally-focused longitudinal research, each new measurement occasion not only provides a more extended portrait of the child’s life course but also brings with it greater methodological opportunities to make use of statistical models that distinguish within- from between-person effects and that loosen constraints that need to be imposed on the furtherance of critical scientific questions.\nFor example, collecting two or more within-person observations on the same construct at different times enables estimation of individual rates of change (slopes); more observations allow for more precise estimates of individual slopes, as well as characterization of non-linear development. Rate of change or other trajectory characteristics may be more informative about individuals than the simple snapshots of level differences that cross-sectional data are limited to informing. Cross-sectional age-related differences across individuals are poor substitutes for longitudinal trajectory estimates except under highly restrictive assumptions, e.g., parallel trajectories and lack of age cohort and experience effects (Wesley K. Thompson et al. 2011). Appreciation of these and other issues can help to guide the analysis and interpretation of data and aid translation to clinical and public health applications.\n\n2.1.1 Vulnerable periods.\nAdolescent development progresses normatively from less mature to more mature levels of functioning. However, unique epochs and experiences can alter the course of this idealized form of development. Consider research that shows cannabis use during adolescence is associated with later psychosis to a greater degree than cannabis use initiated later in development (Arseneault et al. 2002; Bechtold et al. 2016; Hasan et al. 2020; Semple, McIntosh, and Lawrie 2005); or similarly, experimental research on rodents that shows rodent brains to be especially sensitive to the neurotoxic effects of alcohol on brain structure and learning early in development, corresponding to early adolescence in humans (Spear 2016; Crews et al. 2000; Ji et al. 2018). In another example, longitudinal data from the National Consortium on Alcohol in Adolescence (NCANDA) show that binge drinking is associated more strongly with decrements in gray matter volume early in adolescence compared to later (Infante et al. 2022). These examples highlight the importance of considering the role of vulnerable periods – e.g., temporal windows of rapid brain development or remodeling during which the effects of environmental stimuli on the developing brain may be particularly pronounced– when trying to establish an accurate understanding of the association between exposures and outcomes.\n\n\n2.1.2 Developmental disturbances.\nWhereas vulnerable periods heighten neurobiological susceptibility to environmental influences, at other times, environmental exposures will tend to suppress stability and disrupt the orderly stochastic process of normative development (e.g., Schulenberg et al. 2019). This situation reflects a developmental disturbance in that the normal course of development is “altered” for a time by some time-limited process. In such cases, we might find that prediction of behavior in the period of the disturbance is reduced and/or, similarly, the behavior exhibited during the disturbance might have less predictive power with respect to distal outcomes compared to the behavior exhibited before and following the disrupted period. That is, once the environmental presses are removed (or the individual is removed from the environment), patterns of individual differences (and autoregressive effects) recover to levels similar to those prior to entering the environment. For example, in Infante et al. (2022), recent binge drinking appears to be most predictive of gray matter volume trajectories, as opposed to more distal prior binge drinking or cumulative number of binge drinks, suggesting the potential for recovery of gray matter trajectories to prior levels of growth if binge drinking levels subside.\n\n\n2.1.3 Developmental snares and cascade effects.\nNormative development can also be upended by experiences (e.g., drug use) that, through various mechanisms, disrupt the normal flow of development wherein each stage establishes a platform for the next. For instance, substance use could lead to association with deviant peers, precluding opportunities for learning various adaptive skills and prosocial behaviors, in effect creating a “snare” that delays psychosocial development, such as maturing out of adolescent antisocial behavior (Moffitt 2015). Relatedly, the consequences of these types of events can cascade (e.g., school dropout, involvement in the criminal justice system) so that the effects of the snare are amplified (e.g., Masten et al. 2005; Rogosch, Oshri, and Cicchetti 2010). Although conceptually distinct from vulnerable periods, both types of developmental considerations highlight the importance of viewing behavior in the context of development and attempting to determine how various developmental pathways unfold. Longitudinal data are crucial in this context to assess individual levels of development prior to and following onset of experiences or other environmental factors; e.g., the ABCD Study collected data starting at ages 9-10 and hence before the onset of substance use for the vast majority of participants.\n2.1.4 Intermediate processes and feedback loops Something here on the concept of mediation and cross-lagged relationships?",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  },
  {
    "objectID": "manuscript/manuscript.html#interpretation-issues-pitfalls-assumption",
    "href": "manuscript/manuscript.html#interpretation-issues-pitfalls-assumption",
    "title": "Longitudinal Analysis Manuscript: Working Draft",
    "section": "3.1 Interpretation / Issues / Pitfalls & Assumption",
    "text": "3.1 Interpretation / Issues / Pitfalls & Assumption\nThe hallmark characteristic of longitudinal data analysis is the administration of repeated measurements of the same constructs on assessment targets (e.g., individuals, families) across time. The primary rationale for collecting longitudinal data is to assess within-person change over time, allowing researchers to estimate individual developmental trajectories and the genetic and/or environmental factors that may impact these trajectories. Administering repeated measurements more frequently or over longer time spans enables researchers to ask more nuanced questions and to make stronger inferences.\n\n3.1.1 Two Time Points versus Three or More.\nAlthough the clear leap from cross-sectional to the realm of longitudinal data involves going from one assessment to two or more assessments, there are also notable distinctions in designs based on two-assessment points versus three or more measurement occasions. Just as cross-sectional data can be informative in some situations, two waves of data can be beneficial in contexts such as when experimental manipulation is involved (e.g., pre/post tests), or if the central goal is prediction (e.g., trying to predict scores on Variable A at time T as a function of prior scores on Variable A and Variable B at time T-1). At the same time, data based on two assessments are inherently limited on multiple fronts. As Rogosa, Brandt, and Zimowski (1982) noted over forty years ago, “Two waves of data are better than one, but maybe not much better” (p. 744).\nThese sentiments are reflected in more contemporary recommendations regarding best-practice guidelines for prospective data, which increasingly emphasize the benefits of additional measurement occasions for trajectory estimation, model identification and accurate parameter inferences. It is also consistent with research recommending that developmental studies include three or more assessment points, given it is impossible for data based on two-time points to determine the shape of development (given that linear change is the only estimable form for two assessments waves; (see Duncan and Duncan 2009)). Research designs that include three (but preferably more) time points allow for non-linear trajectory estimation and increasingly nuanced analyses that more adequately tease apart sources of variation and covariation among the repeated assessments (King et al. 2018)– a key aspect of developmental research.\nTo illustrate, developmental theories are useful for understanding patterns of within-individual change over time (discussed in further detail, below); however, two data points provide meager information on change at the person level. This point is further underscored in a recent review of statistical models commonly touted as distinguishing within-individual vs between-individual sources of variance in which the study authors concluded “… researchers are limited when attempting to differentiate these sources of variation in psychological phenomenon when using two waves of data” and perhaps more concerning, “…the models discussed here do not offer a feasible way to overcome these inherent limitations” (Andrew K. Littlefield et al. 2021). It is important to note, however, that despite the current focus on two-wave designs versus three or more assessment waves, garnering three assessment points is not a panacea for longitudinal modeling. Indeed, several contemporary longitudinal models designed to isolate within-individual variability (e.g., the Latent Curve Model with Structured Residuals; Patrick J. Curran et al. (2014)) require at least four assessments to parameterize fully and, more generally, increasingly accurate and nuanced parameter estimates are obtained as more assessment occasions are used (Duncan and Duncan 2009).\n\n\n3.1.2 Types of stability and change\nIf one were to try to sum up what developmental trajectories in a living organism are exactly, one could plausibly argue they are the patterns of stability and change in its phenotypes as the organism traverses the life course. Symbolically, developmental trajectories can be expressed as fi(t), a possibly multivariate function of time t, specific to the ith individual and typically taking values in the real numbers for continuous phenotypes and the integers for discrete phenotypes. Ideally, t is a biologically meaningful temporal index (e.g., calendar age) as opposed to an exogenous progression of events (e.g., study visit number). Properties of interest might include rate of change over time, degree of smoothness (e.g., continuously differentiable), shape (e.g., polynomial or asymptotic behavior), how and how much fi(t) differs across individuals, and what factors predict either within-individual variation (at different times) or between-individual variation (either overall or at specific times).\nThere are a few different ways to think about patterns of stability and change (see Figure 1). Consider measuring school disengagement at the start of middle school and the end of middle school . A common first step may be to compare sixth graders’ average disengagement values and eighth graders’ disengagement values. This comparison of the average scores for the same group of individuals at multiple time points is referred to as “mean-level”, as it provides information about change over time (or lack thereof) for an outcome of interest aggregated across members of a group. In contrast, “between-individual” stability could be assessed, e.g., by calculating the Spearman correlation between the values obtained at different time points (e.g., ‘disengagement in sixth grade’ with ’disengagement in eighth grade). This analysis focuses on the degree to which individuals retain their relative placement in a group across time. Consider someone who reported the lowest frequencies of disengagement in 6th grade and may report significantly higher disengagement over middle school (i.e., exhibit high levels of change), but report the lowest frequencies of disengagement in eighth grade. That is, the individual is manifesting rank-order stability, even in the context of high mean-level change.\nBoth types of stability and change are important. Mean-level change in certain traits might help to explain why, in general, populations of individuals tend to be particularly vulnerable to the effects of environmental factors in specific age ranges; rank-order stability might help to quantify the extent to which certain characteristics of the individual are more or less trait-like compared to others. For example, in some areas of development, considerable mean-level change occurs over time (e.g., changes in Big 5 personality traits; Bleidorn et al. (2022)), but exhibit relatively high rank-order stability, at least over shorter measurement intervals (Bleidorn et al. 2022; Roberts and DelVecchio 2000; Roberts, Walton, and Viechtbauer 2006). Despite the useful information afforded by examining mean-level and rank-order stability and change, these approaches are limited in that they provide little information about the overall patterns of within-individual change (i.e., trajectories) and, in turn, can result in fundamental misinterpretations about substantial or meaningful changes in an outcome of interest (Patrick J. Curran and Bauer 2011). For example, questions related to the impact of early-onset substance use on brain development focus on changes within a given individual (i.e., intraindividual differences). The longitudinal nature of the ABCD Study, which will provide researchers with over ten time points for some constructs (e.g., substance use) across a ten-year period, allows for the study of within-person processes.\n!Types of Stability and Change\n\n\n3.1.3 Use of appropriate longitudinal models\nThere is growing recognition that statistical models commonly applied to longitudinal data often fail to align with the developmental theory they are being used to assess (e.g., Patrick J. Curran and Bauer 2011; Hoffman 2015; Andrew K. Littlefield et al. 2021). First, developmental studies typically involve the use of prospective data to inform theories that are concerned with clear within-person processes (e.g., how phenotypes change or remain stable within individuals over time, (e.g., Patrick J. Curran and Bauer 2011)). Despite this, methods generally unsuited for disaggregating between- and within-person effects (e.g., cross-lagged panel models [CLPM]) remain common within various extant literatures. Fortunately, there exists a range of models that have been proposed to tease apart between- and within-person sources of variance across time (see Andrew K. Littlefield et al. 2021; Orth et al. 2021). Most of these contemporary alternatives incorporate time-specific latent variables to capture between-person sources of variance and model within-person deviations around an individual’s mean (or trait) level across time (e.g., random-intercept cross-lagged panel model [RI-CLPM], Hamaker, Kuiper, and Grasman (2015); latent curve models with structured residuals [LCM-SR], Patrick J. Curran et al. (2014)). It is important to note however that these models require multiple assessments waves (e.g., four or more to fully specify the LCM-SR), additional expertise to overcome issues with model convergence, and appreciation of modeling assumptions when attempting to adjudicate among potential models in each research context (see Andrew K. Littlefield et al. (2022), for further discussion).\nSecond, many statistical models assume certain characteristics about the data to which they are being applied. Common assumptions of parametric statistical models (e.g., linear mixed-effects models) include normality and equality of variances. These assumptions must be carefully considered before finalizing analytical approaches, so that valid inferences can be made from the data, as violation of a model’s assumptions can substantively invalidate the interpretation of results. For example, longitudinal data can exhibit heterogeneous variability (i.e., the variance of the response changes over the duration of the study) that may need to be accounted for within a model. Another pertinent modeling assumption is whether trajectories are linear or non-linear. With 2-3 assessments per individual, only a linear model of within-person change is usually feasible; with more time points, higher level polynomials or models with more flexible trajectory shapes (e.g., curve smoothing via cubic splines) becomes possible [REFs]. Note, however, baseline age in the ABCD Study ranges over two full years; for some outcomes it may be desirable to include a (possibly nonlinear) effect of baseline age along with a linear effect of within-person change in age with only 2-3 assessment times (Wesley K. Thompson et al. 2013). As the study progresses and more times points are assessed, nonparametric curve estimation at the mean [GAMMs] and at the individual level may also become useful (Ramsay and Silverman 2002).\n\n\n3.1.4 Continuous and Discrete Outcomes\nImplementing valid and efficient statistical models requires an understanding of the type of data being analyzed. For example, repeated assessments within the ABCD Study can be based on continuous or discrete measures. Examples of discrete measures include repeated assessments of binary variables (e.g., past 12-month alcohol use disorder status measured across ten years), ordinal variables (e.g., caregiver-reported items measuring emotional and behavioral concerns via the Child Behavior Checklist including the categories of “Not True”, “Somewhat True”, and “Very True”), and count variables (e.g., number of cigarettes smoked per day). In many ways, the distributional assumptions of indicators used in longitudinal designs mirror the decision points and considerations when delineating across different types of discrete outcome variables, a topic that spans entire textbooks (e.g., see Lenz 2016). For example, the Mplus manual (Muthén 2017) includes examples of a) censored and censored-inflated models, b) linear growth models for binary or ordinal variables, c) linear growth models for a count outcome assuming a Poisson model, and d) linear growth models for a count outcome assuming a zero-inflated Poisson model. Beyond these highlighted examples, other distributions (e.g., negative binomial) can be assumed for the indicators when modeling longitudinal data (Ren et al. 2022). These models can account for issues that can occur when working with discrete outcomes, including overdispersion [when the variance is higher than would be expected based on a given distribution; see Lenz (2016)]. Given the sheer breadth of issues relevant to determining better models for discrete outcomes, it is not uncommon for texts on longitudinal data analysis to only cover models and approaches that assume continuous variables (e.g., T. D. Little 2013). However, some textbooks on categorical data analysis provide more detailed coverage of the myriad issues and modeling choices to consider when working with discrete outcomes [e.g., Lenz (2016), Chapter 11 for matched pair/two-assessment designs; Chapter 12 for marginal and transitional models for repeated designs, such as generalized estimating equations, and Chapter 13 for random effects models for discrete outcomes].\n\n\n3.1.5 Issues in attributing longitudinal change to development\nOne can observe systematic changes over time in a variable of interest and assume this change is attributable to development. However, various pitfalls with longitudinal data can complicate or even invalidate this conclusion. For example, if data missingness or participant dropout are related to the values of the outcome, changing sample composition as the study progresses can bias mean trajectory estimates (we describe this in more detail in Section 3.1.7 below). Another prerequisite for valid developmental interpretations of longitudinal data is to establish whether a construct is measured consistently over time, i.e., longitudinal measurement invariance (Liu et al. 2017; Van De Schoot et al. 2015; Willoughby, Wirth, and Blair 2012). Establishing longitudinal measurement invariance provides researchers with greater confidence that any change over time identified for a construct is attributable to individual change rather than a measurement artifact. For example, one study using data from the ABCD Study [Brislin et al. (2023)) found differential item functioning in two items from a brief delinquency measure, revealing significant bias in an arrest item across Black and White youth. More specifically, Black youth were more likely to report being arrested compared to White youth with similar levels of delinquency. Prevalence rates of delinquent behavior would have been severely biased if measurement invariance had not been tested.\nObserved patterns of growth and decline often differ between cross-sectional vs. longitudinal effects (Salthouse 2014) where subjects gain increasing experience with the assessment with each successive measurement occasion. Such experience effects on cognitive functioning have been demonstrated in adolescent longitudinal samples similar to ABCD (Sullivan et al. 2017) and highlight the need to consider these effects and address them analytically. In the case of performance-based measures [e.g., matrix reasoning related to neurocognitive functioning; see Salthouse (2014)], this can be due to “learning” the task from previous test administrations (e.g., someone taking the test a second time performs better than they did the first time simply as a function of having taken it before). Even in the case of non-performance-based measures (e.g., levels of depression), where one cannot easily make the argument that one has acquired some task-specific skill through learning, it has been observed that respondents tend to endorse lower levels on subsequent assessments (e.g., Beck et al. 1961; French and Sutton 2010) and this phenomenon has been well documented in research using structured diagnostic interviews (Robins 1985). While it is typically assumed that individuals are rescinding or telling us less information on follow-up interviews, there is reason to suspect that in some cases the initial assessment may be artefactually elevated (see Shrout et al. 2018).\nSome longitudinal studies, e.g., accelerated longitudinal designs [ALDs; Wesley K. Thompson et al. (2011)] are especially well suited for discovering these effects and modeling them. While ABCD is not an ALD, the variability in age (and grade in school) at the time of baseline recruitment (9 years, 0 months to 10 years, 11 months) allows some measures, collected every year, to be conceptualized as an ALD (e.g., substance use; prosocial behavior; family conflict; screen time). It is possible that in later waves, analyses will allow for disaggregating the confounded effects of age and the number of prior assessments. However, ABCD is fundamentally a single-cohort, longitudinal design, wherein number of prior assessments and age are mostly confounded, and for, perhaps, most analyses, the possible influence of experience effects needs to be kept in mind.\n\n\n3.1.6 Covariance Structures\nA central issue for repeated measurements on an individual is how to account for the correlated nature of the data. Traditional techniques, such as a standard regression or ANOVA model, assume residuals are independent and thus are inappropriate for designs that assess the same individuals across time. That is, given that residuals are no longer independent, the standard errors from the models are biased and can produce misleading inferential results. Although there are formal tests of independence for time series data (e.g., the Durbin-Watson statistic (Durbin and Watson 1950), more commonly, independence is assumed to be violated in study designs with repeated assessments. Therefore, an initial question to be addressed by a researcher analyzing prospective data is how to best model the covariance structure of said data.\nStatistical models for longitudinal data include two main components to account for assumptions that are commonly violated when working with repeated measures data: a model for the covariance among repeated measures (involving the covariance among pairs of repeated outcomes on an individual), coupled with a model for the mean response and its dependence on covariates (e.g., sex at birth). There exists a range of methods to model covariance structures, each with its own set of tradeoffs between model fit and parsimony and which may be more or less appropriate for each specific application (e.g., see Kincaid 2005).\nThere are various approaches to adjust models for the lack of independence of residuals across time, be it for data with repeated assessments or other situations with so-called nested data (e.g., children nested within schools; siblings nested within families). The most common approach is to use random effects. Essentially, random effects allow for variance estimates around fixed effects. A classic example (from Bryk and Raudenbush (1992); Singer (1998)) involves math achievement measured among students nested within schools. In a basic, intercept-only model with no covariates, there would be one fixed effect (the grand mean, or intercept, of math achievement) and two random effects (one representing variation in the intercept, or the variation between schools, and another for the within-school residual, or how much variance in math achievement is left over after taking into account nesting in school). From this framework, each student’s score would be a function of the fixed effect (the overall mean), the variation in scores that exists between schools, and the variation that exists among students within the same school. Assumptions about the variance and covariance components of this model dictate the form of the variance/covariance structure. For example, if we assume the random effects are independent (i.e., uncorrelated), the implied structure would be compound symmetry, where it is assumed the covariance of any two students in a single class is represented by a random effect (the variance between school means) and the covariance of any two students in different classes is zero. The assumptions of this relatively simple covariance structure can be relaxed, resulting in different covariance structures with additional parameters (see Singer (1998)).\nIn a similar fashion, individual growth models could be fit to a series of repeated assessments, where assessments are nested within individuals. For example, an unconditional linear growth model would involve two fixed effects – one for the intercept (an estimate of the average score when time is coded zero) and one for the linear slope (an estimate of the change in scores for each unit increase in time). Random effects could include a random effect for intercept (or an estimate of the variation in scores when time is coded as zero), a random effect for the linear slope (or an estimate of the variation in linear change across time), and a random effect for the within-person residual (or an estimate of the left over variance, or residual, of a given assessment when accounting for the intercept and linear slope). Assumptions regarding the covariation among the random effects also indicate different covariance structures. For example, it is typical to assume the random intercept and random slope components covary (e.g., if time is coded such that the first time point = zero, the covariance estimate suggests that an individual’s score at baseline relates to the amount of change exhibited across time). Further, particularly in structural equation model forms of this model, it is typically assumed the random effect for the within-person residual varies across assessments (Patrick J. Curran (2003)).\nOne alternative structure that attempts to handle the reality that correlations between repeated assessments tend to diminish across time is the autoregressive design. As the name implies, the structure assumes a subsequent measurement occasion (e.g., assessment at Wave 2) is regressed onto (that is, is predicted by) a prior measurement occasion (e.g., assessment at Wave 1). The most common type of autoregressive design is the AR(1), where assessments at time T + 1 are regressed on assessments at Time T. Identical to compound symmetry, this model assumes the variances are homogenous across time. Diverting from compound symmetry, this model assumes the correlations between repeated assessments decline exponentially across measurement occasions rather than remaining constant. That is, we can think of the underlying process as a stochastic one that wears itself out over time. For example, per the AR(1) structure, if the correlation between Time 1 and Time 2 data is thought to be .5, then the correlation between Time 1 and Time 3 data would be assumed to be .5 × .5 = .25, and the correlation between Time 1 and Time 4 data would be assumed to be .5 × .5 × .5 = .125. As with compound symmetry, the basic AR(1) model is parsimonious in that it only requires two parameters (the variance of the assessments and the autoregressive coefficient). Notably, the assumption of constant autoregressive relations between assessments is often relaxed in commonly employed designs that use autoregressive modeling (e.g., cross-lagged panel models [CLPM]). These designs still typically assume an AR(1) process (e.g., it is sufficient to regress the Time 3 assessment onto the Time 2 assessment and is not necessary to also regress the Time 3 assessment onto the Time 1 assessment, which would result in an AR(2) process). However, the magnitude of these relations is often allowed to differ across different AR(1) pairs of assessment (e.g., the relation between Time 1 and Time 2 can be different from the relation between Time 2 and Time 3). These more commonly employed models also often relax the assumption of equal variances of the repeated assessments. Although the AR(1) structure may involve a more realistic set of assumptions compared to compound symmetry, in that the AR(1) model allows for diminishing correlations across time, the basic AR(1) model, as well as autoregressive models more generally, can also suffer from several limitations in contexts that are common in prospective designs. In particular, recent work demonstrates that if a construct being assessed prospectively across time is trait-like in nature, then a simple AR(1) process fail to adequately account for this trait-like structure, with the downstream consequence that estimates derived from models based on AR structures (such as the CLPM) can be misleading and fail to adequately demarcate between- vs. within-person sources of variance (Hamaker, Kuiper, and Grasman 2015). Finally, it is also worth noting that in many longitudinal contexts, the time intervals between assessments are not equidistant and researchers need to consider carefully how to appropriately model time in their model and what this model implies.\n\n\n3.1.7 Missing Data/Attrition\nAttrition from a longitudinal panel study such as ABCD is inevitable and represents a potential threat to the validity of longitudinal analyses and cross-sectional analyses conducted at later time points, especially since attrition can only be expected to grow over time(Andrew K. Littlefield et al. 2022). The ABCD Retention Workgroup (RW) employs a data-driven approach to examine, track, and intervene in these issues and while preliminary findings show participant race and parent education level to be associated with late and missing visits, although to date, attrition in ABCD has been minimal (Ewing et al. 2022). Ideally, one tries to minimize attrition through good retention practices from the outset via strategies designed to maintain engagement in the project (Cotter et al. 2005; Hill et al. 2016; Watson et al. 2018). However, even the best-executed studies need to anticipate growing attrition over the length of the study and implement analytic strategies designed to provide the most valid inferences. Perhaps the most key concern when dealing with data that is missing due to attrition is determining the degree of bias in retained variables that is a consequence of attrition. Such bias can attenuate generalizability, particularly if the pattern of missingness is not random (e.g., certain subsets of the population are more likely to drop out/not attend a visit). Assuming that the data are not missing completely at random, attention to the nature of the missingness and employing techniques designed to mitigate attrition-related biases need to be considered in all longitudinal analyses.\nThree types of missingness are considered in the literature (see R. J. Little and Rubin 1989), namely: a) missing completely at random (MCAR), b) missing at random (MAR), and c) missing not at random (MNAR). Data that are MCAR are a simple random sample of all data in a given dataset. MAR implies missing data are a random sample (i.e., does not hinge on some unmeasured variables) within strata of the measured covariates in a dataset (e.g., biological sex). Data that are MNAR are missing as a function of unobserved variables and may bias assocations even after conditioning on the observed covariates. Graham (2009) provides an excellent and easy-to-digest overview of further details involving missing data considerations.\nModern approaches for handling missing data, such as full information maximum likelihood, propensity weighting, auxiliary variables and multiple imputation avoid the biases of older approaches (see Enders 2010; Graham 2009). Graham (2009) noted several “myths” regarding missing data. For example, Graham notes many assume the data must be minimally MAR to permit estimating procedures (such as maximum likelihood or multiple imputation) compared to other, more traditional approaches (e.g., using only complete case data). Violations of MAR impact both traditional and more modern data estimation procedures, though as noted by Graham, violations of MAR tend to have a greater effect on older methods. Graham thus suggests that imputing missing data is a better approach compared to listwise deletion in most circumstances, regardless of the model of missingness [i.e., MCAR, MAR, MNAR; see Graham (2009)].\n\n\n3.1.8 Quantifying effect sizes longitudinally\nGiven that longitudinal data involve multiple sources of variance, quantifying effect sizes longitudinally is a more difficult task compared to deriving such estimates from cross-sectional data. An effect size can be defined as, “a population parameter (estimated in a sample) encapsulating the practical or clinical importance of a phenomenon under study.” (Kraemer 2014). Common effect size metrics include the correlation r between two variables and the standardized difference between two means, Cohen’s d (Cohen 1988). An extensive discussion of effect sizes and their relevance for ABCD is given in Dick et al. (2021). Adjustments to common effect size calculations, such as Cohen’s d, are required even when only two time points are considered (e.g., Morris and DeShon (2002)). Wang et al. (2019) note there are multiple approaches to obtaining standardized within-person effects, and that commonly suggested approaches (e.g., global standardization) can be problematic (see Wang et al. (2019), for more details). Thus, obtaining effect size metrics based on standardized estimates that are relatively simple in cross-sectional data (such as r) becomes more complex in the context of prospective longitudinal data. Feingold (2009) noted that equations for effects sizes used in studies involving growth modeling analysis (e.g., latent growth curve modeling) were not mathematically equivalent, and the effect sizes were not in the same metric as effect sizes from traditional analysis (see Feingold (2009), for more details). Given this issue, there have been various proposals for adjusting effect size measures in repeated assessments. Feingold (2019) reviews the approach for effect size metrics for analyses based on growth modeling, including when considering linear and non-linear (i.e., quadratic) growth factors. Morris and DeShon (2002) review various equations for effect size calculations relevant to combining estimates in meta-analysis with repeated measures and independent-groups designs. Other approaches to quantifying effect sizes longitudinally may be based on standardized estimates from models that more optimally disentangle between- and within-person sources of variance. As an example, within a random-intercept cross-lagged panel model (RI-CLPM) framework, standardized estimates between random intercepts (i.e., the correlation between two random intercepts for two different constructs assessed repeatedly) could be used to index the between-person relation, whereas standardized estimates among the structured residuals could be used as informing the effect sizes of within-person relations.\n\n\n3.1.9 Longitudinal Data Structures\nAn ideal longitudinal study integrates (a) a well-articulated theoretical model, (b) an appropriate longitudinal data structure, and (c) a statistical model that is an operationalization of the theoretical model (Collins 2006). To accommodate various research questions and contexts, different types of longitudinal data and data structures have emerged (see Figure X). An understanding of these data structures is helpful, as they can warrant different types of longitudinal data analysis (LDA). Given that identifying a starting point for making comparisons is somewhat arbitrary, Curran and Bauer [2019; Bauer and Curran (2019)] provide a nice on-ramp in first distinguishing between the use of “time-to-event” and “repeated measures” data. Although both model time, the former is concerned with whether and when an event occurs, whereas the later is focused on growth and change (Bauer and Curran 2019). Time-to-event structures measure time from a well-defined origin point up to the occurrence of an event of interest. This data structure is most often analyzed using survival analysis methods (e.g., hazard rate models, event history analysis, failure-time models) and the time-to-event data can be based on a single assessment or include multiple recurrent or competing events. While much has been written about “time-to-event” data (see xxx; xxx; xxxx), including a recent analysis examining exclusionary discipline in schools using data from the ABCD Study (Brislin et al. (2023)), our emphasis will be given to the modeling of “repeated measures” data.\n\n\n\nLongitudinal Data Analysis Structural Diagram\n\n\nWhen discussing longitudinal analysis, we are most often talking about data collected on the same unit (e.g., individuals) across multiple measurement occasions. However, repeated-measures analysis is not a monolith, and it will serve us well to distinguish between a few of the most common types. One such approach to repeated measures analysis is the use of time-series models. These models generally consist of a long sequence of repeated measurements (≧ 50-100 measurements) on a single (or small number of) variable of interest. Time-series analysis is often used to predict/forecast temporal trends and cyclic patterns and is geared toward making inferences about prospective outcomes within a population (with relatively with less focus on inferring individual-level mechanisms and risk factors). A related type of repeated measures analysis is Intensive Longitudinal Data (ILD). Similar to time-series analysis, ILD models involve frequent measurements (~ 30-40 measurements) of the same individuals in a relatively circumspect period of time (e.g., experience sampling to obtain time series on many individuals). Although ILD models may include slightly fewer measurement occasions than time-series data, ILD models tend to have more subjects than time series models (~ 50-100 subjects). This allows ILD models to examine short-term patterns by incorporating a time series model that can sometimes fit parameter estimates to each individual’s data in order to model individual difference outcomes. The final type of repeated measures analysis that we will primarily focus on is the longitudinal panel model. These models follow a group of individuals— a panel (also referred to as a cohort) — across relatively fewer measurement occassions (~ 5-15), and are often interested in examining change across both, within-individuals and between-individuals.\nWhile other longitudinal designs have their own unique strengths and applications, the longitudinal panel design is particularly well-suited for investigating developmental processes in the context of the ABCD Study. In the following sections, we will discuss various analytic methods commonly used to analyze longitudinal panel data, including growth models, mixed models, and a number of additional trajectory models. These methods provide valuable insights into within- and between-individual differences and are highly relevant for researchers working with the ABCD Study dataset. By focusing on these methods, we aim to equip readers with the knowledge necessary to conduct longitudinal research and perform analyses using the rich, longitudinal, and publicly available data from the ABCD Study.",
    "crumbs": [
      "Manuscript",
      "Longitudinal Analysis Manuscript: Working Draft"
    ]
  }
]